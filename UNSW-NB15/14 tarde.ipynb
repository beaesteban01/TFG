{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (1,3,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0      1              2     3    4    5         6    7    8   9   \\\n",
      "0  59.166.0.0   1390  149.171.126.6    53  udp  CON  0.001055  132  164  31   \n",
      "1  59.166.0.0  33661  149.171.126.9  1024  udp  CON  0.036133  528  304  31   \n",
      "2  59.166.0.6   1464  149.171.126.7    53  udp  CON  0.001119  146  178  31   \n",
      "\n",
      "   ...  39  40  41 42  43  44  45  46   47  48  \n",
      "0  ...   0   3   7  1   3   1   1   1  NaN   0  \n",
      "1  ...   0   2   4  2   3   1   1   2  NaN   0  \n",
      "2  ...   0  12   8  1   2   2   1   1  NaN   0  \n",
      "\n",
      "[3 rows x 49 columns]\n",
      "Read 700001 rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import tensorflow.contrib.learn as skflow\n",
    "import string\n",
    "\n",
    "\n",
    "#from sklearn.utils.multiclass import unique_labels\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, average_precision_score, precision_recall_curve\n",
    "from inspect import signature\n",
    "%matplotlib inline\n",
    "\n",
    "path = \"UNSW-NB15_1.csv\"\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "df = pd.read_csv(path, header=None)\n",
    "print(df[0:3])\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    " # For now, just drop NA's (rows with missing values)\n",
    "\n",
    "# The CSV file has no column heads, so add them\n",
    "df.columns = [\n",
    "    'srcip',\n",
    "    'sport',\n",
    "    'dstip',\n",
    "    'dsport',\n",
    "    'proto',\n",
    "    'state',\n",
    "    'dur',\n",
    "    'sbyte',\n",
    "    'dbytes',\n",
    "    'sttl',\n",
    "    'dttl',\n",
    "    'sloss',\n",
    "    'dloss',\n",
    "    'service',\n",
    "    'Sload',\n",
    "    'Dload',\n",
    "    'Spkts',\n",
    "    'Dpkts',\n",
    "    'swin',\n",
    "    'dwin',\n",
    "    'stcpb',\n",
    "    'dtcpb',\n",
    "    'smeansz',\n",
    "    'dmeansz',\n",
    "    'trans',\n",
    "    'res',\n",
    "    'Sjit',\n",
    "    'Djit',\n",
    "    'Stime', #QUITAR\n",
    "    'Ltime', #QUITAR\n",
    "    'Sintpkt',\n",
    "    'Dintpkt',\n",
    "    'tcprtt',\n",
    "    'synack',\n",
    "    'ackdat',\n",
    "    'is_sm_ips_ports',\n",
    "    'ct_state_ttl',\n",
    "    'ct_flw_http_mthd',\n",
    "    'is_ftp_login',\n",
    "    'ct_ftp_cmd',\n",
    "    'ct_srv_src',\n",
    "    'ct_srv_dst',\n",
    "    'ct_dst_ltm',\n",
    "    'ct_src_ltm', \n",
    "    'ct_src_dport_ltm',\n",
    "    'ct_dst_sport_lt', \n",
    "    'ct_dst_src_ltm',\n",
    "    'attack_cat',\n",
    "    'Label'\n",
    "]\n",
    "\n",
    "df.dropna(inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srcip</th>\n",
       "      <th>sport</th>\n",
       "      <th>dstip</th>\n",
       "      <th>dsport</th>\n",
       "      <th>proto</th>\n",
       "      <th>state</th>\n",
       "      <th>dur</th>\n",
       "      <th>sbyte</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_lt</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.166.0.0</td>\n",
       "      <td>1390</td>\n",
       "      <td>149.171.126.6</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>132</td>\n",
       "      <td>164</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.166.0.0</td>\n",
       "      <td>33661</td>\n",
       "      <td>149.171.126.9</td>\n",
       "      <td>1024</td>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.036133</td>\n",
       "      <td>528</td>\n",
       "      <td>304</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.166.0.6</td>\n",
       "      <td>1464</td>\n",
       "      <td>149.171.126.7</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.166.0.5</td>\n",
       "      <td>3593</td>\n",
       "      <td>149.171.126.5</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>132</td>\n",
       "      <td>164</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.166.0.3</td>\n",
       "      <td>49664</td>\n",
       "      <td>149.171.126.0</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>59.166.0.0</td>\n",
       "      <td>32119</td>\n",
       "      <td>149.171.126.9</td>\n",
       "      <td>111</td>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.078339</td>\n",
       "      <td>568</td>\n",
       "      <td>312</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        srcip  sport          dstip dsport proto state       dur  sbyte  \\\n",
       "0  59.166.0.0   1390  149.171.126.6     53   udp   CON  0.001055    132   \n",
       "1  59.166.0.0  33661  149.171.126.9   1024   udp   CON  0.036133    528   \n",
       "2  59.166.0.6   1464  149.171.126.7     53   udp   CON  0.001119    146   \n",
       "3  59.166.0.5   3593  149.171.126.5     53   udp   CON  0.001209    132   \n",
       "4  59.166.0.3  49664  149.171.126.0     53   udp   CON  0.001169    146   \n",
       "5  59.166.0.0  32119  149.171.126.9    111   udp   CON  0.078339    568   \n",
       "\n",
       "   dbytes  sttl  ...  is_ftp_login  ct_ftp_cmd  ct_srv_src ct_srv_dst  \\\n",
       "0     164    31  ...             0           0           3          7   \n",
       "1     304    31  ...             0           0           2          4   \n",
       "2     178    31  ...             0           0          12          8   \n",
       "3     164    31  ...             0           0           6          9   \n",
       "4     178    31  ...             0           0           7          9   \n",
       "5     312    31  ...             0           0           2          4   \n",
       "\n",
       "   ct_dst_ltm  ct_src_ltm  ct_src_dport_ltm  ct_dst_sport_lt  ct_dst_src_ltm  \\\n",
       "0           1           3                 1                1               1   \n",
       "1           2           3                 1                1               2   \n",
       "2           1           2                 2                1               1   \n",
       "3           1           1                 1                1               1   \n",
       "4           1           1                 1                1               1   \n",
       "5           2           3                 1                1               2   \n",
       "\n",
       "   Label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "5      0  \n",
       "\n",
       "[6 rows x 48 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING = 'utf-8'\n",
    "\n",
    "def expand_categories(values):\n",
    "    result = []\n",
    "    s = values.value_counts()\n",
    "    t = float(len(values))\n",
    "    for v in s.index:\n",
    "        result.append(\"{}:{}%\".format(v,round(100*(s[v]/t),2)))\n",
    "    return \"[{}]\".format(\",\".join(result))\n",
    "        \n",
    "def analyze(filename):\n",
    "    print()\n",
    "    print(\"Analyzing: {}\".format(filename))\n",
    "    df = pd.read_csv(filename,encoding=ENCODING)\n",
    "    cols = df.columns.values\n",
    "    total = float(len(df))\n",
    "\n",
    "    print(\"{} rows\".format(int(total)))\n",
    "    for col in cols:\n",
    "        uniques = df[col].unique()\n",
    "        unique_count = len(uniques)\n",
    "        if unique_count>100:\n",
    "            print(\"** {}:{} ({}%)\".format(col,unique_count,int(((unique_count)/total)*100)))\n",
    "        else:\n",
    "            print(\"** {}:{}\".format(col,expand_categories(df[col])))\n",
    "            expand_categories(df[col])\n",
    "\n",
    "#analyze(path)\n",
    "\n",
    "\n",
    "# display 5 rows\n",
    "# df[0:5]\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "#Clean 'date' column and convert to Int type\n",
    "def clean_date(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_removed = s.replace(\" \", \"\")\n",
    "    s_int = int(s_removed)\n",
    "    return s_int\n",
    "\n",
    "########## CLEAN IP #######################\n",
    "def clean_ip(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_int = int(s)\n",
    "    return s_int\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "#MINMAX -1 1\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def min_max_1(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "#MINMAX 0 1\n",
    "def min_max_0(df, name, normalized_low=0, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "    \n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(\n",
    "        target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    # Regression\n",
    "    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)\n",
    "\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['srcip'] = df['srcip'].apply(clean_ip)\n",
    "df['dstip'] = df['dstip'].apply(clean_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-5-ae55868a1ecf>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-ae55868a1ecf>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    encode_numeric_zscore((df, 'sport')\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "min_max_0(df, 'srcip')#\n",
    "encode_numeric_zscore((df, 'sport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m     \u001b[0mthe_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[1;32m     35\u001b[0m          initial=_NoValue):\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3ff3f04f98a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencode_numeric_zscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sport'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-f9d988f6c1af>\u001b[0m in \u001b[0;36mencode_numeric_zscore\u001b[0;34m(df, name, mean, sd)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mencode_numeric_zscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mstat_func\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  10954\u001b[0m                                       skipna=skipna)\n\u001b[1;32m  10955\u001b[0m         return self._reduce(f, name, axis=axis, skipna=skipna,\n\u001b[0;32m> 10956\u001b[0;31m                             numeric_only=numeric_only)\n\u001b[0m\u001b[1;32m  10957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10958\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mset_function_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   3628\u001b[0m                                           'numeric_only.'.format(name))\n\u001b[1;32m   3629\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3630\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3632\u001b[0m         \u001b[0;31m# TODO(EA) dispatch to Index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;31m# we want to transform an object array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                     \u001b[0;31m# we want to transform an object array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0mdtype_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m     \u001b[0mthe_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[1;32m     34\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     35\u001b[0m          initial=_NoValue):\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "encode_numeric_zscore(df, 'sport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "srcip                 int64\n",
       "sport                object\n",
       "dstip                 int64\n",
       "dsport               object\n",
       "proto                object\n",
       "state                object\n",
       "dur                 float64\n",
       "sbyte                 int64\n",
       "dbytes                int64\n",
       "sttl                  int64\n",
       "dttl                  int64\n",
       "sloss                 int64\n",
       "dloss                 int64\n",
       "service              object\n",
       "Sload               float64\n",
       "Dload               float64\n",
       "Spkts                 int64\n",
       "Dpkts                 int64\n",
       "swin                  int64\n",
       "dwin                  int64\n",
       "stcpb                 int64\n",
       "dtcpb                 int64\n",
       "smeansz               int64\n",
       "dmeansz               int64\n",
       "trans                 int64\n",
       "res                   int64\n",
       "Sjit                float64\n",
       "Djit                float64\n",
       "Stime                 int64\n",
       "Ltime                 int64\n",
       "Sintpkt             float64\n",
       "Dintpkt             float64\n",
       "tcprtt              float64\n",
       "synack              float64\n",
       "ackdat              float64\n",
       "is_sm_ips_ports       int64\n",
       "ct_state_ttl          int64\n",
       "ct_flw_http_mthd      int64\n",
       "is_ftp_login          int64\n",
       "ct_ftp_cmd            int64\n",
       "ct_srv_src            int64\n",
       "ct_srv_dst            int64\n",
       "ct_dst_ltm            int64\n",
       "ct_src_ltm            int64\n",
       "ct_src_dport_ltm      int64\n",
       "ct_dst_sport_lt       int64\n",
       "ct_dst_src_ltm        int64\n",
       "Label                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_text_dummy(df, 'sport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2956d50fa51b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sport'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "sport = df['sport']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c2f89ca7183d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (3,39,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0      1              2      3    4    5         6     7      8   \\\n",
      "0  59.166.0.0   6055  149.171.126.5  54145  tcp  FIN  0.072974  4238  60788   \n",
      "1  59.166.0.0   7832  149.171.126.3   5607  tcp  FIN  0.144951  5174  91072   \n",
      "2  59.166.0.8  11397  149.171.126.6     21  tcp  FIN  0.116107  2934   3742   \n",
      "\n",
      "   9   ...  39  40  41 42  43  44  45  46   47  48  \n",
      "0  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "1  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "2  31  ...   1   1   2  7   5   1   1   4  NaN   0  \n",
      "\n",
      "[3 rows x 49 columns]\n",
      "Read 700001 rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import tensorflow.contrib.learn as skflow\n",
    "import string\n",
    "\n",
    "\n",
    "#from sklearn.utils.multiclass import unique_labels\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, average_precision_score, precision_recall_curve\n",
    "from inspect import signature\n",
    "%matplotlib inline\n",
    "\n",
    "path = \"UNSW-NB15_2.csv\"\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "df = pd.read_csv(path, header=None)\n",
    "print(df[0:3])\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    " # For now, just drop NA's (rows with missing values)\n",
    "\n",
    "# The CSV file has no column heads, so add them\n",
    "df.columns = [\n",
    "    'srcip',\n",
    "    'sport',\n",
    "    'dstip',\n",
    "    'dsport',\n",
    "    'proto',\n",
    "    'state',\n",
    "    'dur',\n",
    "    'sbyte',\n",
    "    'dbytes',\n",
    "    'sttl',\n",
    "    'dttl',\n",
    "    'sloss',\n",
    "    'dloss',\n",
    "    'service',\n",
    "    'Sload',\n",
    "    'Dload',\n",
    "    'Spkts',\n",
    "    'Dpkts',\n",
    "    'swin',\n",
    "    'dwin',\n",
    "    'stcpb',\n",
    "    'dtcpb',\n",
    "    'smeansz',\n",
    "    'dmeansz',\n",
    "    'trans',\n",
    "    'res',\n",
    "    'Sjit',\n",
    "    'Djit',\n",
    "    'Stime', #QUITAR\n",
    "    'Ltime', #QUITAR\n",
    "    'Sintpkt',\n",
    "    'Dintpkt',\n",
    "    'tcprtt',\n",
    "    'synack',\n",
    "    'ackdat',\n",
    "    'is_sm_ips_ports',\n",
    "    'ct_state_ttl',\n",
    "    'ct_flw_http_mthd',\n",
    "    'is_ftp_login',\n",
    "    'ct_ftp_cmd',\n",
    "    'ct_srv_src',\n",
    "    'ct_srv_dst',\n",
    "    'ct_dst_ltm',\n",
    "    'ct_src_ltm', \n",
    "    'ct_src_dport_ltm',\n",
    "    'ct_dst_sport_lt', \n",
    "    'ct_dst_src_ltm',\n",
    "    'attack_cat',\n",
    "    'Label'\n",
    "]\n",
    "\n",
    "df.dropna(inplace=True,axis=1)\n",
    "\n",
    "df.drop('sport', 1, inplace=True)#\n",
    "df.drop('dsport', 1, inplace=True)#\n",
    "df.drop('state', 1, inplace=True)#\n",
    "df.drop('dur', 1, inplace=True)#\n",
    "df.drop('Sload', 1, inplace=True)#\n",
    "df.drop('Dload', 1, inplace=True)#\n",
    "df.drop('Stime', 1, inplace=True)#\n",
    "df.drop('Ltime', 1, inplace=True)#\n",
    "df.drop('ct_src_ltm', 1, inplace=True)#\n",
    "\n",
    "ENCODING = 'utf-8'\n",
    "\n",
    "def expand_categories(values):\n",
    "    result = []\n",
    "    s = values.value_counts()\n",
    "    t = float(len(values))\n",
    "    for v in s.index:\n",
    "        result.append(\"{}:{}%\".format(v,round(100*(s[v]/t),2)))\n",
    "    return \"[{}]\".format(\",\".join(result))\n",
    "        \n",
    "def analyze(filename):\n",
    "    print()\n",
    "    print(\"Analyzing: {}\".format(filename))\n",
    "    df = pd.read_csv(filename,encoding=ENCODING)\n",
    "    cols = df.columns.values\n",
    "    total = float(len(df))\n",
    "\n",
    "    print(\"{} rows\".format(int(total)))\n",
    "    for col in cols:\n",
    "        uniques = df[col].unique()\n",
    "        unique_count = len(uniques)\n",
    "        if unique_count>100:\n",
    "            print(\"** {}:{} ({}%)\".format(col,unique_count,int(((unique_count)/total)*100)))\n",
    "        else:\n",
    "            print(\"** {}:{}\".format(col,expand_categories(df[col])))\n",
    "            expand_categories(df[col])\n",
    "\n",
    "#analyze(path)\n",
    "\n",
    "\n",
    "# display 5 rows\n",
    "# df[0:5]\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "#Clean 'date' column and convert to Int type\n",
    "def clean_date(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_removed = s.replace(\" \", \"\")\n",
    "    s_int = int(s_removed)\n",
    "    return s_int\n",
    "\n",
    "########## CLEAN IP #######################\n",
    "def clean_ip(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_int = int(s)\n",
    "    return s_int\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "#MINMAX -1 1\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def min_max_1(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "#MINMAX 0 1\n",
    "def min_max_0(df, name, normalized_low=0, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "    \n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(\n",
    "        target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    # Regression\n",
    "    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)\n",
    "\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sport'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sport'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2956d50fa51b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sport'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sport'"
     ]
    }
   ],
   "source": [
    "sport = df['sport']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (3,39,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0      1              2      3    4    5         6     7      8   \\\n",
      "0  59.166.0.0   6055  149.171.126.5  54145  tcp  FIN  0.072974  4238  60788   \n",
      "1  59.166.0.0   7832  149.171.126.3   5607  tcp  FIN  0.144951  5174  91072   \n",
      "2  59.166.0.8  11397  149.171.126.6     21  tcp  FIN  0.116107  2934   3742   \n",
      "\n",
      "   9   ...  39  40  41 42  43  44  45  46   47  48  \n",
      "0  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "1  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "2  31  ...   1   1   2  7   5   1   1   4  NaN   0  \n",
      "\n",
      "[3 rows x 49 columns]\n",
      "Read 700001 rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import tensorflow.contrib.learn as skflow\n",
    "import string\n",
    "\n",
    "\n",
    "#from sklearn.utils.multiclass import unique_labels\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, average_precision_score, precision_recall_curve\n",
    "from inspect import signature\n",
    "%matplotlib inline\n",
    "\n",
    "path = \"UNSW-NB15_2.csv\"\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "df = pd.read_csv(path, header=None)\n",
    "print(df[0:3])\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    " # For now, just drop NA's (rows with missing values)\n",
    "\n",
    "# The CSV file has no column heads, so add them\n",
    "df.columns = [\n",
    "    'srcip',\n",
    "    'sport',\n",
    "    'dstip',\n",
    "    'dsport',\n",
    "    'proto',\n",
    "    'state',\n",
    "    'dur',\n",
    "    'sbyte',\n",
    "    'dbytes',\n",
    "    'sttl',\n",
    "    'dttl',\n",
    "    'sloss',\n",
    "    'dloss',\n",
    "    'service',\n",
    "    'Sload',\n",
    "    'Dload',\n",
    "    'Spkts',\n",
    "    'Dpkts',\n",
    "    'swin',\n",
    "    'dwin',\n",
    "    'stcpb',\n",
    "    'dtcpb',\n",
    "    'smeansz',\n",
    "    'dmeansz',\n",
    "    'trans',\n",
    "    'res',\n",
    "    'Sjit',\n",
    "    'Djit',\n",
    "    'Stime', #QUITAR\n",
    "    'Ltime', #QUITAR\n",
    "    'Sintpkt',\n",
    "    'Dintpkt',\n",
    "    'tcprtt',\n",
    "    'synack',\n",
    "    'ackdat',\n",
    "    'is_sm_ips_ports',\n",
    "    'ct_state_ttl',\n",
    "    'ct_flw_http_mthd',\n",
    "    'is_ftp_login',\n",
    "    'ct_ftp_cmd',\n",
    "    'ct_srv_src',\n",
    "    'ct_srv_dst',\n",
    "    'ct_dst_ltm',\n",
    "    'ct_src_ltm', \n",
    "    'ct_src_dport_ltm',\n",
    "    'ct_dst_sport_lt', \n",
    "    'ct_dst_src_ltm',\n",
    "    'attack_cat',\n",
    "    'Label'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport = df['sport']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          6055\n",
       "1          7832\n",
       "2         11397\n",
       "3          3804\n",
       "4         14339\n",
       "5         39094\n",
       "6         10845\n",
       "7         45642\n",
       "8          1931\n",
       "9         25724\n",
       "10        49668\n",
       "11        14951\n",
       "12        27545\n",
       "13        56591\n",
       "14        27855\n",
       "15        50296\n",
       "16        30115\n",
       "17         5573\n",
       "18        23062\n",
       "19        34913\n",
       "20        16182\n",
       "21        60312\n",
       "22        20134\n",
       "23        50600\n",
       "24        55009\n",
       "25        56851\n",
       "26        51278\n",
       "27         8780\n",
       "28        63194\n",
       "29         8844\n",
       "          ...  \n",
       "699971    48965\n",
       "699972     1042\n",
       "699973    28354\n",
       "699974    18455\n",
       "699975    47831\n",
       "699976    35609\n",
       "699977    33127\n",
       "699978    40487\n",
       "699979    12841\n",
       "699980    27449\n",
       "699981     2020\n",
       "699982    49344\n",
       "699983    15030\n",
       "699984    63132\n",
       "699985    61247\n",
       "699986     6870\n",
       "699987     7894\n",
       "699988    10143\n",
       "699989    61561\n",
       "699990     1043\n",
       "699991     1043\n",
       "699992    27775\n",
       "699993     1043\n",
       "699994     1043\n",
       "699995     1043\n",
       "699996     1043\n",
       "699997     1043\n",
       "699998     1043\n",
       "699999     1043\n",
       "700000    18247\n",
       "Name: sport, Length: 700001, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sport.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          6055\n",
       "1          7832\n",
       "2         11397\n",
       "3          3804\n",
       "4         14339\n",
       "5         39094\n",
       "6         10845\n",
       "7         45642\n",
       "8          1931\n",
       "9         25724\n",
       "10        49668\n",
       "11        14951\n",
       "12        27545\n",
       "13        56591\n",
       "14        27855\n",
       "15        50296\n",
       "16        30115\n",
       "17         5573\n",
       "18        23062\n",
       "19        34913\n",
       "20        16182\n",
       "21        60312\n",
       "22        20134\n",
       "23        50600\n",
       "24        55009\n",
       "25        56851\n",
       "26        51278\n",
       "27         8780\n",
       "28        63194\n",
       "29         8844\n",
       "          ...  \n",
       "699971    48965\n",
       "699972     1042\n",
       "699973    28354\n",
       "699974    18455\n",
       "699975    47831\n",
       "699976    35609\n",
       "699977    33127\n",
       "699978    40487\n",
       "699979    12841\n",
       "699980    27449\n",
       "699981     2020\n",
       "699982    49344\n",
       "699983    15030\n",
       "699984    63132\n",
       "699985    61247\n",
       "699986     6870\n",
       "699987     7894\n",
       "699988    10143\n",
       "699989    61561\n",
       "699990     1043\n",
       "699991     1043\n",
       "699992    27775\n",
       "699993     1043\n",
       "699994     1043\n",
       "699995     1043\n",
       "699996     1043\n",
       "699997     1043\n",
       "699998     1043\n",
       "699999     1043\n",
       "700000    18247\n",
       "Name: sport, Length: 700001, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sport'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encode_text_zscore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-172b6367cbdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencode_text_zscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sport'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'encode_text_zscore' is not defined"
     ]
    }
   ],
   "source": [
    "encode_text_zscore(df, 'sport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (3,39,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0      1              2      3    4    5         6     7      8   \\\n",
      "0  59.166.0.0   6055  149.171.126.5  54145  tcp  FIN  0.072974  4238  60788   \n",
      "1  59.166.0.0   7832  149.171.126.3   5607  tcp  FIN  0.144951  5174  91072   \n",
      "2  59.166.0.8  11397  149.171.126.6     21  tcp  FIN  0.116107  2934   3742   \n",
      "\n",
      "   9   ...  39  40  41 42  43  44  45  46   47  48  \n",
      "0  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "1  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "2  31  ...   1   1   2  7   5   1   1   4  NaN   0  \n",
      "\n",
      "[3 rows x 49 columns]\n",
      "Read 700001 rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import tensorflow.contrib.learn as skflow\n",
    "import string\n",
    "\n",
    "\n",
    "#from sklearn.utils.multiclass import unique_labels\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, average_precision_score, precision_recall_curve\n",
    "from inspect import signature\n",
    "%matplotlib inline\n",
    "\n",
    "path = \"UNSW-NB15_2.csv\"\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "df = pd.read_csv(path, header=None)\n",
    "print(df[0:3])\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    " # For now, just drop NA's (rows with missing values)\n",
    "\n",
    "# The CSV file has no column heads, so add them\n",
    "df.columns = [\n",
    "    'srcip',\n",
    "    'sport',\n",
    "    'dstip',\n",
    "    'dsport',\n",
    "    'proto',\n",
    "    'state',\n",
    "    'dur',\n",
    "    'sbyte',\n",
    "    'dbytes',\n",
    "    'sttl',\n",
    "    'dttl',\n",
    "    'sloss',\n",
    "    'dloss',\n",
    "    'service',\n",
    "    'Sload',\n",
    "    'Dload',\n",
    "    'Spkts',\n",
    "    'Dpkts',\n",
    "    'swin',\n",
    "    'dwin',\n",
    "    'stcpb',\n",
    "    'dtcpb',\n",
    "    'smeansz',\n",
    "    'dmeansz',\n",
    "    'trans',\n",
    "    'res',\n",
    "    'Sjit',\n",
    "    'Djit',\n",
    "    'Stime', #QUITAR\n",
    "    'Ltime', #QUITAR\n",
    "    'Sintpkt',\n",
    "    'Dintpkt',\n",
    "    'tcprtt',\n",
    "    'synack',\n",
    "    'ackdat',\n",
    "    'is_sm_ips_ports',\n",
    "    'ct_state_ttl',\n",
    "    'ct_flw_http_mthd',\n",
    "    'is_ftp_login',\n",
    "    'ct_ftp_cmd',\n",
    "    'ct_srv_src',\n",
    "    'ct_srv_dst',\n",
    "    'ct_dst_ltm',\n",
    "    'ct_src_ltm', \n",
    "    'ct_src_dport_ltm',\n",
    "    'ct_dst_sport_lt', \n",
    "    'ct_dst_src_ltm',\n",
    "    'attack_cat',\n",
    "    'Label'\n",
    "]\n",
    "\n",
    "df.dropna(inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING = 'utf-8'\n",
    "\n",
    "def expand_categories(values):\n",
    "    result = []\n",
    "    s = values.value_counts()\n",
    "    t = float(len(values))\n",
    "    for v in s.index:\n",
    "        result.append(\"{}:{}%\".format(v,round(100*(s[v]/t),2)))\n",
    "    return \"[{}]\".format(\",\".join(result))\n",
    "        \n",
    "def analyze(filename):\n",
    "    print()\n",
    "    print(\"Analyzing: {}\".format(filename))\n",
    "    df = pd.read_csv(filename,encoding=ENCODING)\n",
    "    cols = df.columns.values\n",
    "    total = float(len(df))\n",
    "\n",
    "    print(\"{} rows\".format(int(total)))\n",
    "    for col in cols:\n",
    "        uniques = df[col].unique()\n",
    "        unique_count = len(uniques)\n",
    "        if unique_count>100:\n",
    "            print(\"** {}:{} ({}%)\".format(col,unique_count,int(((unique_count)/total)*100)))\n",
    "        else:\n",
    "            print(\"** {}:{}\".format(col,expand_categories(df[col])))\n",
    "            expand_categories(df[col])\n",
    "\n",
    "#analyze(path)\n",
    "\n",
    "\n",
    "# display 5 rows\n",
    "# df[0:5]\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "#Clean 'date' column and convert to Int type\n",
    "def clean_date(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_removed = s.replace(\" \", \"\")\n",
    "    s_int = int(s_removed)\n",
    "    return s_int\n",
    "\n",
    "########## CLEAN IP #######################\n",
    "def clean_ip(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_int = int(s)\n",
    "    return s_int\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "#MINMAX -1 1\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def min_max_1(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "#MINMAX 0 1\n",
    "def min_max_0(df, name, normalized_low=0, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "    \n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(\n",
    "        target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    # Regression\n",
    "    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)\n",
    "\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['srcip'] = df['srcip'].apply(clean_ip)\n",
    "df['dstip'] = df['dstip'].apply(clean_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          6055\n",
       "1          7832\n",
       "2         11397\n",
       "3          3804\n",
       "4         14339\n",
       "5         39094\n",
       "6         10845\n",
       "7         45642\n",
       "8          1931\n",
       "9         25724\n",
       "10        49668\n",
       "11        14951\n",
       "12        27545\n",
       "13        56591\n",
       "14        27855\n",
       "15        50296\n",
       "16        30115\n",
       "17         5573\n",
       "18        23062\n",
       "19        34913\n",
       "20        16182\n",
       "21        60312\n",
       "22        20134\n",
       "23        50600\n",
       "24        55009\n",
       "25        56851\n",
       "26        51278\n",
       "27         8780\n",
       "28        63194\n",
       "29         8844\n",
       "          ...  \n",
       "699971    48965\n",
       "699972     1042\n",
       "699973    28354\n",
       "699974    18455\n",
       "699975    47831\n",
       "699976    35609\n",
       "699977    33127\n",
       "699978    40487\n",
       "699979    12841\n",
       "699980    27449\n",
       "699981     2020\n",
       "699982    49344\n",
       "699983    15030\n",
       "699984    63132\n",
       "699985    61247\n",
       "699986     6870\n",
       "699987     7894\n",
       "699988    10143\n",
       "699989    61561\n",
       "699990     1043\n",
       "699991     1043\n",
       "699992    27775\n",
       "699993     1043\n",
       "699994     1043\n",
       "699995     1043\n",
       "699996     1043\n",
       "699997     1043\n",
       "699998     1043\n",
       "699999     1043\n",
       "700000    18247\n",
       "Name: sport, Length: 700001, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sport'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sport'] = df['sport'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_numeric_zscore(df, 'sport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_numeric_zscore(df, 'dur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srcip</th>\n",
       "      <th>sport</th>\n",
       "      <th>dstip</th>\n",
       "      <th>dsport</th>\n",
       "      <th>proto</th>\n",
       "      <th>state</th>\n",
       "      <th>dur</th>\n",
       "      <th>sbyte</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_state_ttl</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_lt</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5916600</td>\n",
       "      <td>-1.270343</td>\n",
       "      <td>1491711265</td>\n",
       "      <td>54145</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>-0.163935</td>\n",
       "      <td>4238</td>\n",
       "      <td>60788</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5916600</td>\n",
       "      <td>-1.181030</td>\n",
       "      <td>1491711263</td>\n",
       "      <td>5607</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>-0.140845</td>\n",
       "      <td>5174</td>\n",
       "      <td>91072</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5916608</td>\n",
       "      <td>-1.001850</td>\n",
       "      <td>1491711266</td>\n",
       "      <td>21</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>-0.150098</td>\n",
       "      <td>2934</td>\n",
       "      <td>3742</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5916600</td>\n",
       "      <td>-1.383480</td>\n",
       "      <td>1491711263</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>-0.187029</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5916608</td>\n",
       "      <td>-0.853982</td>\n",
       "      <td>1491711266</td>\n",
       "      <td>14724</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>-0.175001</td>\n",
       "      <td>8928</td>\n",
       "      <td>320</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5916608</td>\n",
       "      <td>0.390226</td>\n",
       "      <td>1491711263</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>-0.187016</td>\n",
       "      <td>130</td>\n",
       "      <td>162</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5916600</td>\n",
       "      <td>-1.029594</td>\n",
       "      <td>1491711267</td>\n",
       "      <td>5190</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>-0.185534</td>\n",
       "      <td>1064</td>\n",
       "      <td>2260</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5916603</td>\n",
       "      <td>0.719334</td>\n",
       "      <td>1491711265</td>\n",
       "      <td>80</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>-0.180923</td>\n",
       "      <td>1036</td>\n",
       "      <td>824</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5916604</td>\n",
       "      <td>-1.477619</td>\n",
       "      <td>1491711266</td>\n",
       "      <td>6881</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.863609</td>\n",
       "      <td>13766</td>\n",
       "      <td>548216</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5916608</td>\n",
       "      <td>-0.281762</td>\n",
       "      <td>1491711266</td>\n",
       "      <td>5190</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>-0.138169</td>\n",
       "      <td>1272</td>\n",
       "      <td>2572</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     srcip     sport       dstip dsport proto state       dur  sbyte  dbytes  \\\n",
       "0  5916600 -1.270343  1491711265  54145   tcp   FIN -0.163935   4238   60788   \n",
       "1  5916600 -1.181030  1491711263   5607   tcp   FIN -0.140845   5174   91072   \n",
       "2  5916608 -1.001850  1491711266     21   tcp   FIN -0.150098   2934    3742   \n",
       "3  5916600 -1.383480  1491711263     53   udp   CON -0.187029    146     178   \n",
       "4  5916608 -0.853982  1491711266  14724   tcp   FIN -0.175001   8928     320   \n",
       "5  5916608  0.390226  1491711263     53   udp   CON -0.187016    130     162   \n",
       "6  5916600 -1.029594  1491711267   5190   tcp   FIN -0.185534   1064    2260   \n",
       "7  5916603  0.719334  1491711265     80   tcp   FIN -0.180923   1036     824   \n",
       "8  5916604 -1.477619  1491711266   6881   tcp   FIN  0.863609  13766  548216   \n",
       "9  5916608 -0.281762  1491711266   5190   tcp   FIN -0.138169   1272    2572   \n",
       "\n",
       "   sttl  ...  ct_state_ttl  ct_ftp_cmd  ct_srv_src ct_srv_dst  ct_dst_ltm  \\\n",
       "0    31  ...             0           0          13         13           6   \n",
       "1    31  ...             0           0          13         13           6   \n",
       "2    31  ...             0           1           1          2           7   \n",
       "3    31  ...             0           0          13         13           6   \n",
       "4    31  ...             0           0           8         20           7   \n",
       "5    31  ...             0           0           8         13           6   \n",
       "6    31  ...             0           0          13          9           1   \n",
       "7    31  ...             0           0          18         13           6   \n",
       "8    31  ...             0           0          12         20           7   \n",
       "9    31  ...             0           0           8         20           2   \n",
       "\n",
       "   ct_src_ltm  ct_src_dport_ltm  ct_dst_sport_lt  ct_dst_src_ltm  Label  \n",
       "0           7                 1                1               2      0  \n",
       "1           7                 1                1               2      0  \n",
       "2           5                 1                1               4      0  \n",
       "3           7                 1                1               2      0  \n",
       "4           5                 1                1               4      0  \n",
       "5           5                 1                1               1      0  \n",
       "6           7                 2                1               1      0  \n",
       "7           5                 2                1               1      0  \n",
       "8           2                 1                1               1      0  \n",
       "9           1                 1                1               1      0  \n",
       "\n",
       "[10 rows x 46 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_numeric_zscore(df, 'Sload')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_numeric_zscore(df, 'Dload')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_numeric_zscore(df, 'is_sm_ips_ports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'is_ftp_login'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'is_ftp_login'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f70dc9f38819>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencode_numeric_zscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is_ftp_login'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-58d67288af45>\u001b[0m in \u001b[0;36mencode_numeric_zscore\u001b[0;34m(df, name, mean, sd)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mencode_numeric_zscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'is_ftp_login'"
     ]
    }
   ],
   "source": [
    "encode_numeric_zscore(df, 'is_ftp_login')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'is_ftp_login'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'is_ftp_login'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-8ed5aed23635>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_ftp_login'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'is_ftp_login'"
     ]
    }
   ],
   "source": [
    "df['is_ftp_login']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srcip</th>\n",
       "      <th>sport</th>\n",
       "      <th>dstip</th>\n",
       "      <th>dsport</th>\n",
       "      <th>proto</th>\n",
       "      <th>state</th>\n",
       "      <th>dur</th>\n",
       "      <th>sbyte</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_state_ttl</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_lt</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5916600</td>\n",
       "      <td>-1.270343</td>\n",
       "      <td>1491711265</td>\n",
       "      <td>54145</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>-0.163935</td>\n",
       "      <td>4238</td>\n",
       "      <td>60788</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5916600</td>\n",
       "      <td>-1.181030</td>\n",
       "      <td>1491711263</td>\n",
       "      <td>5607</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>-0.140845</td>\n",
       "      <td>5174</td>\n",
       "      <td>91072</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     srcip     sport       dstip dsport proto state       dur  sbyte  dbytes  \\\n",
       "0  5916600 -1.270343  1491711265  54145   tcp   FIN -0.163935   4238   60788   \n",
       "1  5916600 -1.181030  1491711263   5607   tcp   FIN -0.140845   5174   91072   \n",
       "\n",
       "   sttl  ...  ct_state_ttl  ct_ftp_cmd  ct_srv_src ct_srv_dst  ct_dst_ltm  \\\n",
       "0    31  ...             0           0          13         13           6   \n",
       "1    31  ...             0           0          13         13           6   \n",
       "\n",
       "   ct_src_ltm  ct_src_dport_ltm  ct_dst_sport_lt  ct_dst_src_ltm  Label  \n",
       "0           7                 1                1               2      0  \n",
       "1           7                 1                1               2      0  \n",
       "\n",
       "[2 rows x 46 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ct_flw_http_mthd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ct_flw_http_mthd'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-aa99bc0e742f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmin_max_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ct_flw_http_mthd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-58d67288af45>\u001b[0m in \u001b[0;36mmin_max_0\u001b[0;34m(df, name, normalized_low, normalized_high, data_low, data_high)\u001b[0m\n\u001b[1;32m     78\u001b[0m                          data_low=None, data_high=None):\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_low\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mdata_low\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mdata_high\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ct_flw_http_mthd'"
     ]
    }
   ],
   "source": [
    "min_max_0(df, 'ct_flw_http_mthd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_numeric_zscore(df, 'ct_src_ltm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0      1              2      3    4    5         6     7      8   \\\n",
      "0  59.166.0.0   6055  149.171.126.5  54145  tcp  FIN  0.072974  4238  60788   \n",
      "1  59.166.0.0   7832  149.171.126.3   5607  tcp  FIN  0.144951  5174  91072   \n",
      "2  59.166.0.8  11397  149.171.126.6     21  tcp  FIN  0.116107  2934   3742   \n",
      "\n",
      "   9   ...  39  40  41 42  43  44  45  46   47  48  \n",
      "0  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "1  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "2  31  ...   1   1   2  7   5   1   1   4  NaN   0  \n",
      "\n",
      "[3 rows x 49 columns]\n",
      "Read 700001 rows.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '0xcc09'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-7f378de97171>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sport'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sport'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dsport'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dsport'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;31m# Now encode the feature vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[1;32m   5689\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5690\u001b[0m             new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors,\n\u001b[0;32m-> 5691\u001b[0;31m                                          **kwargs)\n\u001b[0m\u001b[1;32m   5692\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'astype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                                             copy=align_copy)\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         return self._astype(dtype, copy=copy, errors=errors, values=values,\n\u001b[0;32m--> 534\u001b[0;31m                             **kwargs)\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     def _astype(self, dtype, copy=False, errors='raise', values=None,\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m_astype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                     \u001b[0;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m                     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0;31m# TODO(extension)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;31m# work around NumPy brokenness, #1987\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype_intsafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;31m# if we have a datetime/timedelta array of objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.astype_intsafe\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '0xcc09'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import tensorflow.contrib.learn as skflow\n",
    "import string\n",
    "\n",
    "\n",
    "#from sklearn.utils.multiclass import unique_labels\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, average_precision_score, precision_recall_curve\n",
    "from inspect import signature\n",
    "%matplotlib inline\n",
    "\n",
    "path = \"UNSW-NB15_2.csv\"\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "df = pd.read_csv(path, header=None)\n",
    "print(df[0:3])\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    " # For now, just drop NA's (rows with missing values)\n",
    "\n",
    "# The CSV file has no column heads, so add them\n",
    "df.columns = [\n",
    "    'srcip',\n",
    "    'sport',\n",
    "    'dstip',\n",
    "    'dsport',\n",
    "    'proto',\n",
    "    'state',\n",
    "    'dur',\n",
    "    'sbyte',\n",
    "    'dbytes',\n",
    "    'sttl',\n",
    "    'dttl',\n",
    "    'sloss',\n",
    "    'dloss',\n",
    "    'service',\n",
    "    'Sload',\n",
    "    'Dload',\n",
    "    'Spkts',\n",
    "    'Dpkts',\n",
    "    'swin',\n",
    "    'dwin',\n",
    "    'stcpb',\n",
    "    'dtcpb',\n",
    "    'smeansz',\n",
    "    'dmeansz',\n",
    "    'trans',\n",
    "    'res',\n",
    "    'Sjit',\n",
    "    'Djit',\n",
    "    'Stime', #QUITAR\n",
    "    'Ltime', #QUITAR\n",
    "    'Sintpkt',\n",
    "    'Dintpkt',\n",
    "    'tcprtt',\n",
    "    'synack',\n",
    "    'ackdat',\n",
    "    'is_sm_ips_ports',\n",
    "    'ct_state_ttl',\n",
    "    'ct_flw_http_mthd',\n",
    "    'is_ftp_login',\n",
    "    'ct_ftp_cmd',\n",
    "    'ct_srv_src',\n",
    "    'ct_srv_dst',\n",
    "    'ct_dst_ltm',\n",
    "    'ct_src_ltm', \n",
    "    'ct_src_dport_ltm',\n",
    "    'ct_dst_sport_lt', \n",
    "    'ct_dst_src_ltm',\n",
    "    'attack_cat',\n",
    "    'Label'\n",
    "]\n",
    "\n",
    "df.dropna(inplace=True,axis=1)\n",
    "\n",
    "# df.drop('sport', 1, inplace=True)#\n",
    "# df.drop('dsport', 1, inplace=True)#\n",
    "# df.drop('state', 1, inplace=True)#\n",
    "# df.drop('dur', 1, inplace=True)#\n",
    "# df.drop('Sload', 1, inplace=True)#\n",
    "# df.drop('Dload', 1, inplace=True)#\n",
    "# df.drop('Stime', 1, inplace=True)#\n",
    "# df.drop('Ltime', 1, inplace=True)#\n",
    "# df.drop('ct_src_ltm', 1, inplace=True)#\n",
    "\n",
    "ENCODING = 'utf-8'\n",
    "\n",
    "def expand_categories(values):\n",
    "    result = []\n",
    "    s = values.value_counts()\n",
    "    t = float(len(values))\n",
    "    for v in s.index:\n",
    "        result.append(\"{}:{}%\".format(v,round(100*(s[v]/t),2)))\n",
    "    return \"[{}]\".format(\",\".join(result))\n",
    "        \n",
    "def analyze(filename):\n",
    "    print()\n",
    "    print(\"Analyzing: {}\".format(filename))\n",
    "    df = pd.read_csv(filename,encoding=ENCODING)\n",
    "    cols = df.columns.values\n",
    "    total = float(len(df))\n",
    "\n",
    "    print(\"{} rows\".format(int(total)))\n",
    "    for col in cols:\n",
    "        uniques = df[col].unique()\n",
    "        unique_count = len(uniques)\n",
    "        if unique_count>100:\n",
    "            print(\"** {}:{} ({}%)\".format(col,unique_count,int(((unique_count)/total)*100)))\n",
    "        else:\n",
    "            print(\"** {}:{}\".format(col,expand_categories(df[col])))\n",
    "            expand_categories(df[col])\n",
    "\n",
    "#analyze(path)\n",
    "\n",
    "\n",
    "# display 5 rows\n",
    "# df[0:5]\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "#Clean 'date' column and convert to Int type\n",
    "def clean_date(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_removed = s.replace(\" \", \"\")\n",
    "    s_int = int(s_removed)\n",
    "    return s_int\n",
    "\n",
    "########## CLEAN IP #######################\n",
    "def clean_ip(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_int = int(s)\n",
    "    return s_int\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "#MINMAX -1 1\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def min_max_1(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "#MINMAX 0 1\n",
    "def min_max_0(df, name, normalized_low=0, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "    \n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(\n",
    "        target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    # Regression\n",
    "    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)\n",
    "\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['srcip'] = df['srcip'].apply(clean_ip)\n",
    "df['dstip'] = df['dstip'].apply(clean_ip)\n",
    "\n",
    "df['sport'] = df['sport'].astype('int64')\n",
    "df['dsport'] = df['dsport'].astype('int64')\n",
    "\n",
    "# Now encode the feature vector\n",
    "\n",
    "min_max_0(df, 'srcip')#\n",
    "min_max_0(df, 'sport')\n",
    "\n",
    "min_max_0(df, 'dstip') #\n",
    "min_max_0(df, 'dsport')\n",
    "\n",
    "encode_text_dummy(df, 'proto') #\n",
    "#encode_text_dummy(df, 'state')\n",
    "\n",
    "min_max_0(df, 'dur')\n",
    "\n",
    "min_max_0(df, 'sbyte') #\n",
    "min_max_0(df, 'dbytes')#\n",
    "min_max_0(df, 'sttl')#\n",
    "min_max_0(df, 'dttl')#\n",
    "min_max_0(df, 'sloss')#\n",
    "min_max_0(df, 'dloss')#\n",
    "encode_text_dummy(df, 'service') #\n",
    "min_max_0(df, 'Sload')\n",
    "\n",
    "min_max_0(df, 'Dload')\n",
    "\n",
    "min_max_0(df, 'Spkts')#\n",
    "min_max_0(df, 'Dpkts')#\n",
    "min_max_0(df, 'swin')#\n",
    "min_max_0(df, 'dwin')#\n",
    "min_max_0(df, 'stcpb')#\n",
    "min_max_0(df, 'dtcpb')#\n",
    "min_max_0(df, 'smeansz')#\n",
    "min_max_0(df, 'dmeansz')#\n",
    "min_max_0(df, 'trans')#\n",
    "min_max_0(df, 'res')#\n",
    "min_max_0(df, 'Sjit')#\n",
    "min_max_0(df, 'Djit')#\n",
    "\n",
    "min_max_0(df, 'Sintpkt')#\n",
    "min_max_0(df, 'Dintpkt')#\n",
    "min_max_0(df, 'tcprtt')#\n",
    "min_max_0(df, 'synack')#\n",
    "min_max_0(df, 'ackdat')#\n",
    "encode_numeric_zscore(df, 'is_sm_ips_ports')#ojo\n",
    "min_max_0(df, 'ct_state_ttl')#\n",
    "min_max_0(df, 'ct_flw_http_mthd')#\n",
    "encode_numeric_zscore(df, 'is_ftp_login')#ojo\n",
    "min_max_0(df, 'ct_ftp_cmd')#\n",
    "min_max_0(df, 'ct_srv_src')#\n",
    "min_max_0(df, 'ct_srv_dst')#\n",
    "min_max_0(df, 'ct_dst_ltm')#\n",
    "min_max_0(df, 'ct_src_ltm')\n",
    "\n",
    "min_max_0(df, 'ct_src_dport_ltm')#\n",
    "min_max_0(df, 'ct_dst_sport_lt')#\n",
    "min_max_0(df, 'ct_dst_src_ltm')#\n",
    "#encode_numeric_zscore(df, 'attack_cat')#\n",
    "encode_text_dummy(df, 'attack_cat')\n",
    "\n",
    "outcomes = encode_text_index(df, 'Label')#\n",
    "num_classes = len(outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dsport'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         54145\n",
       "1          5607\n",
       "2            21\n",
       "3            53\n",
       "4         14724\n",
       "5            53\n",
       "6          5190\n",
       "7            80\n",
       "8          6881\n",
       "9          5190\n",
       "10           80\n",
       "11           53\n",
       "12          111\n",
       "13        39730\n",
       "14           53\n",
       "15           53\n",
       "16        31010\n",
       "17           80\n",
       "18         5190\n",
       "19         5190\n",
       "20           53\n",
       "21           53\n",
       "22         5190\n",
       "23        49439\n",
       "24           53\n",
       "25           21\n",
       "26          143\n",
       "27           53\n",
       "28        31010\n",
       "29           53\n",
       "          ...  \n",
       "699971    46884\n",
       "699972       80\n",
       "699973       53\n",
       "699974      179\n",
       "699975     5190\n",
       "699976     6881\n",
       "699977       53\n",
       "699978       21\n",
       "699979       80\n",
       "699980     5190\n",
       "699981       25\n",
       "699982    24108\n",
       "699983     6881\n",
       "699984       21\n",
       "699985      110\n",
       "699986       80\n",
       "699987     5972\n",
       "699988       53\n",
       "699989       53\n",
       "699990       53\n",
       "699991       53\n",
       "699992       80\n",
       "699993       53\n",
       "699994       53\n",
       "699995       53\n",
       "699996       53\n",
       "699997       53\n",
       "699998       53\n",
       "699999       53\n",
       "700000     7662\n",
       "Name: dsport, Length: 700001, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dsport']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '0xcc09'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-696431384c83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dsport'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dsport'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[1;32m   5689\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5690\u001b[0m             new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors,\n\u001b[0;32m-> 5691\u001b[0;31m                                          **kwargs)\n\u001b[0m\u001b[1;32m   5692\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'astype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                                             copy=align_copy)\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         return self._astype(dtype, copy=copy, errors=errors, values=values,\n\u001b[0;32m--> 534\u001b[0;31m                             **kwargs)\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     def _astype(self, dtype, copy=False, errors='raise', values=None,\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m_astype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                     \u001b[0;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m                     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0;31m# TODO(extension)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;31m# work around NumPy brokenness, #1987\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype_intsafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;31m# if we have a datetime/timedelta array of objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.astype_intsafe\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '0xcc09'"
     ]
    }
   ],
   "source": [
    "df['dsport'] = df['dsport'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '0xcc09'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-c803d982d760>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dsport'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dsport'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[1;32m   5689\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5690\u001b[0m             new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors,\n\u001b[0;32m-> 5691\u001b[0;31m                                          **kwargs)\n\u001b[0m\u001b[1;32m   5692\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'astype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                                             copy=align_copy)\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         return self._astype(dtype, copy=copy, errors=errors, values=values,\n\u001b[0;32m--> 534\u001b[0;31m                             **kwargs)\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     def _astype(self, dtype, copy=False, errors='raise', values=None,\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m_astype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                     \u001b[0;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m                     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0;31m# TODO(extension)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;31m# Explicit copy, or required since NumPy can't view from / to object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '0xcc09'"
     ]
    }
   ],
   "source": [
    "df['dsport'] = df['dsport'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-e15258622b7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmin_max_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dsport'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-7f378de97171>\u001b[0m in \u001b[0;36mmin_max_0\u001b[0;34m(df, name, normalized_low, normalized_high, data_low, data_high)\u001b[0m\n\u001b[1;32m    175\u001b[0m                          data_low=None, data_high=None):\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_low\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mdata_low\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0mdata_high\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "min_max_0(df, 'dsport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srcip</th>\n",
       "      <th>sport</th>\n",
       "      <th>dstip</th>\n",
       "      <th>dsport</th>\n",
       "      <th>proto</th>\n",
       "      <th>state</th>\n",
       "      <th>dur</th>\n",
       "      <th>sbyte</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_state_ttl</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_lt</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5916600</td>\n",
       "      <td>6055</td>\n",
       "      <td>1491711265</td>\n",
       "      <td>54145</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.072974</td>\n",
       "      <td>4238</td>\n",
       "      <td>60788</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5916600</td>\n",
       "      <td>7832</td>\n",
       "      <td>1491711263</td>\n",
       "      <td>5607</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.144951</td>\n",
       "      <td>5174</td>\n",
       "      <td>91072</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5916608</td>\n",
       "      <td>11397</td>\n",
       "      <td>1491711266</td>\n",
       "      <td>21</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.116107</td>\n",
       "      <td>2934</td>\n",
       "      <td>3742</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5916600</td>\n",
       "      <td>3804</td>\n",
       "      <td>1491711263</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5916608</td>\n",
       "      <td>14339</td>\n",
       "      <td>1491711266</td>\n",
       "      <td>14724</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.038480</td>\n",
       "      <td>8928</td>\n",
       "      <td>320</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5916608</td>\n",
       "      <td>39094</td>\n",
       "      <td>1491711263</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>130</td>\n",
       "      <td>162</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5916600</td>\n",
       "      <td>10845</td>\n",
       "      <td>1491711267</td>\n",
       "      <td>5190</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.005645</td>\n",
       "      <td>1064</td>\n",
       "      <td>2260</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5916603</td>\n",
       "      <td>45642</td>\n",
       "      <td>1491711265</td>\n",
       "      <td>80</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.020018</td>\n",
       "      <td>1036</td>\n",
       "      <td>824</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5916604</td>\n",
       "      <td>1931</td>\n",
       "      <td>1491711266</td>\n",
       "      <td>6881</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>3.276020</td>\n",
       "      <td>13766</td>\n",
       "      <td>548216</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5916608</td>\n",
       "      <td>25724</td>\n",
       "      <td>1491711266</td>\n",
       "      <td>5190</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.153293</td>\n",
       "      <td>1272</td>\n",
       "      <td>2572</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     srcip  sport       dstip dsport proto state       dur  sbyte  dbytes  \\\n",
       "0  5916600   6055  1491711265  54145   tcp   FIN  0.072974   4238   60788   \n",
       "1  5916600   7832  1491711263   5607   tcp   FIN  0.144951   5174   91072   \n",
       "2  5916608  11397  1491711266     21   tcp   FIN  0.116107   2934    3742   \n",
       "3  5916600   3804  1491711263     53   udp   CON  0.000986    146     178   \n",
       "4  5916608  14339  1491711266  14724   tcp   FIN  0.038480   8928     320   \n",
       "5  5916608  39094  1491711263     53   udp   CON  0.001026    130     162   \n",
       "6  5916600  10845  1491711267   5190   tcp   FIN  0.005645   1064    2260   \n",
       "7  5916603  45642  1491711265     80   tcp   FIN  0.020018   1036     824   \n",
       "8  5916604   1931  1491711266   6881   tcp   FIN  3.276020  13766  548216   \n",
       "9  5916608  25724  1491711266   5190   tcp   FIN  0.153293   1272    2572   \n",
       "\n",
       "   sttl  ...  ct_state_ttl  ct_ftp_cmd  ct_srv_src ct_srv_dst  ct_dst_ltm  \\\n",
       "0    31  ...             0           0          13         13           6   \n",
       "1    31  ...             0           0          13         13           6   \n",
       "2    31  ...             0           1           1          2           7   \n",
       "3    31  ...             0           0          13         13           6   \n",
       "4    31  ...             0           0           8         20           7   \n",
       "5    31  ...             0           0           8         13           6   \n",
       "6    31  ...             0           0          13          9           1   \n",
       "7    31  ...             0           0          18         13           6   \n",
       "8    31  ...             0           0          12         20           7   \n",
       "9    31  ...             0           0           8         20           2   \n",
       "\n",
       "   ct_src_ltm  ct_src_dport_ltm  ct_dst_sport_lt  ct_dst_src_ltm  Label  \n",
       "0           7                 1                1               2      0  \n",
       "1           7                 1                1               2      0  \n",
       "2           5                 1                1               4      0  \n",
       "3           7                 1                1               2      0  \n",
       "4           5                 1                1               4      0  \n",
       "5           5                 1                1               1      0  \n",
       "6           7                 2                1               1      0  \n",
       "7           5                 2                1               1      0  \n",
       "8           2                 1                1               1      0  \n",
       "9           1                 1                1               1      0  \n",
       "\n",
       "[10 rows x 46 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_numeric_zscore(df, 'sport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         54145\n",
       "1          5607\n",
       "2            21\n",
       "3            53\n",
       "4         14724\n",
       "5            53\n",
       "6          5190\n",
       "7            80\n",
       "8          6881\n",
       "9          5190\n",
       "10           80\n",
       "11           53\n",
       "12          111\n",
       "13        39730\n",
       "14           53\n",
       "15           53\n",
       "16        31010\n",
       "17           80\n",
       "18         5190\n",
       "19         5190\n",
       "20           53\n",
       "21           53\n",
       "22         5190\n",
       "23        49439\n",
       "24           53\n",
       "25           21\n",
       "26          143\n",
       "27           53\n",
       "28        31010\n",
       "29           53\n",
       "          ...  \n",
       "699971    46884\n",
       "699972       80\n",
       "699973       53\n",
       "699974      179\n",
       "699975     5190\n",
       "699976     6881\n",
       "699977       53\n",
       "699978       21\n",
       "699979       80\n",
       "699980     5190\n",
       "699981       25\n",
       "699982    24108\n",
       "699983     6881\n",
       "699984       21\n",
       "699985      110\n",
       "699986       80\n",
       "699987     5972\n",
       "699988       53\n",
       "699989       53\n",
       "699990       53\n",
       "699991       53\n",
       "699992       80\n",
       "699993       53\n",
       "699994       53\n",
       "699995       53\n",
       "699996       53\n",
       "699997       53\n",
       "699998       53\n",
       "699999       53\n",
       "700000     7662\n",
       "Name: dsport, Length: 700001, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dsport']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (3,39,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0      1              2      3    4    5         6     7      8   \\\n",
      "0  59.166.0.0   6055  149.171.126.5  54145  tcp  FIN  0.072974  4238  60788   \n",
      "1  59.166.0.0   7832  149.171.126.3   5607  tcp  FIN  0.144951  5174  91072   \n",
      "2  59.166.0.8  11397  149.171.126.6     21  tcp  FIN  0.116107  2934   3742   \n",
      "\n",
      "   9   ...  39  40  41 42  43  44  45  46   47  48  \n",
      "0  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "1  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "2  31  ...   1   1   2  7   5   1   1   4  NaN   0  \n",
      "\n",
      "[3 rows x 49 columns]\n",
      "Read 700001 rows.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'dsport'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'dsport'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-a457f8237da0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sport'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sport'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dsport'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dsport'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;31m# Now encode the feature vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'dsport'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import tensorflow.contrib.learn as skflow\n",
    "import string\n",
    "\n",
    "\n",
    "#from sklearn.utils.multiclass import unique_labels\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, average_precision_score, precision_recall_curve\n",
    "from inspect import signature\n",
    "%matplotlib inline\n",
    "\n",
    "path = \"UNSW-NB15_2.csv\"\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "df = pd.read_csv(path, header=None)\n",
    "print(df[0:3])\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    " # For now, just drop NA's (rows with missing values)\n",
    "\n",
    "# The CSV file has no column heads, so add them\n",
    "df.columns = [\n",
    "    'srcip',\n",
    "    'sport',\n",
    "    'dstip',\n",
    "    'dsport',\n",
    "    'proto',\n",
    "    'state',\n",
    "    'dur',\n",
    "    'sbyte',\n",
    "    'dbytes',\n",
    "    'sttl',\n",
    "    'dttl',\n",
    "    'sloss',\n",
    "    'dloss',\n",
    "    'service',\n",
    "    'Sload',\n",
    "    'Dload',\n",
    "    'Spkts',\n",
    "    'Dpkts',\n",
    "    'swin',\n",
    "    'dwin',\n",
    "    'stcpb',\n",
    "    'dtcpb',\n",
    "    'smeansz',\n",
    "    'dmeansz',\n",
    "    'trans',\n",
    "    'res',\n",
    "    'Sjit',\n",
    "    'Djit',\n",
    "    'Stime', #QUITAR\n",
    "    'Ltime', #QUITAR\n",
    "    'Sintpkt',\n",
    "    'Dintpkt',\n",
    "    'tcprtt',\n",
    "    'synack',\n",
    "    'ackdat',\n",
    "    'is_sm_ips_ports',\n",
    "    'ct_state_ttl',\n",
    "    'ct_flw_http_mthd',\n",
    "    'is_ftp_login',\n",
    "    'ct_ftp_cmd',\n",
    "    'ct_srv_src',\n",
    "    'ct_srv_dst',\n",
    "    'ct_dst_ltm',\n",
    "    'ct_src_ltm', \n",
    "    'ct_src_dport_ltm',\n",
    "    'ct_dst_sport_lt', \n",
    "    'ct_dst_src_ltm',\n",
    "    'attack_cat',\n",
    "    'Label'\n",
    "]\n",
    "\n",
    "df.dropna(inplace=True,axis=1)\n",
    "\n",
    "# df.drop('sport', 1, inplace=True)#\n",
    "# df.drop('dsport', 1, inplace=True)#\n",
    "# df.drop('state', 1, inplace=True)#\n",
    "# df.drop('dur', 1, inplace=True)#\n",
    "# df.drop('Sload', 1, inplace=True)#\n",
    "# df.drop('Dload', 1, inplace=True)#\n",
    "# df.drop('Stime', 1, inplace=True)#\n",
    "# df.drop('Ltime', 1, inplace=True)#\n",
    "# df.drop('ct_src_ltm', 1, inplace=True)#\n",
    "\n",
    "ENCODING = 'utf-8'\n",
    "\n",
    "def expand_categories(values):\n",
    "    result = []\n",
    "    s = values.value_counts()\n",
    "    t = float(len(values))\n",
    "    for v in s.index:\n",
    "        result.append(\"{}:{}%\".format(v,round(100*(s[v]/t),2)))\n",
    "    return \"[{}]\".format(\",\".join(result))\n",
    "        \n",
    "def analyze(filename):\n",
    "    print()\n",
    "    print(\"Analyzing: {}\".format(filename))\n",
    "    df = pd.read_csv(filename,encoding=ENCODING)\n",
    "    cols = df.columns.values\n",
    "    total = float(len(df))\n",
    "\n",
    "    print(\"{} rows\".format(int(total)))\n",
    "    for col in cols:\n",
    "        uniques = df[col].unique()\n",
    "        unique_count = len(uniques)\n",
    "        if unique_count>100:\n",
    "            print(\"** {}:{} ({}%)\".format(col,unique_count,int(((unique_count)/total)*100)))\n",
    "        else:\n",
    "            print(\"** {}:{}\".format(col,expand_categories(df[col])))\n",
    "            expand_categories(df[col])\n",
    "\n",
    "#analyze(path)\n",
    "\n",
    "\n",
    "# display 5 rows\n",
    "# df[0:5]\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "#Clean 'date' column and convert to Int type\n",
    "def clean_date(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_removed = s.replace(\" \", \"\")\n",
    "    s_int = int(s_removed)\n",
    "    return s_int\n",
    "\n",
    "########## CLEAN IP #######################\n",
    "def clean_ip(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_int = int(s)\n",
    "    return s_int\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "#MINMAX -1 1\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def min_max_1(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "#MINMAX 0 1\n",
    "def min_max_0(df, name, normalized_low=0, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "    \n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(\n",
    "        target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    # Regression\n",
    "    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)\n",
    "\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['srcip'] = df['srcip'].apply(clean_ip)\n",
    "df['dstip'] = df['dstip'].apply(clean_ip)\n",
    "\n",
    "df['sport'] = df['sport'].astype('int64')\n",
    "df['dsport'] = df['dsport'].astype('int64')\n",
    "\n",
    "# Now encode the feature vector\n",
    "\n",
    "min_max_0(df, 'srcip')#\n",
    "min_max_0(df, 'sport')\n",
    "\n",
    "min_max_0(df, 'dstip') #\n",
    "min_max_0(df, 'dsport')\n",
    "\n",
    "encode_text_dummy(df, 'proto') #\n",
    "#encode_text_dummy(df, 'state')\n",
    "\n",
    "min_max_0(df, 'dur')\n",
    "\n",
    "min_max_0(df, 'sbyte') #\n",
    "min_max_0(df, 'dbytes')#\n",
    "min_max_0(df, 'sttl')#\n",
    "min_max_0(df, 'dttl')#\n",
    "min_max_0(df, 'sloss')#\n",
    "min_max_0(df, 'dloss')#\n",
    "encode_text_dummy(df, 'service') #\n",
    "min_max_0(df, 'Sload')\n",
    "\n",
    "min_max_0(df, 'Dload')\n",
    "\n",
    "min_max_0(df, 'Spkts')#\n",
    "min_max_0(df, 'Dpkts')#\n",
    "min_max_0(df, 'swin')#\n",
    "min_max_0(df, 'dwin')#\n",
    "min_max_0(df, 'stcpb')#\n",
    "min_max_0(df, 'dtcpb')#\n",
    "min_max_0(df, 'smeansz')#\n",
    "min_max_0(df, 'dmeansz')#\n",
    "min_max_0(df, 'trans')#\n",
    "min_max_0(df, 'res')#\n",
    "min_max_0(df, 'Sjit')#\n",
    "min_max_0(df, 'Djit')#\n",
    "\n",
    "min_max_0(df, 'Sintpkt')#\n",
    "min_max_0(df, 'Dintpkt')#\n",
    "min_max_0(df, 'tcprtt')#\n",
    "min_max_0(df, 'synack')#\n",
    "min_max_0(df, 'ackdat')#\n",
    "encode_numeric_zscore(df, 'is_sm_ips_ports')#ojo\n",
    "min_max_0(df, 'ct_state_ttl')#\n",
    "min_max_0(df, 'ct_flw_http_mthd')#\n",
    "encode_numeric_zscore(df, 'is_ftp_login')#ojo\n",
    "min_max_0(df, 'ct_ftp_cmd')#\n",
    "min_max_0(df, 'ct_srv_src')#\n",
    "min_max_0(df, 'ct_srv_dst')#\n",
    "min_max_0(df, 'ct_dst_ltm')#\n",
    "min_max_0(df, 'ct_src_ltm')\n",
    "\n",
    "min_max_0(df, 'ct_src_dport_ltm')#\n",
    "min_max_0(df, 'ct_dst_sport_lt')#\n",
    "min_max_0(df, 'ct_dst_src_ltm')#\n",
    "#encode_numeric_zscore(df, 'attack_cat')#\n",
    "encode_text_dummy(df, 'attack_cat')\n",
    "\n",
    "outcomes = encode_text_index(df, 'Label')#\n",
    "num_classes = len(outcomes)\n",
    "\n",
    "# display 5 rows\n",
    "\n",
    "#df.dropna(inplace=True,axis=1)\n",
    "df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'dsport'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'dsport'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-696431384c83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dsport'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dsport'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'dsport'"
     ]
    }
   ],
   "source": [
    "df['dsport'] = df['dsport'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'dsport'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'dsport'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-26e500f53639>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dsport'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'dsport'"
     ]
    }
   ],
   "source": [
    "df['dsport']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (3,39,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0      1              2      3    4    5         6     7      8   \\\n",
      "0  59.166.0.0   6055  149.171.126.5  54145  tcp  FIN  0.072974  4238  60788   \n",
      "1  59.166.0.0   7832  149.171.126.3   5607  tcp  FIN  0.144951  5174  91072   \n",
      "2  59.166.0.8  11397  149.171.126.6     21  tcp  FIN  0.116107  2934   3742   \n",
      "\n",
      "   9   ...  39  40  41 42  43  44  45  46   47  48  \n",
      "0  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "1  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "2  31  ...   1   1   2  7   5   1   1   4  NaN   0  \n",
      "\n",
      "[3 rows x 49 columns]\n",
      "Read 700001 rows.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-ef8490db70af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;31m# Now encode the feature vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m \u001b[0mmin_max_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'srcip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0mmin_max_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sport'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-ef8490db70af>\u001b[0m in \u001b[0;36mmin_max_0\u001b[0;34m(df, name, normalized_low, normalized_high, data_low, data_high)\u001b[0m\n\u001b[1;32m    175\u001b[0m                          data_low=None, data_high=None):\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_low\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mdata_low\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0mdata_high\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: min() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import tensorflow.contrib.learn as skflow\n",
    "import string\n",
    "\n",
    "\n",
    "#from sklearn.utils.multiclass import unique_labels\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, average_precision_score, precision_recall_curve\n",
    "from inspect import signature\n",
    "%matplotlib inline\n",
    "\n",
    "path = \"UNSW-NB15_2.csv\"\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "df = pd.read_csv(path, header=None)\n",
    "print(df[0:3])\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    " # For now, just drop NA's (rows with missing values)\n",
    "\n",
    "# The CSV file has no column heads, so add them\n",
    "df.columns = [\n",
    "    'srcip',\n",
    "    'sport',\n",
    "    'dstip',\n",
    "    'dsport',\n",
    "    'proto',\n",
    "    'state',\n",
    "    'dur',\n",
    "    'sbyte',\n",
    "    'dbytes',\n",
    "    'sttl',\n",
    "    'dttl',\n",
    "    'sloss',\n",
    "    'dloss',\n",
    "    'service',\n",
    "    'Sload',\n",
    "    'Dload',\n",
    "    'Spkts',\n",
    "    'Dpkts',\n",
    "    'swin',\n",
    "    'dwin',\n",
    "    'stcpb',\n",
    "    'dtcpb',\n",
    "    'smeansz',\n",
    "    'dmeansz',\n",
    "    'trans',\n",
    "    'res',\n",
    "    'Sjit',\n",
    "    'Djit',\n",
    "    'Stime', #QUITAR\n",
    "    'Ltime', #QUITAR\n",
    "    'Sintpkt',\n",
    "    'Dintpkt',\n",
    "    'tcprtt',\n",
    "    'synack',\n",
    "    'ackdat',\n",
    "    'is_sm_ips_ports',\n",
    "    'ct_state_ttl',\n",
    "    'ct_flw_http_mthd',\n",
    "    'is_ftp_login',\n",
    "    'ct_ftp_cmd',\n",
    "    'ct_srv_src',\n",
    "    'ct_srv_dst',\n",
    "    'ct_dst_ltm',\n",
    "    'ct_src_ltm', \n",
    "    'ct_src_dport_ltm',\n",
    "    'ct_dst_sport_lt', \n",
    "    'ct_dst_src_ltm',\n",
    "    'attack_cat',\n",
    "    'Label'\n",
    "]\n",
    "\n",
    "df.dropna(inplace=True,axis=0)\n",
    "\n",
    "# df.drop('sport', 1, inplace=True)#\n",
    "# df.drop('dsport', 1, inplace=True)#\n",
    "# df.drop('state', 1, inplace=True)#\n",
    "# df.drop('dur', 1, inplace=True)#\n",
    "# df.drop('Sload', 1, inplace=True)#\n",
    "# df.drop('Dload', 1, inplace=True)#\n",
    "# df.drop('Stime', 1, inplace=True)#\n",
    "# df.drop('Ltime', 1, inplace=True)#\n",
    "# df.drop('ct_src_ltm', 1, inplace=True)#\n",
    "\n",
    "ENCODING = 'utf-8'\n",
    "\n",
    "def expand_categories(values):\n",
    "    result = []\n",
    "    s = values.value_counts()\n",
    "    t = float(len(values))\n",
    "    for v in s.index:\n",
    "        result.append(\"{}:{}%\".format(v,round(100*(s[v]/t),2)))\n",
    "    return \"[{}]\".format(\",\".join(result))\n",
    "        \n",
    "def analyze(filename):\n",
    "    print()\n",
    "    print(\"Analyzing: {}\".format(filename))\n",
    "    df = pd.read_csv(filename,encoding=ENCODING)\n",
    "    cols = df.columns.values\n",
    "    total = float(len(df))\n",
    "\n",
    "    print(\"{} rows\".format(int(total)))\n",
    "    for col in cols:\n",
    "        uniques = df[col].unique()\n",
    "        unique_count = len(uniques)\n",
    "        if unique_count>100:\n",
    "            print(\"** {}:{} ({}%)\".format(col,unique_count,int(((unique_count)/total)*100)))\n",
    "        else:\n",
    "            print(\"** {}:{}\".format(col,expand_categories(df[col])))\n",
    "            expand_categories(df[col])\n",
    "\n",
    "#analyze(path)\n",
    "\n",
    "\n",
    "# display 5 rows\n",
    "# df[0:5]\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "#Clean 'date' column and convert to Int type\n",
    "def clean_date(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_removed = s.replace(\" \", \"\")\n",
    "    s_int = int(s_removed)\n",
    "    return s_int\n",
    "\n",
    "########## CLEAN IP #######################\n",
    "def clean_ip(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_int = int(s)\n",
    "    return s_int\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "#MINMAX -1 1\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def min_max_1(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "#MINMAX 0 1\n",
    "def min_max_0(df, name, normalized_low=0, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "    \n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(\n",
    "        target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    # Regression\n",
    "    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)\n",
    "\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['srcip'] = df['srcip'].apply(clean_ip)\n",
    "df['dstip'] = df['dstip'].apply(clean_ip)\n",
    "\n",
    "df['sport'] = df['sport'].astype('int64')\n",
    "df['dsport'] = df['dsport'].astype('int64')\n",
    "\n",
    "# Now encode the feature vector\n",
    "\n",
    "min_max_0(df, 'srcip')#\n",
    "min_max_0(df, 'sport')\n",
    "\n",
    "min_max_0(df, 'dstip') #\n",
    "min_max_0(df, 'dsport')\n",
    "\n",
    "encode_text_dummy(df, 'proto') #\n",
    "encode_text_dummy(df, 'state')\n",
    "\n",
    "min_max_0(df, 'dur')\n",
    "\n",
    "min_max_0(df, 'sbyte') #\n",
    "min_max_0(df, 'dbytes')#\n",
    "min_max_0(df, 'sttl')#\n",
    "min_max_0(df, 'dttl')#\n",
    "min_max_0(df, 'sloss')#\n",
    "min_max_0(df, 'dloss')#\n",
    "encode_text_dummy(df, 'service') #\n",
    "min_max_0(df, 'Sload')\n",
    "\n",
    "min_max_0(df, 'Dload')\n",
    "\n",
    "min_max_0(df, 'Spkts')#\n",
    "min_max_0(df, 'Dpkts')#\n",
    "min_max_0(df, 'swin')#\n",
    "min_max_0(df, 'dwin')#\n",
    "min_max_0(df, 'stcpb')#\n",
    "min_max_0(df, 'dtcpb')#\n",
    "min_max_0(df, 'smeansz')#\n",
    "min_max_0(df, 'dmeansz')#\n",
    "min_max_0(df, 'trans')#\n",
    "min_max_0(df, 'res')#\n",
    "min_max_0(df, 'Sjit')#\n",
    "min_max_0(df, 'Djit')#\n",
    "\n",
    "min_max_0(df, 'Sintpkt')#\n",
    "min_max_0(df, 'Dintpkt')#\n",
    "min_max_0(df, 'tcprtt')#\n",
    "min_max_0(df, 'synack')#\n",
    "min_max_0(df, 'ackdat')#\n",
    "encode_numeric_zscore(df, 'is_sm_ips_ports')#ojo\n",
    "min_max_0(df, 'ct_state_ttl')#\n",
    "min_max_0(df, 'ct_flw_http_mthd')#\n",
    "encode_numeric_zscore(df, 'is_ftp_login')#ojo\n",
    "min_max_0(df, 'ct_ftp_cmd')#\n",
    "min_max_0(df, 'ct_srv_src')#\n",
    "min_max_0(df, 'ct_srv_dst')#\n",
    "min_max_0(df, 'ct_dst_ltm')#\n",
    "min_max_0(df, 'ct_src_ltm')\n",
    "\n",
    "min_max_0(df, 'ct_src_dport_ltm')#\n",
    "min_max_0(df, 'ct_dst_sport_lt')#\n",
    "min_max_0(df, 'ct_dst_src_ltm')#\n",
    "#encode_numeric_zscore(df, 'attack_cat')#\n",
    "encode_text_dummy(df, 'attack_cat')\n",
    "\n",
    "outcomes = encode_text_index(df, 'Label')#\n",
    "num_classes = len(outcomes)\n",
    "\n",
    "# display 5 rows\n",
    "\n",
    "#df.dropna(inplace=True,axis=1)\n",
    "df[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srcip</th>\n",
       "      <th>sport</th>\n",
       "      <th>dstip</th>\n",
       "      <th>dsport</th>\n",
       "      <th>proto</th>\n",
       "      <th>state</th>\n",
       "      <th>dur</th>\n",
       "      <th>sbyte</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_lt</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [srcip, sport, dstip, dsport, proto, state, dur, sbyte, dbytes, sttl, dttl, sloss, dloss, service, Sload, Dload, Spkts, Dpkts, swin, dwin, stcpb, dtcpb, smeansz, dmeansz, trans, res, Sjit, Djit, Stime, Ltime, Sintpkt, Dintpkt, tcprtt, synack, ackdat, is_sm_ips_ports, ct_state_ttl, ct_flw_http_mthd, is_ftp_login, ct_ftp_cmd, ct_srv_src, ct_srv_dst, ct_dst_ltm, ct_src_ltm, ct_src_dport_ltm, ct_dst_sport_lt, ct_dst_src_ltm, attack_cat, Label]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 49 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0      1              2      3    4    5         6     7      8   \\\n",
      "0  59.166.0.0   6055  149.171.126.5  54145  tcp  FIN  0.072974  4238  60788   \n",
      "1  59.166.0.0   7832  149.171.126.3   5607  tcp  FIN  0.144951  5174  91072   \n",
      "2  59.166.0.8  11397  149.171.126.6     21  tcp  FIN  0.116107  2934   3742   \n",
      "\n",
      "   9   ...  39  40  41 42  43  44  45  46   47  48  \n",
      "0  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "1  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "2  31  ...   1   1   2  7   5   1   1   4  NaN   0  \n",
      "\n",
      "[3 rows x 49 columns]\n",
      "Read 700001 rows.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-02a1aa02d5ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;31m# Now encode the feature vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m \u001b[0mmin_max_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'srcip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0mmin_max_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sport'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-02a1aa02d5ca>\u001b[0m in \u001b[0;36mmin_max_0\u001b[0;34m(df, name, normalized_low, normalized_high, data_low, data_high)\u001b[0m\n\u001b[1;32m    175\u001b[0m                          data_low=None, data_high=None):\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_low\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mdata_low\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0mdata_high\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: min() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import tensorflow.contrib.learn as skflow\n",
    "import string\n",
    "\n",
    "\n",
    "#from sklearn.utils.multiclass import unique_labels\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, average_precision_score, precision_recall_curve\n",
    "from inspect import signature\n",
    "%matplotlib inline\n",
    "\n",
    "path = \"UNSW-NB15_2.csv\"\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "df = pd.read_csv(path, header=None)\n",
    "print(df[0:3])\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    " # For now, just drop NA's (rows with missing values)\n",
    "\n",
    "# The CSV file has no column heads, so add them\n",
    "df.columns = [\n",
    "    'srcip',\n",
    "    'sport',\n",
    "    'dstip',\n",
    "    'dsport',\n",
    "    'proto',\n",
    "    'state',\n",
    "    'dur',\n",
    "    'sbyte',\n",
    "    'dbytes',\n",
    "    'sttl',\n",
    "    'dttl',\n",
    "    'sloss',\n",
    "    'dloss',\n",
    "    'service',\n",
    "    'Sload',\n",
    "    'Dload',\n",
    "    'Spkts',\n",
    "    'Dpkts',\n",
    "    'swin',\n",
    "    'dwin',\n",
    "    'stcpb',\n",
    "    'dtcpb',\n",
    "    'smeansz',\n",
    "    'dmeansz',\n",
    "    'trans',\n",
    "    'res',\n",
    "    'Sjit',\n",
    "    'Djit',\n",
    "    'Stime', #QUITAR\n",
    "    'Ltime', #QUITAR\n",
    "    'Sintpkt',\n",
    "    'Dintpkt',\n",
    "    'tcprtt',\n",
    "    'synack',\n",
    "    'ackdat',\n",
    "    'is_sm_ips_ports',\n",
    "    'ct_state_ttl',\n",
    "    'ct_flw_http_mthd',\n",
    "    'is_ftp_login',\n",
    "    'ct_ftp_cmd',\n",
    "    'ct_srv_src',\n",
    "    'ct_srv_dst',\n",
    "    'ct_dst_ltm',\n",
    "    'ct_src_ltm', \n",
    "    'ct_src_dport_ltm',\n",
    "    'ct_dst_sport_lt', \n",
    "    'ct_dst_src_ltm',\n",
    "    'attack_cat',\n",
    "    'Label'\n",
    "]\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# df.drop('sport', 1, inplace=True)#\n",
    "# df.drop('dsport', 1, inplace=True)#\n",
    "# df.drop('state', 1, inplace=True)#\n",
    "# df.drop('dur', 1, inplace=True)#\n",
    "# df.drop('Sload', 1, inplace=True)#\n",
    "# df.drop('Dload', 1, inplace=True)#\n",
    "# df.drop('Stime', 1, inplace=True)#\n",
    "# df.drop('Ltime', 1, inplace=True)#\n",
    "# df.drop('ct_src_ltm', 1, inplace=True)#\n",
    "\n",
    "ENCODING = 'utf-8'\n",
    "\n",
    "def expand_categories(values):\n",
    "    result = []\n",
    "    s = values.value_counts()\n",
    "    t = float(len(values))\n",
    "    for v in s.index:\n",
    "        result.append(\"{}:{}%\".format(v,round(100*(s[v]/t),2)))\n",
    "    return \"[{}]\".format(\",\".join(result))\n",
    "        \n",
    "def analyze(filename):\n",
    "    print()\n",
    "    print(\"Analyzing: {}\".format(filename))\n",
    "    df = pd.read_csv(filename,encoding=ENCODING)\n",
    "    cols = df.columns.values\n",
    "    total = float(len(df))\n",
    "\n",
    "    print(\"{} rows\".format(int(total)))\n",
    "    for col in cols:\n",
    "        uniques = df[col].unique()\n",
    "        unique_count = len(uniques)\n",
    "        if unique_count>100:\n",
    "            print(\"** {}:{} ({}%)\".format(col,unique_count,int(((unique_count)/total)*100)))\n",
    "        else:\n",
    "            print(\"** {}:{}\".format(col,expand_categories(df[col])))\n",
    "            expand_categories(df[col])\n",
    "\n",
    "#analyze(path)\n",
    "\n",
    "\n",
    "# display 5 rows\n",
    "# df[0:5]\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "#Clean 'date' column and convert to Int type\n",
    "def clean_date(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_removed = s.replace(\" \", \"\")\n",
    "    s_int = int(s_removed)\n",
    "    return s_int\n",
    "\n",
    "########## CLEAN IP #######################\n",
    "def clean_ip(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_int = int(s)\n",
    "    return s_int\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "#MINMAX -1 1\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def min_max_1(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "#MINMAX 0 1\n",
    "def min_max_0(df, name, normalized_low=0, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "    \n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(\n",
    "        target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    # Regression\n",
    "    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)\n",
    "\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['srcip'] = df['srcip'].apply(clean_ip)\n",
    "df['dstip'] = df['dstip'].apply(clean_ip)\n",
    "\n",
    "df['sport'] = df['sport'].astype('int64')\n",
    "df['dsport'] = df['dsport'].astype('int64')\n",
    "\n",
    "# Now encode the feature vector\n",
    "\n",
    "min_max_0(df, 'srcip')#\n",
    "min_max_0(df, 'sport')\n",
    "\n",
    "min_max_0(df, 'dstip') #\n",
    "min_max_0(df, 'dsport')\n",
    "\n",
    "encode_text_dummy(df, 'proto') #\n",
    "encode_text_dummy(df, 'state')\n",
    "\n",
    "min_max_0(df, 'dur')\n",
    "\n",
    "min_max_0(df, 'sbyte') #\n",
    "min_max_0(df, 'dbytes')#\n",
    "min_max_0(df, 'sttl')#\n",
    "min_max_0(df, 'dttl')#\n",
    "min_max_0(df, 'sloss')#\n",
    "min_max_0(df, 'dloss')#\n",
    "encode_text_dummy(df, 'service') #\n",
    "min_max_0(df, 'Sload')\n",
    "\n",
    "min_max_0(df, 'Dload')\n",
    "\n",
    "min_max_0(df, 'Spkts')#\n",
    "min_max_0(df, 'Dpkts')#\n",
    "min_max_0(df, 'swin')#\n",
    "min_max_0(df, 'dwin')#\n",
    "min_max_0(df, 'stcpb')#\n",
    "min_max_0(df, 'dtcpb')#\n",
    "min_max_0(df, 'smeansz')#\n",
    "min_max_0(df, 'dmeansz')#\n",
    "min_max_0(df, 'trans')#\n",
    "min_max_0(df, 'res')#\n",
    "min_max_0(df, 'Sjit')#\n",
    "min_max_0(df, 'Djit')#\n",
    "\n",
    "min_max_0(df, 'Sintpkt')#\n",
    "min_max_0(df, 'Dintpkt')#\n",
    "min_max_0(df, 'tcprtt')#\n",
    "min_max_0(df, 'synack')#\n",
    "min_max_0(df, 'ackdat')#\n",
    "min_max_0(df, 'is_sm_ips_ports')#ojo\n",
    "min_max_0(df, 'ct_state_ttl')#\n",
    "min_max_0(df, 'ct_flw_http_mthd')#\n",
    "min_max_0(df, 'is_ftp_login')#ojo\n",
    "min_max_0(df, 'ct_ftp_cmd')#\n",
    "min_max_0(df, 'ct_srv_src')#\n",
    "min_max_0(df, 'ct_srv_dst')#\n",
    "min_max_0(df, 'ct_dst_ltm')#\n",
    "min_max_0(df, 'ct_src_ltm')\n",
    "\n",
    "min_max_0(df, 'ct_src_dport_ltm')#\n",
    "min_max_0(df, 'ct_dst_sport_lt')#\n",
    "min_max_0(df, 'ct_dst_src_ltm')#\n",
    "#encode_numeric_zscore(df, 'attack_cat')#\n",
    "encode_text_dummy(df, 'attack_cat')\n",
    "\n",
    "outcomes = encode_text_index(df, 'Label')#\n",
    "num_classes = len(outcomes)\n",
    "\n",
    "# display 5 rows\n",
    "\n",
    "#df.dropna(inplace=True,axis=1)\n",
    "df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srcip</th>\n",
       "      <th>sport</th>\n",
       "      <th>dstip</th>\n",
       "      <th>dsport</th>\n",
       "      <th>proto</th>\n",
       "      <th>state</th>\n",
       "      <th>dur</th>\n",
       "      <th>sbyte</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_lt</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [srcip, sport, dstip, dsport, proto, state, dur, sbyte, dbytes, sttl, dttl, sloss, dloss, service, Sload, Dload, Spkts, Dpkts, swin, dwin, stcpb, dtcpb, smeansz, dmeansz, trans, res, Sjit, Djit, Stime, Ltime, Sintpkt, Dintpkt, tcprtt, synack, ackdat, is_sm_ips_ports, ct_state_ttl, ct_flw_http_mthd, is_ftp_login, ct_ftp_cmd, ct_srv_src, ct_srv_dst, ct_dst_ltm, ct_src_ltm, ct_src_dport_ltm, ct_dst_sport_lt, ct_dst_src_ltm, attack_cat, Label]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 49 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0      1              2      3    4    5         6     7      8   \\\n",
      "0  59.166.0.0   6055  149.171.126.5  54145  tcp  FIN  0.072974  4238  60788   \n",
      "1  59.166.0.0   7832  149.171.126.3   5607  tcp  FIN  0.144951  5174  91072   \n",
      "2  59.166.0.8  11397  149.171.126.6     21  tcp  FIN  0.116107  2934   3742   \n",
      "\n",
      "   9   ...  39  40  41 42  43  44  45  46   47  48  \n",
      "0  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "1  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "2  31  ...   1   1   2  7   5   1   1   4  NaN   0  \n",
      "\n",
      "[3 rows x 49 columns]\n",
      "Read 700001 rows.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srcip</th>\n",
       "      <th>sport</th>\n",
       "      <th>dstip</th>\n",
       "      <th>proto</th>\n",
       "      <th>state</th>\n",
       "      <th>dur</th>\n",
       "      <th>sbyte</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_state_ttl</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_lt</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.166.0.0</td>\n",
       "      <td>6055</td>\n",
       "      <td>149.171.126.5</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.072974</td>\n",
       "      <td>4238</td>\n",
       "      <td>60788</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.166.0.0</td>\n",
       "      <td>7832</td>\n",
       "      <td>149.171.126.3</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.144951</td>\n",
       "      <td>5174</td>\n",
       "      <td>91072</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.166.0.8</td>\n",
       "      <td>11397</td>\n",
       "      <td>149.171.126.6</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.116107</td>\n",
       "      <td>2934</td>\n",
       "      <td>3742</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.166.0.0</td>\n",
       "      <td>3804</td>\n",
       "      <td>149.171.126.3</td>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.166.0.8</td>\n",
       "      <td>14339</td>\n",
       "      <td>149.171.126.6</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.038480</td>\n",
       "      <td>8928</td>\n",
       "      <td>320</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        srcip  sport          dstip proto state       dur  sbyte  dbytes  \\\n",
       "0  59.166.0.0   6055  149.171.126.5   tcp   FIN  0.072974   4238   60788   \n",
       "1  59.166.0.0   7832  149.171.126.3   tcp   FIN  0.144951   5174   91072   \n",
       "2  59.166.0.8  11397  149.171.126.6   tcp   FIN  0.116107   2934    3742   \n",
       "3  59.166.0.0   3804  149.171.126.3   udp   CON  0.000986    146     178   \n",
       "4  59.166.0.8  14339  149.171.126.6   tcp   FIN  0.038480   8928     320   \n",
       "\n",
       "   sttl  dttl  ...  ct_state_ttl  ct_ftp_cmd ct_srv_src  ct_srv_dst  \\\n",
       "0    31    29  ...             0           0         13          13   \n",
       "1    31    29  ...             0           0         13          13   \n",
       "2    31    29  ...             0           1          1           2   \n",
       "3    31    29  ...             0           0         13          13   \n",
       "4    31    29  ...             0           0          8          20   \n",
       "\n",
       "   ct_dst_ltm  ct_src_ltm  ct_src_dport_ltm  ct_dst_sport_lt  ct_dst_src_ltm  \\\n",
       "0           6           7                 1                1               2   \n",
       "1           6           7                 1                1               2   \n",
       "2           7           5                 1                1               4   \n",
       "3           6           7                 1                1               2   \n",
       "4           7           5                 1                1               4   \n",
       "\n",
       "   Label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import tensorflow.contrib.learn as skflow\n",
    "import string\n",
    "\n",
    "\n",
    "#from sklearn.utils.multiclass import unique_labels\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, average_precision_score, precision_recall_curve\n",
    "from inspect import signature\n",
    "%matplotlib inline\n",
    "\n",
    "path = \"UNSW-NB15_2.csv\"\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "df = pd.read_csv(path, header=None)\n",
    "print(df[0:3])\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    " # For now, just drop NA's (rows with missing values)\n",
    "\n",
    "# The CSV file has no column heads, so add them\n",
    "df.columns = [\n",
    "    'srcip',\n",
    "    'sport',\n",
    "    'dstip',\n",
    "    'dsport',\n",
    "    'proto',\n",
    "    'state',\n",
    "    'dur',\n",
    "    'sbyte',\n",
    "    'dbytes',\n",
    "    'sttl',\n",
    "    'dttl',\n",
    "    'sloss',\n",
    "    'dloss',\n",
    "    'service',\n",
    "    'Sload',\n",
    "    'Dload',\n",
    "    'Spkts',\n",
    "    'Dpkts',\n",
    "    'swin',\n",
    "    'dwin',\n",
    "    'stcpb',\n",
    "    'dtcpb',\n",
    "    'smeansz',\n",
    "    'dmeansz',\n",
    "    'trans',\n",
    "    'res',\n",
    "    'Sjit',\n",
    "    'Djit',\n",
    "    'Stime', #QUITAR\n",
    "    'Ltime', #QUITAR\n",
    "    'Sintpkt',\n",
    "    'Dintpkt',\n",
    "    'tcprtt',\n",
    "    'synack',\n",
    "    'ackdat',\n",
    "    'is_sm_ips_ports',\n",
    "    'ct_state_ttl',\n",
    "    'ct_flw_http_mthd',\n",
    "    'is_ftp_login',\n",
    "    'ct_ftp_cmd',\n",
    "    'ct_srv_src',\n",
    "    'ct_srv_dst',\n",
    "    'ct_dst_ltm',\n",
    "    'ct_src_ltm', \n",
    "    'ct_src_dport_ltm',\n",
    "    'ct_dst_sport_lt', \n",
    "    'ct_dst_src_ltm',\n",
    "    'attack_cat',\n",
    "    'Label'\n",
    "]\n",
    "\n",
    "df.dropna(inplace=True, axis=1)\n",
    "df[0:5]\n",
    "print(df[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 700001 rows.\n"
     ]
    }
   ],
   "source": [
    "print(\"Read {} rows.\".format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        srcip  sport          dstip proto state       dur  sbyte  dbytes  \\\n",
      "0  59.166.0.0   6055  149.171.126.5   tcp   FIN  0.072974   4238   60788   \n",
      "1  59.166.0.0   7832  149.171.126.3   tcp   FIN  0.144951   5174   91072   \n",
      "2  59.166.0.8  11397  149.171.126.6   tcp   FIN  0.116107   2934    3742   \n",
      "\n",
      "   sttl  dttl  ...  ct_state_ttl  ct_ftp_cmd ct_srv_src  ct_srv_dst  \\\n",
      "0    31    29  ...             0           0         13          13   \n",
      "1    31    29  ...             0           0         13          13   \n",
      "2    31    29  ...             0           1          1           2   \n",
      "\n",
      "   ct_dst_ltm  ct_src_ltm  ct_src_dport_ltm  ct_dst_sport_lt  ct_dst_src_ltm  \\\n",
      "0           6           7                 1                1               2   \n",
      "1           6           7                 1                1               2   \n",
      "2           7           5                 1                1               4   \n",
      "\n",
      "   Label  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "\n",
      "[3 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0      1              2      3    4    5         6     7      8   \\\n",
      "0  59.166.0.0   6055  149.171.126.5  54145  tcp  FIN  0.072974  4238  60788   \n",
      "1  59.166.0.0   7832  149.171.126.3   5607  tcp  FIN  0.144951  5174  91072   \n",
      "2  59.166.0.8  11397  149.171.126.6     21  tcp  FIN  0.116107  2934   3742   \n",
      "\n",
      "   9   ...  39  40  41 42  43  44  45  46   47  48  \n",
      "0  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "1  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "2  31  ...   1   1   2  7   5   1   1   4  NaN   0  \n",
      "\n",
      "[3 rows x 49 columns]\n",
      "Read 700001 rows.\n",
      "        srcip  sport          dstip dsport proto state       dur  sbyte  \\\n",
      "0  59.166.0.0   6055  149.171.126.5  54145   tcp   FIN  0.072974   4238   \n",
      "1  59.166.0.0   7832  149.171.126.3   5607   tcp   FIN  0.144951   5174   \n",
      "2  59.166.0.8  11397  149.171.126.6     21   tcp   FIN  0.116107   2934   \n",
      "\n",
      "   dbytes  sttl  ...  ct_ftp_cmd  ct_srv_src  ct_srv_dst ct_dst_ltm  \\\n",
      "0   60788    31  ...           0          13          13          6   \n",
      "1   91072    31  ...           0          13          13          6   \n",
      "2    3742    31  ...           1           1           2          7   \n",
      "\n",
      "   ct_src_ltm  ct_src_dport_ltm  ct_dst_sport_lt  ct_dst_src_ltm  attack_cat  \\\n",
      "0           7                 1                1               2         NaN   \n",
      "1           7                 1                1               2         NaN   \n",
      "2           5                 1                1               4         NaN   \n",
      "\n",
      "   Label  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "\n",
      "[3 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import tensorflow.contrib.learn as skflow\n",
    "import string\n",
    "\n",
    "\n",
    "#from sklearn.utils.multiclass import unique_labels\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, average_precision_score, precision_recall_curve\n",
    "from inspect import signature\n",
    "%matplotlib inline\n",
    "\n",
    "path = \"UNSW-NB15_2.csv\"\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "df = pd.read_csv(path, header=None)\n",
    "print(df[0:3])\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    " # For now, just drop NA's (rows with missing values)\n",
    "\n",
    "# The CSV file has no column heads, so add them\n",
    "df.columns = [\n",
    "    'srcip',\n",
    "    'sport',\n",
    "    'dstip',\n",
    "    'dsport',\n",
    "    'proto',\n",
    "    'state',\n",
    "    'dur',\n",
    "    'sbyte',\n",
    "    'dbytes',\n",
    "    'sttl',\n",
    "    'dttl',\n",
    "    'sloss',\n",
    "    'dloss',\n",
    "    'service',\n",
    "    'Sload',\n",
    "    'Dload',\n",
    "    'Spkts',\n",
    "    'Dpkts',\n",
    "    'swin',\n",
    "    'dwin',\n",
    "    'stcpb',\n",
    "    'dtcpb',\n",
    "    'smeansz',\n",
    "    'dmeansz',\n",
    "    'trans',\n",
    "    'res',\n",
    "    'Sjit',\n",
    "    'Djit',\n",
    "    'Stime', #QUITAR\n",
    "    'Ltime', #QUITAR\n",
    "    'Sintpkt',\n",
    "    'Dintpkt',\n",
    "    'tcprtt',\n",
    "    'synack',\n",
    "    'ackdat',\n",
    "    'is_sm_ips_ports',\n",
    "    'ct_state_ttl',\n",
    "    'ct_flw_http_mthd',\n",
    "    'is_ftp_login',\n",
    "    'ct_ftp_cmd',\n",
    "    'ct_srv_src',\n",
    "    'ct_srv_dst',\n",
    "    'ct_dst_ltm',\n",
    "    'ct_src_ltm', \n",
    "    'ct_src_dport_ltm',\n",
    "    'ct_dst_sport_lt', \n",
    "    'ct_dst_src_ltm',\n",
    "    'attack_cat',\n",
    "    'Label'\n",
    "]\n",
    "\n",
    "df.dropna(thresh=1)\n",
    "df[0:5]\n",
    "print(df[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0      1              2      3    4    5         6     7      8   \\\n",
      "0  59.166.0.0   6055  149.171.126.5  54145  tcp  FIN  0.072974  4238  60788   \n",
      "1  59.166.0.0   7832  149.171.126.3   5607  tcp  FIN  0.144951  5174  91072   \n",
      "2  59.166.0.8  11397  149.171.126.6     21  tcp  FIN  0.116107  2934   3742   \n",
      "\n",
      "   9   ...  39  40  41 42  43  44  45  46   47  48  \n",
      "0  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "1  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "2  31  ...   1   1   2  7   5   1   1   4  NaN   0  \n",
      "\n",
      "[3 rows x 49 columns]\n",
      "Read 700001 rows.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-b97925fe2048>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'srcip'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'srcip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_ip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dstip'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dstip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_ip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3590\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3591\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3593\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-b97925fe2048>\u001b[0m in \u001b[0;36mclean_ip\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;31m########## CLEAN IP #######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_ip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0ms_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ms_int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-b97925fe2048>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;31m########## CLEAN IP #######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_ip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0ms_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ms_int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import tensorflow.contrib.learn as skflow\n",
    "import string\n",
    "\n",
    "\n",
    "#from sklearn.utils.multiclass import unique_labels\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, average_precision_score, precision_recall_curve\n",
    "from inspect import signature\n",
    "%matplotlib inline\n",
    "\n",
    "path = \"UNSW-NB15_2.csv\"\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "df = pd.read_csv(path, header=None)\n",
    "print(df[0:3])\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    " # For now, just drop NA's (rows with missing values)\n",
    "\n",
    "# The CSV file has no column heads, so add them\n",
    "df.columns = [\n",
    "    'srcip',\n",
    "    'sport',\n",
    "    'dstip',\n",
    "    'dsport',\n",
    "    'proto',\n",
    "    'state',\n",
    "    'dur',\n",
    "    'sbyte',\n",
    "    'dbytes',\n",
    "    'sttl',\n",
    "    'dttl',\n",
    "    'sloss',\n",
    "    'dloss',\n",
    "    'service',\n",
    "    'Sload',\n",
    "    'Dload',\n",
    "    'Spkts',\n",
    "    'Dpkts',\n",
    "    'swin',\n",
    "    'dwin',\n",
    "    'stcpb',\n",
    "    'dtcpb',\n",
    "    'smeansz',\n",
    "    'dmeansz',\n",
    "    'trans',\n",
    "    'res',\n",
    "    'Sjit',\n",
    "    'Djit',\n",
    "    'Stime', #QUITAR\n",
    "    'Ltime', #QUITAR\n",
    "    'Sintpkt',\n",
    "    'Dintpkt',\n",
    "    'tcprtt',\n",
    "    'synack',\n",
    "    'ackdat',\n",
    "    'is_sm_ips_ports',\n",
    "    'ct_state_ttl',\n",
    "    'ct_flw_http_mthd',\n",
    "    'is_ftp_login',\n",
    "    'ct_ftp_cmd',\n",
    "    'ct_srv_src',\n",
    "    'ct_srv_dst',\n",
    "    'ct_dst_ltm',\n",
    "    'ct_src_ltm', \n",
    "    'ct_src_dport_ltm',\n",
    "    'ct_dst_sport_lt', \n",
    "    'ct_dst_src_ltm',\n",
    "    'attack_cat',\n",
    "    'Label'\n",
    "]\n",
    "\n",
    "df.dropna(thresh=1)\n",
    "df[0:5]\n",
    "\n",
    "# df.drop('sport', 1, inplace=True)#\n",
    "# df.drop('dsport', 1, inplace=True)#\n",
    "# df.drop('state', 1, inplace=True)#\n",
    "# df.drop('dur', 1, inplace=True)#\n",
    "# df.drop('Sload', 1, inplace=True)#\n",
    "# df.drop('Dload', 1, inplace=True)#\n",
    "# df.drop('Stime', 1, inplace=True)#\n",
    "# df.drop('Ltime', 1, inplace=True)#\n",
    "# df.drop('ct_src_ltm', 1, inplace=True)#\n",
    "\n",
    "ENCODING = 'utf-8'\n",
    "\n",
    "def expand_categories(values):\n",
    "    result = []\n",
    "    s = values.value_counts()\n",
    "    t = float(len(values))\n",
    "    for v in s.index:\n",
    "        result.append(\"{}:{}%\".format(v,round(100*(s[v]/t),2)))\n",
    "    return \"[{}]\".format(\",\".join(result))\n",
    "        \n",
    "def analyze(filename):\n",
    "    print()\n",
    "    print(\"Analyzing: {}\".format(filename))\n",
    "    df = pd.read_csv(filename,encoding=ENCODING)\n",
    "    cols = df.columns.values\n",
    "    total = float(len(df))\n",
    "\n",
    "    print(\"{} rows\".format(int(total)))\n",
    "    for col in cols:\n",
    "        uniques = df[col].unique()\n",
    "        unique_count = len(uniques)\n",
    "        if unique_count>100:\n",
    "            print(\"** {}:{} ({}%)\".format(col,unique_count,int(((unique_count)/total)*100)))\n",
    "        else:\n",
    "            print(\"** {}:{}\".format(col,expand_categories(df[col])))\n",
    "            expand_categories(df[col])\n",
    "\n",
    "#analyze(path)\n",
    "\n",
    "\n",
    "# display 5 rows\n",
    "# df[0:5]\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "#Clean 'date' column and convert to Int type\n",
    "def clean_date(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_removed = s.replace(\" \", \"\")\n",
    "    s_int = int(s_removed)\n",
    "    return s_int\n",
    "\n",
    "########## CLEAN IP #######################\n",
    "def clean_ip(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_int = int(s)\n",
    "    return s_int\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "#MINMAX -1 1\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def min_max_1(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "#MINMAX 0 1\n",
    "def min_max_0(df, name, normalized_low=0, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "    \n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(\n",
    "        target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    # Regression\n",
    "    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)\n",
    "\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['srcip'] = df['srcip'].apply(clean_ip)\n",
    "df['dstip'] = df['dstip'].apply(clean_ip)\n",
    "\n",
    "df['sport'] = df['sport'].astype('int64')\n",
    "df['dsport'] = df['dsport'].astype('int64')\n",
    "\n",
    "# Now encode the feature vector\n",
    "\n",
    "min_max_0(df, 'srcip')#\n",
    "min_max_0(df, 'sport')\n",
    "\n",
    "min_max_0(df, 'dstip') #\n",
    "min_max_0(df, 'dsport')\n",
    "\n",
    "encode_text_dummy(df, 'proto') #\n",
    "encode_text_dummy(df, 'state')\n",
    "\n",
    "min_max_0(df, 'dur')\n",
    "\n",
    "min_max_0(df, 'sbyte') #\n",
    "min_max_0(df, 'dbytes')#\n",
    "min_max_0(df, 'sttl')#\n",
    "min_max_0(df, 'dttl')#\n",
    "min_max_0(df, 'sloss')#\n",
    "min_max_0(df, 'dloss')#\n",
    "encode_text_dummy(df, 'service') #\n",
    "min_max_0(df, 'Sload')\n",
    "\n",
    "min_max_0(df, 'Dload')\n",
    "\n",
    "min_max_0(df, 'Spkts')#\n",
    "min_max_0(df, 'Dpkts')#\n",
    "min_max_0(df, 'swin')#\n",
    "min_max_0(df, 'dwin')#\n",
    "min_max_0(df, 'stcpb')#\n",
    "min_max_0(df, 'dtcpb')#\n",
    "min_max_0(df, 'smeansz')#\n",
    "min_max_0(df, 'dmeansz')#\n",
    "min_max_0(df, 'trans')#\n",
    "min_max_0(df, 'res')#\n",
    "min_max_0(df, 'Sjit')#\n",
    "min_max_0(df, 'Djit')#\n",
    "\n",
    "min_max_0(df, 'Sintpkt')#\n",
    "min_max_0(df, 'Dintpkt')#\n",
    "min_max_0(df, 'tcprtt')#\n",
    "min_max_0(df, 'synack')#\n",
    "min_max_0(df, 'ackdat')#\n",
    "min_max_0(df, 'is_sm_ips_ports')#ojo\n",
    "min_max_0(df, 'ct_state_ttl')#\n",
    "min_max_0(df, 'ct_flw_http_mthd')#\n",
    "min_max_0(df, 'is_ftp_login')#ojo\n",
    "min_max_0(df, 'ct_ftp_cmd')#\n",
    "min_max_0(df, 'ct_srv_src')#\n",
    "min_max_0(df, 'ct_srv_dst')#\n",
    "min_max_0(df, 'ct_dst_ltm')#\n",
    "min_max_0(df, 'ct_src_ltm')\n",
    "\n",
    "min_max_0(df, 'ct_src_dport_ltm')#\n",
    "min_max_0(df, 'ct_dst_sport_lt')#\n",
    "min_max_0(df, 'ct_dst_src_ltm')#\n",
    "#encode_numeric_zscore(df, 'attack_cat')#\n",
    "encode_text_dummy(df, 'attack_cat')\n",
    "\n",
    "outcomes = encode_text_index(df, 'Label')#\n",
    "num_classes = len(outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0      1              2      3    4    5         6     7      8   \\\n",
      "0  59.166.0.0   6055  149.171.126.5  54145  tcp  FIN  0.072974  4238  60788   \n",
      "1  59.166.0.0   7832  149.171.126.3   5607  tcp  FIN  0.144951  5174  91072   \n",
      "2  59.166.0.8  11397  149.171.126.6     21  tcp  FIN  0.116107  2934   3742   \n",
      "\n",
      "   9   ...  39  40  41 42  43  44  45  46   47  48  \n",
      "0  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "1  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "2  31  ...   1   1   2  7   5   1   1   4  NaN   0  \n",
      "\n",
      "[3 rows x 49 columns]\n",
      "Read 700001 rows.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-b97925fe2048>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sport'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sport'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dsport'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dsport'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;31m# Now encode the feature vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[1;32m   5689\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5690\u001b[0m             new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors,\n\u001b[0;32m-> 5691\u001b[0;31m                                          **kwargs)\n\u001b[0m\u001b[1;32m   5692\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'astype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                                             copy=align_copy)\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         return self._astype(dtype, copy=copy, errors=errors, values=values,\n\u001b[0;32m--> 534\u001b[0;31m                             **kwargs)\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     def _astype(self, dtype, copy=False, errors='raise', values=None,\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m_astype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                     \u001b[0;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m                     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0;31m# TODO(extension)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;31m# work around NumPy brokenness, #1987\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype_intsafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;31m# if we have a datetime/timedelta array of objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.astype_intsafe\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import tensorflow.contrib.learn as skflow\n",
    "import string\n",
    "\n",
    "\n",
    "#from sklearn.utils.multiclass import unique_labels\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, average_precision_score, precision_recall_curve\n",
    "from inspect import signature\n",
    "%matplotlib inline\n",
    "\n",
    "path = \"UNSW-NB15_2.csv\"\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "df = pd.read_csv(path, header=None)\n",
    "print(df[0:3])\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    " # For now, just drop NA's (rows with missing values)\n",
    "\n",
    "# The CSV file has no column heads, so add them\n",
    "df.columns = [\n",
    "    'srcip',\n",
    "    'sport',\n",
    "    'dstip',\n",
    "    'dsport',\n",
    "    'proto',\n",
    "    'state',\n",
    "    'dur',\n",
    "    'sbyte',\n",
    "    'dbytes',\n",
    "    'sttl',\n",
    "    'dttl',\n",
    "    'sloss',\n",
    "    'dloss',\n",
    "    'service',\n",
    "    'Sload',\n",
    "    'Dload',\n",
    "    'Spkts',\n",
    "    'Dpkts',\n",
    "    'swin',\n",
    "    'dwin',\n",
    "    'stcpb',\n",
    "    'dtcpb',\n",
    "    'smeansz',\n",
    "    'dmeansz',\n",
    "    'trans',\n",
    "    'res',\n",
    "    'Sjit',\n",
    "    'Djit',\n",
    "    'Stime', #QUITAR\n",
    "    'Ltime', #QUITAR\n",
    "    'Sintpkt',\n",
    "    'Dintpkt',\n",
    "    'tcprtt',\n",
    "    'synack',\n",
    "    'ackdat',\n",
    "    'is_sm_ips_ports',\n",
    "    'ct_state_ttl',\n",
    "    'ct_flw_http_mthd',\n",
    "    'is_ftp_login',\n",
    "    'ct_ftp_cmd',\n",
    "    'ct_srv_src',\n",
    "    'ct_srv_dst',\n",
    "    'ct_dst_ltm',\n",
    "    'ct_src_ltm', \n",
    "    'ct_src_dport_ltm',\n",
    "    'ct_dst_sport_lt', \n",
    "    'ct_dst_src_ltm',\n",
    "    'attack_cat',\n",
    "    'Label'\n",
    "]\n",
    "\n",
    "df.dropna(thresh=1)\n",
    "df[0:5]\n",
    "\n",
    "# df.drop('sport', 1, inplace=True)#\n",
    "# df.drop('dsport', 1, inplace=True)#\n",
    "# df.drop('state', 1, inplace=True)#\n",
    "# df.drop('dur', 1, inplace=True)#\n",
    "# df.drop('Sload', 1, inplace=True)#\n",
    "# df.drop('Dload', 1, inplace=True)#\n",
    "# df.drop('Stime', 1, inplace=True)#\n",
    "# df.drop('Ltime', 1, inplace=True)#\n",
    "# df.drop('ct_src_ltm', 1, inplace=True)#\n",
    "\n",
    "ENCODING = 'utf-8'\n",
    "\n",
    "def expand_categories(values):\n",
    "    result = []\n",
    "    s = values.value_counts()\n",
    "    t = float(len(values))\n",
    "    for v in s.index:\n",
    "        result.append(\"{}:{}%\".format(v,round(100*(s[v]/t),2)))\n",
    "    return \"[{}]\".format(\",\".join(result))\n",
    "        \n",
    "def analyze(filename):\n",
    "    print()\n",
    "    print(\"Analyzing: {}\".format(filename))\n",
    "    df = pd.read_csv(filename,encoding=ENCODING)\n",
    "    cols = df.columns.values\n",
    "    total = float(len(df))\n",
    "\n",
    "    print(\"{} rows\".format(int(total)))\n",
    "    for col in cols:\n",
    "        uniques = df[col].unique()\n",
    "        unique_count = len(uniques)\n",
    "        if unique_count>100:\n",
    "            print(\"** {}:{} ({}%)\".format(col,unique_count,int(((unique_count)/total)*100)))\n",
    "        else:\n",
    "            print(\"** {}:{}\".format(col,expand_categories(df[col])))\n",
    "            expand_categories(df[col])\n",
    "\n",
    "#analyze(path)\n",
    "\n",
    "\n",
    "# display 5 rows\n",
    "# df[0:5]\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "#Clean 'date' column and convert to Int type\n",
    "def clean_date(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_removed = s.replace(\" \", \"\")\n",
    "    s_int = int(s_removed)\n",
    "    return s_int\n",
    "\n",
    "########## CLEAN IP #######################\n",
    "def clean_ip(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_int = int(s)\n",
    "    return s_int\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "#MINMAX -1 1\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def min_max_1(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "#MINMAX 0 1\n",
    "def min_max_0(df, name, normalized_low=0, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "    \n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(\n",
    "        target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    # Regression\n",
    "    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)\n",
    "\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['srcip'] = df['srcip'].apply(clean_ip)\n",
    "df['dstip'] = df['dstip'].apply(clean_ip)\n",
    "\n",
    "df['sport'] = df['sport'].astype('int64')\n",
    "df['dsport'] = df['dsport'].astype('int64')\n",
    "\n",
    "# Now encode the feature vector\n",
    "\n",
    "min_max_0(df, 'srcip')#\n",
    "min_max_0(df, 'sport')\n",
    "\n",
    "min_max_0(df, 'dstip') #\n",
    "min_max_0(df, 'dsport')\n",
    "\n",
    "encode_text_dummy(df, 'proto') #\n",
    "encode_text_dummy(df, 'state')\n",
    "\n",
    "min_max_0(df, 'dur')\n",
    "\n",
    "min_max_0(df, 'sbyte') #\n",
    "min_max_0(df, 'dbytes')#\n",
    "min_max_0(df, 'sttl')#\n",
    "min_max_0(df, 'dttl')#\n",
    "min_max_0(df, 'sloss')#\n",
    "min_max_0(df, 'dloss')#\n",
    "encode_text_dummy(df, 'service') #\n",
    "min_max_0(df, 'Sload')\n",
    "\n",
    "min_max_0(df, 'Dload')\n",
    "\n",
    "min_max_0(df, 'Spkts')#\n",
    "min_max_0(df, 'Dpkts')#\n",
    "min_max_0(df, 'swin')#\n",
    "min_max_0(df, 'dwin')#\n",
    "min_max_0(df, 'stcpb')#\n",
    "min_max_0(df, 'dtcpb')#\n",
    "min_max_0(df, 'smeansz')#\n",
    "min_max_0(df, 'dmeansz')#\n",
    "min_max_0(df, 'trans')#\n",
    "min_max_0(df, 'res')#\n",
    "min_max_0(df, 'Sjit')#\n",
    "min_max_0(df, 'Djit')#\n",
    "\n",
    "min_max_0(df, 'Sintpkt')#\n",
    "min_max_0(df, 'Dintpkt')#\n",
    "min_max_0(df, 'tcprtt')#\n",
    "min_max_0(df, 'synack')#\n",
    "min_max_0(df, 'ackdat')#\n",
    "min_max_0(df, 'is_sm_ips_ports')#ojo\n",
    "min_max_0(df, 'ct_state_ttl')#\n",
    "min_max_0(df, 'ct_flw_http_mthd')#\n",
    "min_max_0(df, 'is_ftp_login')#ojo\n",
    "min_max_0(df, 'ct_ftp_cmd')#\n",
    "min_max_0(df, 'ct_srv_src')#\n",
    "min_max_0(df, 'ct_srv_dst')#\n",
    "min_max_0(df, 'ct_dst_ltm')#\n",
    "min_max_0(df, 'ct_src_ltm')\n",
    "\n",
    "min_max_0(df, 'ct_src_dport_ltm')#\n",
    "min_max_0(df, 'ct_dst_sport_lt')#\n",
    "min_max_0(df, 'ct_dst_src_ltm')#\n",
    "#encode_numeric_zscore(df, 'attack_cat')#\n",
    "encode_text_dummy(df, 'attack_cat')\n",
    "\n",
    "outcomes = encode_text_index(df, 'Label')#\n",
    "num_classes = len(outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0      1              2      3    4    5         6     7      8   \\\n",
      "0  59.166.0.0   6055  149.171.126.5  54145  tcp  FIN  0.072974  4238  60788   \n",
      "1  59.166.0.0   7832  149.171.126.3   5607  tcp  FIN  0.144951  5174  91072   \n",
      "2  59.166.0.8  11397  149.171.126.6     21  tcp  FIN  0.116107  2934   3742   \n",
      "\n",
      "   9   ...  39  40  41 42  43  44  45  46   47  48  \n",
      "0  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "1  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "2  31  ...   1   1   2  7   5   1   1   4  NaN   0  \n",
      "\n",
      "[3 rows x 49 columns]\n",
      "Read 700001 rows.\n",
      "        srcip  sport          dstip dsport proto state       dur  sbyte  \\\n",
      "0  59.166.0.0   6055  149.171.126.5  54145   tcp   FIN  0.072974   4238   \n",
      "1  59.166.0.0   7832  149.171.126.3   5607   tcp   FIN  0.144951   5174   \n",
      "2  59.166.0.8  11397  149.171.126.6     21   tcp   FIN  0.116107   2934   \n",
      "\n",
      "   dbytes  sttl  ...  ct_ftp_cmd  ct_srv_src  ct_srv_dst ct_dst_ltm  \\\n",
      "0   60788    31  ...           0          13          13          6   \n",
      "1   91072    31  ...           0          13          13          6   \n",
      "2    3742    31  ...           1           1           2          7   \n",
      "\n",
      "   ct_src_ltm  ct_src_dport_ltm  ct_dst_sport_lt  ct_dst_src_ltm  attack_cat  \\\n",
      "0           7                 1                1               2         NaN   \n",
      "1           7                 1                1               2         NaN   \n",
      "2           5                 1                1               4         NaN   \n",
      "\n",
      "   Label  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "\n",
      "[3 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import tensorflow.contrib.learn as skflow\n",
    "import string\n",
    "\n",
    "\n",
    "#from sklearn.utils.multiclass import unique_labels\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, average_precision_score, precision_recall_curve\n",
    "from inspect import signature\n",
    "%matplotlib inline\n",
    "\n",
    "path = \"UNSW-NB15_2.csv\"\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "df = pd.read_csv(path, header=None)\n",
    "print(df[0:3])\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    " # For now, just drop NA's (rows with missing values)\n",
    "df.dropna(thresh=1)\n",
    "# The CSV file has no column heads, so add them\n",
    "df.columns = [\n",
    "    'srcip',\n",
    "    'sport',\n",
    "    'dstip',\n",
    "    'dsport',\n",
    "    'proto',\n",
    "    'state',\n",
    "    'dur',\n",
    "    'sbyte',\n",
    "    'dbytes',\n",
    "    'sttl',\n",
    "    'dttl',\n",
    "    'sloss',\n",
    "    'dloss',\n",
    "    'service',\n",
    "    'Sload',\n",
    "    'Dload',\n",
    "    'Spkts',\n",
    "    'Dpkts',\n",
    "    'swin',\n",
    "    'dwin',\n",
    "    'stcpb',\n",
    "    'dtcpb',\n",
    "    'smeansz',\n",
    "    'dmeansz',\n",
    "    'trans',\n",
    "    'res',\n",
    "    'Sjit',\n",
    "    'Djit',\n",
    "    'Stime', #QUITAR\n",
    "    'Ltime', #QUITAR\n",
    "    'Sintpkt',\n",
    "    'Dintpkt',\n",
    "    'tcprtt',\n",
    "    'synack',\n",
    "    'ackdat',\n",
    "    'is_sm_ips_ports',\n",
    "    'ct_state_ttl',\n",
    "    'ct_flw_http_mthd',\n",
    "    'is_ftp_login',\n",
    "    'ct_ftp_cmd',\n",
    "    'ct_srv_src',\n",
    "    'ct_srv_dst',\n",
    "    'ct_dst_ltm',\n",
    "    'ct_src_ltm', \n",
    "    'ct_src_dport_ltm',\n",
    "    'ct_dst_sport_lt', \n",
    "    'ct_dst_src_ltm',\n",
    "    'attack_cat',\n",
    "    'Label'\n",
    "]\n",
    "\n",
    "df.dropna(thresh=1)\n",
    "print(df[0:3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        srcip  sport          dstip dsport proto state       dur  sbyte  \\\n",
      "0  59.166.0.0   6055  149.171.126.5  54145   tcp   FIN  0.072974   4238   \n",
      "1  59.166.0.0   7832  149.171.126.3   5607   tcp   FIN  0.144951   5174   \n",
      "2  59.166.0.8  11397  149.171.126.6     21   tcp   FIN  0.116107   2934   \n",
      "\n",
      "   dbytes  sttl  ...  ct_ftp_cmd  ct_srv_src  ct_srv_dst ct_dst_ltm  \\\n",
      "0   60788    31  ...           0          13          13          6   \n",
      "1   91072    31  ...           0          13          13          6   \n",
      "2    3742    31  ...           1           1           2          7   \n",
      "\n",
      "   ct_src_ltm  ct_src_dport_ltm  ct_dst_sport_lt  ct_dst_src_ltm  attack_cat  \\\n",
      "0           7                 1                1               2         NaN   \n",
      "1           7                 1                1               2         NaN   \n",
      "2           5                 1                1               4         NaN   \n",
      "\n",
      "   Label  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "\n",
      "[3 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "df.dropna(thresh=0)\n",
    "print(df[0:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        srcip  sport          dstip dsport proto state       dur  sbyte  \\\n",
      "0  59.166.0.0   6055  149.171.126.5  54145   tcp   FIN  0.072974   4238   \n",
      "1  59.166.0.0   7832  149.171.126.3   5607   tcp   FIN  0.144951   5174   \n",
      "2  59.166.0.8  11397  149.171.126.6     21   tcp   FIN  0.116107   2934   \n",
      "\n",
      "   dbytes  sttl  ...  ct_ftp_cmd  ct_srv_src  ct_srv_dst ct_dst_ltm  \\\n",
      "0   60788    31  ...           0          13          13          6   \n",
      "1   91072    31  ...           0          13          13          6   \n",
      "2    3742    31  ...           1           1           2          7   \n",
      "\n",
      "   ct_src_ltm  ct_src_dport_ltm  ct_dst_sport_lt  ct_dst_src_ltm  attack_cat  \\\n",
      "0           7                 1                1               2         NaN   \n",
      "1           7                 1                1               2         NaN   \n",
      "2           5                 1                1               4         NaN   \n",
      "\n",
      "   Label  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "\n",
      "[3 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "df.dropna(axis=0)\n",
    "print(df[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34300049"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700001, 49)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        srcip  sport          dstip dsport proto state       dur  sbyte  \\\n",
      "0  59.166.0.0   6055  149.171.126.5  54145   tcp   FIN  0.072974   4238   \n",
      "1  59.166.0.0   7832  149.171.126.3   5607   tcp   FIN  0.144951   5174   \n",
      "2  59.166.0.8  11397  149.171.126.6     21   tcp   FIN  0.116107   2934   \n",
      "\n",
      "   dbytes  sttl  ...  ct_ftp_cmd  ct_srv_src  ct_srv_dst ct_dst_ltm  \\\n",
      "0   60788    31  ...           0          13          13          6   \n",
      "1   91072    31  ...           0          13          13          6   \n",
      "2    3742    31  ...           1           1           2          7   \n",
      "\n",
      "   ct_src_ltm  ct_src_dport_ltm  ct_dst_sport_lt  ct_dst_src_ltm  attack_cat  \\\n",
      "0           7                 1                1               2         NaN   \n",
      "1           7                 1                1               2         NaN   \n",
      "2           5                 1                1               4         NaN   \n",
      "\n",
      "   Label  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "\n",
      "[3 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "df.dropna(axis=1)\n",
    "print(df[0:3])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        srcip  sport          dstip dsport proto state       dur  sbyte  \\\n",
      "0  59.166.0.0   6055  149.171.126.5  54145   tcp   FIN  0.072974   4238   \n",
      "1  59.166.0.0   7832  149.171.126.3   5607   tcp   FIN  0.144951   5174   \n",
      "2  59.166.0.8  11397  149.171.126.6     21   tcp   FIN  0.116107   2934   \n",
      "\n",
      "   dbytes  sttl  ...  ct_ftp_cmd  ct_srv_src  ct_srv_dst ct_dst_ltm  \\\n",
      "0   60788    31  ...           0          13          13          6   \n",
      "1   91072    31  ...           0          13          13          6   \n",
      "2    3742    31  ...           1           1           2          7   \n",
      "\n",
      "   ct_src_ltm  ct_src_dport_ltm  ct_dst_sport_lt  ct_dst_src_ltm  attack_cat  \\\n",
      "0           7                 1                1               2         NaN   \n",
      "1           7                 1                1               2         NaN   \n",
      "2           5                 1                1               4         NaN   \n",
      "\n",
      "   Label  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "\n",
      "[3 rows x 49 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(700001, 49)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True, axis=1)\n",
    "print(df[0:3])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        srcip  sport          dstip proto state       dur  sbyte  dbytes  \\\n",
      "0  59.166.0.0   6055  149.171.126.5   tcp   FIN  0.072974   4238   60788   \n",
      "1  59.166.0.0   7832  149.171.126.3   tcp   FIN  0.144951   5174   91072   \n",
      "2  59.166.0.8  11397  149.171.126.6   tcp   FIN  0.116107   2934    3742   \n",
      "\n",
      "   sttl  dttl  ...  ct_state_ttl  ct_ftp_cmd ct_srv_src  ct_srv_dst  \\\n",
      "0    31    29  ...             0           0         13          13   \n",
      "1    31    29  ...             0           0         13          13   \n",
      "2    31    29  ...             0           1          1           2   \n",
      "\n",
      "   ct_dst_ltm  ct_src_ltm  ct_src_dport_ltm  ct_dst_sport_lt  ct_dst_src_ltm  \\\n",
      "0           6           7                 1                1               2   \n",
      "1           6           7                 1                1               2   \n",
      "2           7           5                 1                1               4   \n",
      "\n",
      "   Label  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "\n",
      "[3 rows x 45 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(700001, 45)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True, axis=1)\n",
    "print(df[0:3])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0      1              2      3    4    5         6     7      8   \\\n",
      "0  59.166.0.0   6055  149.171.126.5  54145  tcp  FIN  0.072974  4238  60788   \n",
      "1  59.166.0.0   7832  149.171.126.3   5607  tcp  FIN  0.144951  5174  91072   \n",
      "2  59.166.0.8  11397  149.171.126.6     21  tcp  FIN  0.116107  2934   3742   \n",
      "\n",
      "   9   ...  39  40  41 42  43  44  45  46   47  48  \n",
      "0  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "1  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "2  31  ...   1   1   2  7   5   1   1   4  NaN   0  \n",
      "\n",
      "[3 rows x 49 columns]\n",
      "Read 700001 rows.\n",
      "        srcip  sport          dstip proto state       dur  sbyte  dbytes  \\\n",
      "0  59.166.0.0   6055  149.171.126.5   tcp   FIN  0.072974   4238   60788   \n",
      "1  59.166.0.0   7832  149.171.126.3   tcp   FIN  0.144951   5174   91072   \n",
      "2  59.166.0.8  11397  149.171.126.6   tcp   FIN  0.116107   2934    3742   \n",
      "\n",
      "   sttl  dttl  ...  ct_state_ttl  ct_ftp_cmd ct_srv_src  ct_srv_dst  \\\n",
      "0    31    29  ...             0           0         13          13   \n",
      "1    31    29  ...             0           0         13          13   \n",
      "2    31    29  ...             0           1          1           2   \n",
      "\n",
      "   ct_dst_ltm  ct_src_ltm  ct_src_dport_ltm  ct_dst_sport_lt  ct_dst_src_ltm  \\\n",
      "0           6           7                 1                1               2   \n",
      "1           6           7                 1                1               2   \n",
      "2           7           5                 1                1               4   \n",
      "\n",
      "   Label  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "\n",
      "[3 rows x 45 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(700001, 45)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import tensorflow.contrib.learn as skflow\n",
    "import string\n",
    "\n",
    "\n",
    "#from sklearn.utils.multiclass import unique_labels\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, average_precision_score, precision_recall_curve\n",
    "from inspect import signature\n",
    "%matplotlib inline\n",
    "\n",
    "path = \"UNSW-NB15_2.csv\"\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "df = pd.read_csv(path, header=None)\n",
    "print(df[0:3])\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    " # For now, just drop NA's (rows with missing values)\n",
    "#df.dropna(thresh=1)\n",
    "# The CSV file has no column heads, so add them\n",
    "df.columns = [\n",
    "    'srcip',\n",
    "    'sport',\n",
    "    'dstip',\n",
    "    'dsport',\n",
    "    'proto',\n",
    "    'state',\n",
    "    'dur',\n",
    "    'sbyte',\n",
    "    'dbytes',\n",
    "    'sttl',\n",
    "    'dttl',\n",
    "    'sloss',\n",
    "    'dloss',\n",
    "    'service',\n",
    "    'Sload',\n",
    "    'Dload',\n",
    "    'Spkts',\n",
    "    'Dpkts',\n",
    "    'swin',\n",
    "    'dwin',\n",
    "    'stcpb',\n",
    "    'dtcpb',\n",
    "    'smeansz',\n",
    "    'dmeansz',\n",
    "    'trans',\n",
    "    'res',\n",
    "    'Sjit',\n",
    "    'Djit',\n",
    "    'Stime', #QUITAR\n",
    "    'Ltime', #QUITAR\n",
    "    'Sintpkt',\n",
    "    'Dintpkt',\n",
    "    'tcprtt',\n",
    "    'synack',\n",
    "    'ackdat',\n",
    "    'is_sm_ips_ports',\n",
    "    'ct_state_ttl',\n",
    "    'ct_flw_http_mthd',\n",
    "    'is_ftp_login',\n",
    "    'ct_ftp_cmd',\n",
    "    'ct_srv_src',\n",
    "    'ct_srv_dst',\n",
    "    'ct_dst_ltm',\n",
    "    'ct_src_ltm', \n",
    "    'ct_src_dport_ltm',\n",
    "    'ct_dst_sport_lt', \n",
    "    'ct_dst_src_ltm',\n",
    "    'attack_cat',\n",
    "    'Label'\n",
    "]\n",
    "\n",
    "df.dropna(inplace=True, axis=1)\n",
    "print(df[0:3])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "srcip                object\n",
       "sport                 int64\n",
       "dstip                object\n",
       "proto                object\n",
       "state                object\n",
       "dur                 float64\n",
       "sbyte                 int64\n",
       "dbytes                int64\n",
       "sttl                  int64\n",
       "dttl                  int64\n",
       "sloss                 int64\n",
       "dloss                 int64\n",
       "service              object\n",
       "Sload               float64\n",
       "Dload               float64\n",
       "Spkts                 int64\n",
       "Dpkts                 int64\n",
       "swin                  int64\n",
       "dwin                  int64\n",
       "stcpb                 int64\n",
       "dtcpb                 int64\n",
       "smeansz               int64\n",
       "dmeansz               int64\n",
       "trans                 int64\n",
       "res                   int64\n",
       "Sjit                float64\n",
       "Djit                float64\n",
       "Stime                 int64\n",
       "Ltime                 int64\n",
       "Sintpkt             float64\n",
       "Dintpkt             float64\n",
       "tcprtt              float64\n",
       "synack              float64\n",
       "ackdat              float64\n",
       "is_sm_ips_ports       int64\n",
       "ct_state_ttl          int64\n",
       "ct_ftp_cmd           object\n",
       "ct_srv_src            int64\n",
       "ct_srv_dst            int64\n",
       "ct_dst_ltm            int64\n",
       "ct_src_ltm            int64\n",
       "ct_src_dport_ltm      int64\n",
       "ct_dst_sport_lt       int64\n",
       "ct_dst_src_ltm        int64\n",
       "Label                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-44dffda33ce2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'srcip'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'srcip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_ip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dstip'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dstip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_ip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3590\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3591\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3593\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-44dffda33ce2>\u001b[0m in \u001b[0;36mclean_ip\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m########## CLEAN IP #######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_ip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0ms_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ms_int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "ENCODING = 'utf-8'\n",
    "\n",
    "def expand_categories(values):\n",
    "    result = []\n",
    "    s = values.value_counts()\n",
    "    t = float(len(values))\n",
    "    for v in s.index:\n",
    "        result.append(\"{}:{}%\".format(v,round(100*(s[v]/t),2)))\n",
    "    return \"[{}]\".format(\",\".join(result))\n",
    "        \n",
    "def analyze(filename):\n",
    "    print()\n",
    "    print(\"Analyzing: {}\".format(filename))\n",
    "    df = pd.read_csv(filename,encoding=ENCODING)\n",
    "    cols = df.columns.values\n",
    "    total = float(len(df))\n",
    "\n",
    "    print(\"{} rows\".format(int(total)))\n",
    "    for col in cols:\n",
    "        uniques = df[col].unique()\n",
    "        unique_count = len(uniques)\n",
    "        if unique_count>100:\n",
    "            print(\"** {}:{} ({}%)\".format(col,unique_count,int(((unique_count)/total)*100)))\n",
    "        else:\n",
    "            print(\"** {}:{}\".format(col,expand_categories(df[col])))\n",
    "            expand_categories(df[col])\n",
    "\n",
    "#analyze(path)\n",
    "\n",
    "\n",
    "# display 5 rows\n",
    "# df[0:5]\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "#Clean 'date' column and convert to Int type\n",
    "def clean_date(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_removed = s.replace(\" \", \"\")\n",
    "    s_int = int(s_removed)\n",
    "    return s_int\n",
    "\n",
    "########## CLEAN IP #######################\n",
    "def clean_ip(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_int = int(s)\n",
    "    return s_int\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "#MINMAX -1 1\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def min_max_1(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "#MINMAX 0 1\n",
    "def min_max_0(df, name, normalized_low=0, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "    \n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(\n",
    "        target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    # Regression\n",
    "    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)\n",
    "\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['srcip'] = df['srcip'].apply(clean_ip)\n",
    "df['dstip'] = df['dstip'].apply(clean_ip)\n",
    "\n",
    "df['sport'] = df['sport'].astype('int64')\n",
    "df['dsport'] = df['dsport'].astype('int64')\n",
    "\n",
    "# Now encode the feature vector\n",
    "\n",
    "min_max_0(df, 'srcip')#\n",
    "min_max_0(df, 'sport')\n",
    "\n",
    "min_max_0(df, 'dstip') #\n",
    "#min_max_0(df, 'dsport')\n",
    "\n",
    "encode_text_dummy(df, 'proto') #\n",
    "encode_text_dummy(df, 'state')\n",
    "\n",
    "min_max_0(df, 'dur')\n",
    "\n",
    "min_max_0(df, 'sbyte') #\n",
    "min_max_0(df, 'dbytes')#\n",
    "min_max_0(df, 'sttl')#\n",
    "min_max_0(df, 'dttl')#\n",
    "min_max_0(df, 'sloss')#\n",
    "min_max_0(df, 'dloss')#\n",
    "encode_text_dummy(df, 'service') #\n",
    "min_max_0(df, 'Sload')\n",
    "\n",
    "min_max_0(df, 'Dload')\n",
    "\n",
    "min_max_0(df, 'Spkts')#\n",
    "min_max_0(df, 'Dpkts')#\n",
    "min_max_0(df, 'swin')#\n",
    "min_max_0(df, 'dwin')#\n",
    "min_max_0(df, 'stcpb')#\n",
    "min_max_0(df, 'dtcpb')#\n",
    "min_max_0(df, 'smeansz')#\n",
    "min_max_0(df, 'dmeansz')#\n",
    "min_max_0(df, 'trans')#\n",
    "min_max_0(df, 'res')#\n",
    "min_max_0(df, 'Sjit')#\n",
    "min_max_0(df, 'Djit')#\n",
    "\n",
    "min_max_0(df, 'Sintpkt')#\n",
    "min_max_0(df, 'Dintpkt')#\n",
    "min_max_0(df, 'tcprtt')#\n",
    "min_max_0(df, 'synack')#\n",
    "min_max_0(df, 'ackdat')#\n",
    "min_max_0(df, 'is_sm_ips_ports')#ojo\n",
    "min_max_0(df, 'ct_state_ttl')#\n",
    "#min_max_0(df, 'ct_flw_http_mthd')#\n",
    "#min_max_0(df, 'is_ftp_login')#ojo\n",
    "min_max_0(df, 'ct_ftp_cmd')#\n",
    "min_max_0(df, 'ct_srv_src')#\n",
    "min_max_0(df, 'ct_srv_dst')#\n",
    "min_max_0(df, 'ct_dst_ltm')#\n",
    "min_max_0(df, 'ct_src_ltm')\n",
    "\n",
    "min_max_0(df, 'ct_src_dport_ltm')#\n",
    "min_max_0(df, 'ct_dst_sport_lt')#\n",
    "min_max_0(df, 'ct_dst_src_ltm')#\n",
    "\n",
    "#encode_text_dummy(df, 'attack_cat')\n",
    "\n",
    "outcomes = encode_text_index(df, 'Label')#\n",
    "num_classes = len(outcomes)\n",
    "\n",
    "# display 5 rows\n",
    "\n",
    "#df.dropna(inplace=True,axis=1)\n",
    "df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0      1              2      3    4    5         6     7      8   \\\n",
      "0  59.166.0.0   6055  149.171.126.5  54145  tcp  FIN  0.072974  4238  60788   \n",
      "1  59.166.0.0   7832  149.171.126.3   5607  tcp  FIN  0.144951  5174  91072   \n",
      "2  59.166.0.8  11397  149.171.126.6     21  tcp  FIN  0.116107  2934   3742   \n",
      "\n",
      "   9   ...  39  40  41 42  43  44  45  46   47  48  \n",
      "0  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "1  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "2  31  ...   1   1   2  7   5   1   1   4  NaN   0  \n",
      "\n",
      "[3 rows x 49 columns]\n",
      "Read 700001 rows.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-1a998fb9fceb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;31m#min_max_0(df, 'ct_flw_http_mthd')#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;31m#min_max_0(df, 'is_ftp_login')#ojo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m \u001b[0mmin_max_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ct_ftp_cmd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0mmin_max_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ct_srv_src'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0mmin_max_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ct_srv_dst'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-1a998fb9fceb>\u001b[0m in \u001b[0;36mmin_max_0\u001b[0;34m(df, name, normalized_low, normalized_high, data_low, data_high)\u001b[0m\n\u001b[1;32m    174\u001b[0m                          data_low=None, data_high=None):\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_low\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mdata_low\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0mdata_high\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import tensorflow.contrib.learn as skflow\n",
    "import string\n",
    "\n",
    "\n",
    "#from sklearn.utils.multiclass import unique_labels\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, average_precision_score, precision_recall_curve\n",
    "from inspect import signature\n",
    "%matplotlib inline\n",
    "\n",
    "path = \"UNSW-NB15_2.csv\"\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "df = pd.read_csv(path, header=None)\n",
    "print(df[0:3])\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    " # For now, just drop NA's (rows with missing values)\n",
    "\n",
    "# The CSV file has no column heads, so add them\n",
    "df.columns = [\n",
    "    'srcip',\n",
    "    'sport',\n",
    "    'dstip',\n",
    "    'dsport',\n",
    "    'proto',\n",
    "    'state',\n",
    "    'dur',\n",
    "    'sbyte',\n",
    "    'dbytes',\n",
    "    'sttl',\n",
    "    'dttl',\n",
    "    'sloss',\n",
    "    'dloss',\n",
    "    'service',\n",
    "    'Sload',\n",
    "    'Dload',\n",
    "    'Spkts',\n",
    "    'Dpkts',\n",
    "    'swin',\n",
    "    'dwin',\n",
    "    'stcpb',\n",
    "    'dtcpb',\n",
    "    'smeansz',\n",
    "    'dmeansz',\n",
    "    'trans',\n",
    "    'res',\n",
    "    'Sjit',\n",
    "    'Djit',\n",
    "    'Stime', #QUITAR\n",
    "    'Ltime', #QUITAR\n",
    "    'Sintpkt',\n",
    "    'Dintpkt',\n",
    "    'tcprtt',\n",
    "    'synack',\n",
    "    'ackdat',\n",
    "    'is_sm_ips_ports',\n",
    "    'ct_state_ttl',\n",
    "    'ct_flw_http_mthd',\n",
    "    'is_ftp_login',\n",
    "    'ct_ftp_cmd',\n",
    "    'ct_srv_src',\n",
    "    'ct_srv_dst',\n",
    "    'ct_dst_ltm',\n",
    "    'ct_src_ltm', \n",
    "    'ct_src_dport_ltm',\n",
    "    'ct_dst_sport_lt', \n",
    "    'ct_dst_src_ltm',\n",
    "    'attack_cat',\n",
    "    'Label'\n",
    "]\n",
    "\n",
    "\n",
    "df[0:5]\n",
    "\n",
    "#df.drop('dsport', 1, inplace=True)#\n",
    "# df.drop('state', 1, inplace=True)#\n",
    "# df.drop('dur', 1, inplace=True)#\n",
    "# df.drop('Sload', 1, inplace=True)#\n",
    "# df.drop('Dload', 1, inplace=True)#\n",
    "# df.drop('Stime', 1, inplace=True)#\n",
    "# df.drop('Ltime', 1, inplace=True)#\n",
    "# df.drop('ct_src_ltm', 1, inplace=True)#\n",
    "\n",
    "ENCODING = 'utf-8'\n",
    "\n",
    "def expand_categories(values):\n",
    "    result = []\n",
    "    s = values.value_counts()\n",
    "    t = float(len(values))\n",
    "    for v in s.index:\n",
    "        result.append(\"{}:{}%\".format(v,round(100*(s[v]/t),2)))\n",
    "    return \"[{}]\".format(\",\".join(result))\n",
    "        \n",
    "def analyze(filename):\n",
    "    print()\n",
    "    print(\"Analyzing: {}\".format(filename))\n",
    "    df = pd.read_csv(filename,encoding=ENCODING)\n",
    "    cols = df.columns.values\n",
    "    total = float(len(df))\n",
    "\n",
    "    print(\"{} rows\".format(int(total)))\n",
    "    for col in cols:\n",
    "        uniques = df[col].unique()\n",
    "        unique_count = len(uniques)\n",
    "        if unique_count>100:\n",
    "            print(\"** {}:{} ({}%)\".format(col,unique_count,int(((unique_count)/total)*100)))\n",
    "        else:\n",
    "            print(\"** {}:{}\".format(col,expand_categories(df[col])))\n",
    "            expand_categories(df[col])\n",
    "\n",
    "#analyze(path)\n",
    "\n",
    "\n",
    "# display 5 rows\n",
    "# df[0:5]\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "#Clean 'date' column and convert to Int type\n",
    "def clean_date(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_removed = s.replace(\" \", \"\")\n",
    "    s_int = int(s_removed)\n",
    "    return s_int\n",
    "\n",
    "########## CLEAN IP #######################\n",
    "def clean_ip(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_int = int(s)\n",
    "    return s_int\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "#MINMAX -1 1\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def min_max_1(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "#MINMAX 0 1\n",
    "def min_max_0(df, name, normalized_low=0, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "    \n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(\n",
    "        target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    # Regression\n",
    "    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)\n",
    "\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['srcip'] = df['srcip'].apply(clean_ip)\n",
    "df['dstip'] = df['dstip'].apply(clean_ip)\n",
    "\n",
    "df['sport'] = df['sport'].astype('int64')\n",
    "#df['dsport'] = df['dsport'].astype('int64')\n",
    "\n",
    "# Now encode the feature vector\n",
    "\n",
    "min_max_0(df, 'srcip')#\n",
    "min_max_0(df, 'sport')\n",
    "\n",
    "min_max_0(df, 'dstip') #\n",
    "#min_max_0(df, 'dsport')\n",
    "\n",
    "encode_text_dummy(df, 'proto') #\n",
    "encode_text_dummy(df, 'state')\n",
    "\n",
    "min_max_0(df, 'dur')\n",
    "\n",
    "min_max_0(df, 'sbyte') #\n",
    "min_max_0(df, 'dbytes')#\n",
    "min_max_0(df, 'sttl')#\n",
    "min_max_0(df, 'dttl')#\n",
    "min_max_0(df, 'sloss')#\n",
    "min_max_0(df, 'dloss')#\n",
    "encode_text_dummy(df, 'service') #\n",
    "min_max_0(df, 'Sload')\n",
    "\n",
    "min_max_0(df, 'Dload')\n",
    "\n",
    "min_max_0(df, 'Spkts')#\n",
    "min_max_0(df, 'Dpkts')#\n",
    "min_max_0(df, 'swin')#\n",
    "min_max_0(df, 'dwin')#\n",
    "min_max_0(df, 'stcpb')#\n",
    "min_max_0(df, 'dtcpb')#\n",
    "min_max_0(df, 'smeansz')#\n",
    "min_max_0(df, 'dmeansz')#\n",
    "min_max_0(df, 'trans')#\n",
    "min_max_0(df, 'res')#\n",
    "min_max_0(df, 'Sjit')#\n",
    "min_max_0(df, 'Djit')#\n",
    "\n",
    "min_max_0(df, 'Sintpkt')#\n",
    "min_max_0(df, 'Dintpkt')#\n",
    "min_max_0(df, 'tcprtt')#\n",
    "min_max_0(df, 'synack')#\n",
    "min_max_0(df, 'ackdat')#\n",
    "min_max_0(df, 'is_sm_ips_ports')#ojo\n",
    "min_max_0(df, 'ct_state_ttl')#\n",
    "#min_max_0(df, 'ct_flw_http_mthd')#\n",
    "#min_max_0(df, 'is_ftp_login')#ojo\n",
    "min_max_0(df, 'ct_ftp_cmd')#\n",
    "min_max_0(df, 'ct_srv_src')#\n",
    "min_max_0(df, 'ct_srv_dst')#\n",
    "min_max_0(df, 'ct_dst_ltm')#\n",
    "min_max_0(df, 'ct_src_ltm')\n",
    "\n",
    "min_max_0(df, 'ct_src_dport_ltm')#\n",
    "min_max_0(df, 'ct_dst_sport_lt')#\n",
    "min_max_0(df, 'ct_dst_src_ltm')#\n",
    "\n",
    "#encode_text_dummy(df, 'attack_cat')\n",
    "\n",
    "outcomes = encode_text_index(df, 'Label')#\n",
    "num_classes = len(outcomes)\n",
    "\n",
    "# display 5 rows\n",
    "\n",
    "#df.dropna(inplace=True,axis=1)\n",
    "df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "srcip               float64\n",
       "sport               float64\n",
       "dstip               float64\n",
       "dsport               object\n",
       "dur                 float64\n",
       "sbyte               float64\n",
       "dbytes              float64\n",
       "sttl                float64\n",
       "dttl                float64\n",
       "sloss               float64\n",
       "dloss               float64\n",
       "Sload               float64\n",
       "Dload               float64\n",
       "Spkts               float64\n",
       "Dpkts               float64\n",
       "swin                float64\n",
       "dwin                float64\n",
       "stcpb               float64\n",
       "dtcpb               float64\n",
       "smeansz             float64\n",
       "dmeansz             float64\n",
       "trans               float64\n",
       "res                 float64\n",
       "Sjit                float64\n",
       "Djit                float64\n",
       "Stime                 int64\n",
       "Ltime                 int64\n",
       "Sintpkt             float64\n",
       "Dintpkt             float64\n",
       "tcprtt              float64\n",
       "                     ...   \n",
       "proto-xtp             uint8\n",
       "proto-zero            uint8\n",
       "state-ACC             uint8\n",
       "state-CLO             uint8\n",
       "state-CON             uint8\n",
       "state-ECO             uint8\n",
       "state-ECR             uint8\n",
       "state-FIN             uint8\n",
       "state-INT             uint8\n",
       "state-MAS             uint8\n",
       "state-PAR             uint8\n",
       "state-REQ             uint8\n",
       "state-RST             uint8\n",
       "state-TST             uint8\n",
       "state-TXD             uint8\n",
       "state-URN             uint8\n",
       "state-no              uint8\n",
       "service--             uint8\n",
       "service-dhcp          uint8\n",
       "service-dns           uint8\n",
       "service-ftp           uint8\n",
       "service-ftp-data      uint8\n",
       "service-http          uint8\n",
       "service-irc           uint8\n",
       "service-pop3          uint8\n",
       "service-radius        uint8\n",
       "service-smtp          uint8\n",
       "service-snmp          uint8\n",
       "service-ssh           uint8\n",
       "service-ssl           uint8\n",
       "Length: 208, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (3,39,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0      1              2      3    4    5         6     7      8   \\\n",
      "0  59.166.0.0   6055  149.171.126.5  54145  tcp  FIN  0.072974  4238  60788   \n",
      "1  59.166.0.0   7832  149.171.126.3   5607  tcp  FIN  0.144951  5174  91072   \n",
      "2  59.166.0.8  11397  149.171.126.6     21  tcp  FIN  0.116107  2934   3742   \n",
      "\n",
      "   9   ...  39  40  41 42  43  44  45  46   47  48  \n",
      "0  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "1  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "2  31  ...   1   1   2  7   5   1   1   4  NaN   0  \n",
      "\n",
      "[3 rows x 49 columns]\n",
      "Read 700001 rows.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "srcip                object\n",
       "sport                 int64\n",
       "dstip                object\n",
       "dsport               object\n",
       "proto                object\n",
       "state                object\n",
       "dur                 float64\n",
       "sbyte                 int64\n",
       "dbytes                int64\n",
       "sttl                  int64\n",
       "dttl                  int64\n",
       "sloss                 int64\n",
       "dloss                 int64\n",
       "service              object\n",
       "Sload               float64\n",
       "Dload               float64\n",
       "Spkts                 int64\n",
       "Dpkts                 int64\n",
       "swin                  int64\n",
       "dwin                  int64\n",
       "stcpb                 int64\n",
       "dtcpb                 int64\n",
       "smeansz               int64\n",
       "dmeansz               int64\n",
       "trans                 int64\n",
       "res                   int64\n",
       "Sjit                float64\n",
       "Djit                float64\n",
       "Stime                 int64\n",
       "Ltime                 int64\n",
       "Sintpkt             float64\n",
       "Dintpkt             float64\n",
       "tcprtt              float64\n",
       "synack              float64\n",
       "ackdat              float64\n",
       "is_sm_ips_ports       int64\n",
       "ct_state_ttl          int64\n",
       "ct_flw_http_mthd    float64\n",
       "is_ftp_login        float64\n",
       "ct_ftp_cmd           object\n",
       "ct_srv_src            int64\n",
       "ct_srv_dst            int64\n",
       "ct_dst_ltm            int64\n",
       "ct_src_ltm            int64\n",
       "ct_src_dport_ltm      int64\n",
       "ct_dst_sport_lt       int64\n",
       "ct_dst_src_ltm        int64\n",
       "attack_cat           object\n",
       "Label                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import tensorflow.contrib.learn as skflow\n",
    "import string\n",
    "\n",
    "\n",
    "#from sklearn.utils.multiclass import unique_labels\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, average_precision_score, precision_recall_curve\n",
    "from inspect import signature\n",
    "%matplotlib inline\n",
    "\n",
    "path = \"UNSW-NB15_2.csv\"\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "df = pd.read_csv(path, header=None)\n",
    "print(df[0:3])\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    " # For now, just drop NA's (rows with missing values)\n",
    "\n",
    "# The CSV file has no column heads, so add them\n",
    "df.columns = [\n",
    "    'srcip',\n",
    "    'sport',\n",
    "    'dstip',\n",
    "    'dsport',\n",
    "    'proto',\n",
    "    'state',\n",
    "    'dur',\n",
    "    'sbyte',\n",
    "    'dbytes',\n",
    "    'sttl',\n",
    "    'dttl',\n",
    "    'sloss',\n",
    "    'dloss',\n",
    "    'service',\n",
    "    'Sload',\n",
    "    'Dload',\n",
    "    'Spkts',\n",
    "    'Dpkts',\n",
    "    'swin',\n",
    "    'dwin',\n",
    "    'stcpb',\n",
    "    'dtcpb',\n",
    "    'smeansz',\n",
    "    'dmeansz',\n",
    "    'trans',\n",
    "    'res',\n",
    "    'Sjit',\n",
    "    'Djit',\n",
    "    'Stime', #QUITAR\n",
    "    'Ltime', #QUITAR\n",
    "    'Sintpkt',\n",
    "    'Dintpkt',\n",
    "    'tcprtt',\n",
    "    'synack',\n",
    "    'ackdat',\n",
    "    'is_sm_ips_ports',\n",
    "    'ct_state_ttl',\n",
    "    'ct_flw_http_mthd',\n",
    "    'is_ftp_login',\n",
    "    'ct_ftp_cmd',\n",
    "    'ct_srv_src',\n",
    "    'ct_srv_dst',\n",
    "    'ct_dst_ltm',\n",
    "    'ct_src_ltm', \n",
    "    'ct_src_dport_ltm',\n",
    "    'ct_dst_sport_lt', \n",
    "    'ct_dst_src_ltm',\n",
    "    'attack_cat',\n",
    "    'Label'\n",
    "]\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'min_text_dummy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-4858192512ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m#min_max_0(df, 'is_ftp_login')#ojo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;31m#min_max_0(df, 'ct_ftp_cmd')#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m \u001b[0mmin_text_dummy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ct_ftp_cmd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0mmin_max_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ct_srv_src'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0mmin_max_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ct_srv_dst'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'min_text_dummy' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "ENCODING = 'utf-8'\n",
    "\n",
    "def expand_categories(values):\n",
    "    result = []\n",
    "    s = values.value_counts()\n",
    "    t = float(len(values))\n",
    "    for v in s.index:\n",
    "        result.append(\"{}:{}%\".format(v,round(100*(s[v]/t),2)))\n",
    "    return \"[{}]\".format(\",\".join(result))\n",
    "        \n",
    "def analyze(filename):\n",
    "    print()\n",
    "    print(\"Analyzing: {}\".format(filename))\n",
    "    df = pd.read_csv(filename,encoding=ENCODING)\n",
    "    cols = df.columns.values\n",
    "    total = float(len(df))\n",
    "\n",
    "    print(\"{} rows\".format(int(total)))\n",
    "    for col in cols:\n",
    "        uniques = df[col].unique()\n",
    "        unique_count = len(uniques)\n",
    "        if unique_count>100:\n",
    "            print(\"** {}:{} ({}%)\".format(col,unique_count,int(((unique_count)/total)*100)))\n",
    "        else:\n",
    "            print(\"** {}:{}\".format(col,expand_categories(df[col])))\n",
    "            expand_categories(df[col])\n",
    "\n",
    "#analyze(path)\n",
    "\n",
    "\n",
    "# display 5 rows\n",
    "# df[0:5]\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "#Clean 'date' column and convert to Int type\n",
    "def clean_date(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_removed = s.replace(\" \", \"\")\n",
    "    s_int = int(s_removed)\n",
    "    return s_int\n",
    "\n",
    "########## CLEAN IP #######################\n",
    "def clean_ip(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_int = int(s)\n",
    "    return s_int\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "#MINMAX -1 1\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def min_max_1(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "#MINMAX 0 1\n",
    "def min_max_0(df, name, normalized_low=0, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "    \n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(\n",
    "        target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    # Regression\n",
    "    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)\n",
    "\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['srcip'] = df['srcip'].apply(clean_ip)\n",
    "df['dstip'] = df['dstip'].apply(clean_ip)\n",
    "\n",
    "df['sport'] = df['sport'].astype('int64')\n",
    "#df['dsport'] = df['dsport'].astype('int64')\n",
    "\n",
    "# Now encode the feature vector\n",
    "\n",
    "min_max_0(df, 'srcip')#\n",
    "min_max_0(df, 'sport')\n",
    "\n",
    "min_max_0(df, 'dstip') #\n",
    "#min_max_0(df, 'dsport')\n",
    "\n",
    "encode_text_dummy(df, 'proto') #\n",
    "encode_text_dummy(df, 'state')\n",
    "\n",
    "min_max_0(df, 'dur')\n",
    "\n",
    "min_max_0(df, 'sbyte') #\n",
    "min_max_0(df, 'dbytes')#\n",
    "min_max_0(df, 'sttl')#\n",
    "min_max_0(df, 'dttl')#\n",
    "min_max_0(df, 'sloss')#\n",
    "min_max_0(df, 'dloss')#\n",
    "encode_text_dummy(df, 'service') #\n",
    "min_max_0(df, 'Sload')\n",
    "\n",
    "min_max_0(df, 'Dload')\n",
    "\n",
    "min_max_0(df, 'Spkts')#\n",
    "min_max_0(df, 'Dpkts')#\n",
    "min_max_0(df, 'swin')#\n",
    "min_max_0(df, 'dwin')#\n",
    "min_max_0(df, 'stcpb')#\n",
    "min_max_0(df, 'dtcpb')#\n",
    "min_max_0(df, 'smeansz')#\n",
    "min_max_0(df, 'dmeansz')#\n",
    "min_max_0(df, 'trans')#\n",
    "min_max_0(df, 'res')#\n",
    "min_max_0(df, 'Sjit')#\n",
    "min_max_0(df, 'Djit')#\n",
    "\n",
    "min_max_0(df, 'Sintpkt')#\n",
    "min_max_0(df, 'Dintpkt')#\n",
    "min_max_0(df, 'tcprtt')#\n",
    "min_max_0(df, 'synack')#\n",
    "min_max_0(df, 'ackdat')#\n",
    "min_max_0(df, 'is_sm_ips_ports')#ojo\n",
    "min_max_0(df, 'ct_state_ttl')#\n",
    "#min_max_0(df, 'ct_flw_http_mthd')#\n",
    "#min_max_0(df, 'is_ftp_login')#ojo\n",
    "#min_max_0(df, 'ct_ftp_cmd')#\n",
    "min_text_dummy(df, 'ct_ftp_cmd')#\n",
    "min_max_0(df, 'ct_srv_src')#\n",
    "min_max_0(df, 'ct_srv_dst')#\n",
    "min_max_0(df, 'ct_dst_ltm')#\n",
    "min_max_0(df, 'ct_src_ltm')\n",
    "\n",
    "min_max_0(df, 'ct_src_dport_ltm')#\n",
    "min_max_0(df, 'ct_dst_sport_lt')#\n",
    "min_max_0(df, 'ct_dst_src_ltm')#\n",
    "\n",
    "#encode_text_dummy(df, 'attack_cat')\n",
    "\n",
    "outcomes = encode_text_index(df, 'Label')#\n",
    "num_classes = len(outcomes)\n",
    "\n",
    "# display 5 rows\n",
    "\n",
    "#df.dropna(inplace=True,axis=1)\n",
    "df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0      1              2      3    4    5         6     7      8   \\\n",
      "0  59.166.0.0   6055  149.171.126.5  54145  tcp  FIN  0.072974  4238  60788   \n",
      "1  59.166.0.0   7832  149.171.126.3   5607  tcp  FIN  0.144951  5174  91072   \n",
      "2  59.166.0.8  11397  149.171.126.6     21  tcp  FIN  0.116107  2934   3742   \n",
      "\n",
      "   9   ...  39  40  41 42  43  44  45  46   47  48  \n",
      "0  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "1  31  ...   0  13  13  6   7   1   1   2  NaN   0  \n",
      "2  31  ...   1   1   2  7   5   1   1   4  NaN   0  \n",
      "\n",
      "[3 rows x 49 columns]\n",
      "Read 700001 rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import tensorflow.contrib.learn as skflow\n",
    "import string\n",
    "\n",
    "\n",
    "#from sklearn.utils.multiclass import unique_labels\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, average_precision_score, precision_recall_curve\n",
    "from inspect import signature\n",
    "%matplotlib inline\n",
    "\n",
    "path = \"UNSW-NB15_2.csv\"\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "df = pd.read_csv(path, header=None)\n",
    "print(df[0:3])\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    " # For now, just drop NA's (rows with missing values)\n",
    "\n",
    "# The CSV file has no column heads, so add them\n",
    "df.columns = [\n",
    "    'srcip',\n",
    "    'sport',\n",
    "    'dstip',\n",
    "    'dsport',\n",
    "    'proto',\n",
    "    'state',\n",
    "    'dur',\n",
    "    'sbyte',\n",
    "    'dbytes',\n",
    "    'sttl',\n",
    "    'dttl',\n",
    "    'sloss',\n",
    "    'dloss',\n",
    "    'service',\n",
    "    'Sload',\n",
    "    'Dload',\n",
    "    'Spkts',\n",
    "    'Dpkts',\n",
    "    'swin',\n",
    "    'dwin',\n",
    "    'stcpb',\n",
    "    'dtcpb',\n",
    "    'smeansz',\n",
    "    'dmeansz',\n",
    "    'trans',\n",
    "    'res',\n",
    "    'Sjit',\n",
    "    'Djit',\n",
    "    'Stime', #QUITAR\n",
    "    'Ltime', #QUITAR\n",
    "    'Sintpkt',\n",
    "    'Dintpkt',\n",
    "    'tcprtt',\n",
    "    'synack',\n",
    "    'ackdat',\n",
    "    'is_sm_ips_ports',\n",
    "    'ct_state_ttl',\n",
    "    'ct_flw_http_mthd',\n",
    "    'is_ftp_login',\n",
    "    'ct_ftp_cmd',\n",
    "    'ct_srv_src',\n",
    "    'ct_srv_dst',\n",
    "    'ct_dst_ltm',\n",
    "    'ct_src_ltm', \n",
    "    'ct_src_dport_ltm',\n",
    "    'ct_dst_sport_lt', \n",
    "    'ct_dst_src_ltm',\n",
    "    'attack_cat',\n",
    "    'Label'\n",
    "]\n",
    "\n",
    "df[0:5]\n",
    "\n",
    "#df.drop('dsport', 1, inplace=True)#\n",
    "# df.drop('state', 1, inplace=True)#\n",
    "# df.drop('dur', 1, inplace=True)#\n",
    "# df.drop('Sload', 1, inplace=True)#\n",
    "# df.drop('Dload', 1, inplace=True)#\n",
    "df.drop('Stime', 1, inplace=True)#\n",
    "df.drop('Ltime', 1, inplace=True)#\n",
    "# df.drop('ct_src_ltm', 1, inplace=True)#\n",
    "\n",
    "ENCODING = 'utf-8'\n",
    "\n",
    "def expand_categories(values):\n",
    "    result = []\n",
    "    s = values.value_counts()\n",
    "    t = float(len(values))\n",
    "    for v in s.index:\n",
    "        result.append(\"{}:{}%\".format(v,round(100*(s[v]/t),2)))\n",
    "    return \"[{}]\".format(\",\".join(result))\n",
    "        \n",
    "def analyze(filename):\n",
    "    print()\n",
    "    print(\"Analyzing: {}\".format(filename))\n",
    "    df = pd.read_csv(filename,encoding=ENCODING)\n",
    "    cols = df.columns.values\n",
    "    total = float(len(df))\n",
    "\n",
    "    print(\"{} rows\".format(int(total)))\n",
    "    for col in cols:\n",
    "        uniques = df[col].unique()\n",
    "        unique_count = len(uniques)\n",
    "        if unique_count>100:\n",
    "            print(\"** {}:{} ({}%)\".format(col,unique_count,int(((unique_count)/total)*100)))\n",
    "        else:\n",
    "            print(\"** {}:{}\".format(col,expand_categories(df[col])))\n",
    "            expand_categories(df[col])\n",
    "\n",
    "#analyze(path)\n",
    "\n",
    "\n",
    "# display 5 rows\n",
    "# df[0:5]\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "#Clean 'date' column and convert to Int type\n",
    "def clean_date(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_removed = s.replace(\" \", \"\")\n",
    "    s_int = int(s_removed)\n",
    "    return s_int\n",
    "\n",
    "########## CLEAN IP #######################\n",
    "def clean_ip(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_int = int(s)\n",
    "    return s_int\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "#MINMAX -1 1\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def min_max_1(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "#MINMAX 0 1\n",
    "def min_max_0(df, name, normalized_low=0, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "    \n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(\n",
    "        target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    # Regression\n",
    "    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)\n",
    "\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['srcip'] = df['srcip'].apply(clean_ip)\n",
    "df['dstip'] = df['dstip'].apply(clean_ip)\n",
    "\n",
    "df['sport'] = df['sport'].astype('int64')\n",
    "#df['dsport'] = df['dsport'].astype('int64')\n",
    "\n",
    "# Now encode the feature vector\n",
    "\n",
    "min_max_0(df, 'srcip')#\n",
    "min_max_0(df, 'sport')\n",
    "\n",
    "min_max_0(df, 'dstip') #\n",
    "#min_max_0(df, 'dsport')\n",
    "\n",
    "encode_text_dummy(df, 'proto') #\n",
    "encode_text_dummy(df, 'state')\n",
    "\n",
    "min_max_0(df, 'dur')\n",
    "\n",
    "min_max_0(df, 'sbyte') #\n",
    "min_max_0(df, 'dbytes')#\n",
    "min_max_0(df, 'sttl')#\n",
    "min_max_0(df, 'dttl')#\n",
    "min_max_0(df, 'sloss')#\n",
    "min_max_0(df, 'dloss')#\n",
    "encode_text_dummy(df, 'service') #\n",
    "min_max_0(df, 'Sload')\n",
    "\n",
    "min_max_0(df, 'Dload')\n",
    "\n",
    "min_max_0(df, 'Spkts')#\n",
    "min_max_0(df, 'Dpkts')#\n",
    "min_max_0(df, 'swin')#\n",
    "min_max_0(df, 'dwin')#\n",
    "min_max_0(df, 'stcpb')#\n",
    "min_max_0(df, 'dtcpb')#\n",
    "min_max_0(df, 'smeansz')#\n",
    "min_max_0(df, 'dmeansz')#\n",
    "min_max_0(df, 'trans')#\n",
    "min_max_0(df, 'res')#\n",
    "min_max_0(df, 'Sjit')#\n",
    "min_max_0(df, 'Djit')#\n",
    "\n",
    "min_max_0(df, 'Sintpkt')#\n",
    "min_max_0(df, 'Dintpkt')#\n",
    "min_max_0(df, 'tcprtt')#\n",
    "min_max_0(df, 'synack')#\n",
    "min_max_0(df, 'ackdat')#\n",
    "min_max_0(df, 'is_sm_ips_ports')#ojo\n",
    "min_max_0(df, 'ct_state_ttl')#\n",
    "#min_max_0(df, 'ct_flw_http_mthd')#\n",
    "#min_max_0(df, 'is_ftp_login')#ojo\n",
    "#min_max_0(df, 'ct_ftp_cmd')#\n",
    "encode_text_dummy(df, 'ct_ftp_cmd')#\n",
    "min_max_0(df, 'ct_srv_src')#\n",
    "min_max_0(df, 'ct_srv_dst')#\n",
    "min_max_0(df, 'ct_dst_ltm')#\n",
    "min_max_0(df, 'ct_src_ltm')\n",
    "\n",
    "min_max_0(df, 'ct_src_dport_ltm')#\n",
    "min_max_0(df, 'ct_dst_sport_lt')#\n",
    "min_max_0(df, 'ct_dst_src_ltm')#\n",
    "\n",
    "#encode_text_dummy(df, 'attack_cat')\n",
    "\n",
    "outcomes = encode_text_index(df, 'Label')#\n",
    "num_classes = len(outcomes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '0xcc09'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-1dee63fe488f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-261d660c0515>\u001b[0m in \u001b[0;36mto_xy\u001b[0;34m(df, target)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;31m# Classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mdummies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m     \u001b[0;31m# Regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '0xcc09'"
     ]
    }
   ],
   "source": [
    "x, y = to_xy(df,'Label')\n",
    "#################################################\n",
    "\n",
    "\n",
    "\n",
    "# Create a test/train split.  25% test\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Create neural net\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(50, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(10, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "model.add(Dense(y.shape[1],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, verbose=1, mode='auto')\n",
    "history = model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2,epochs=1000)\n",
    "\n",
    "\n",
    "# Measure accuracy\n",
    "pred = model.predict(x_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "y_eval = np.argmax(y_test,axis=1)\n",
    "score = metrics.accuracy_score(y_eval, pred)\n",
    "print(\"Validation score: {}\".format(score))\n",
    "\n",
    "print(outcomes)\n",
    "\n",
    "### PLOT ACCURACY ####\n",
    "\n",
    "plt.plot(np.arange(len(history.history['acc'])),\n",
    "history.history['acc'], label='training')\n",
    "plt.plot(np.arange(len(history.history['val_acc'])),\n",
    "history.history['val_acc'], label='validation')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy ')\n",
    "plt.legend(loc=0)\n",
    "plt.show()\n",
    "\n",
    "### PLOT CONFUSION MATRIX ###\n",
    "\n",
    "# Not normalized\n",
    "cm = confusion_matrix(y_eval, pred)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, outcomes)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_normalized, outcomes, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### PLOT ROC ###\n",
    "\n",
    "#Plot an ROC. pred - the predictions, y - the expected outpus.\n",
    "#En mi caso creo que es pred == pred y== y_eval\n",
    "def plot_roc(pred, y):\n",
    "    fpr, tpr, _ = roc_curve(y, pred)\n",
    "    roc_auc = auc(fpr,tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "plot_roc(pred, y_eval)\n",
    "\n",
    "\n",
    "### PRECISION-RECALL ###\n",
    "\n",
    "average_precision = average_precision_score(y_eval, pred)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_eval, pred)\n",
    "\n",
    "# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srcip</th>\n",
       "      <th>sport</th>\n",
       "      <th>dstip</th>\n",
       "      <th>dsport</th>\n",
       "      <th>dur</th>\n",
       "      <th>sbyte</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sloss</th>\n",
       "      <th>...</th>\n",
       "      <th>service-radius</th>\n",
       "      <th>service-smtp</th>\n",
       "      <th>service-snmp</th>\n",
       "      <th>service-ssh</th>\n",
       "      <th>service-ssl</th>\n",
       "      <th>ct_ftp_cmd-0</th>\n",
       "      <th>ct_ftp_cmd-1</th>\n",
       "      <th>ct_ftp_cmd-2</th>\n",
       "      <th>ct_ftp_cmd-4</th>\n",
       "      <th>ct_ftp_cmd-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.092393</td>\n",
       "      <td>0.077615</td>\n",
       "      <td>54145</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.119509</td>\n",
       "      <td>0.077615</td>\n",
       "      <td>5607</td>\n",
       "      <td>0.002416</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.006213</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.173907</td>\n",
       "      <td>0.077615</td>\n",
       "      <td>21</td>\n",
       "      <td>0.001935</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.058045</td>\n",
       "      <td>0.077615</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.218799</td>\n",
       "      <td>0.077615</td>\n",
       "      <td>14724</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.596536</td>\n",
       "      <td>0.077615</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.165484</td>\n",
       "      <td>0.077615</td>\n",
       "      <td>5190</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.696452</td>\n",
       "      <td>0.077615</td>\n",
       "      <td>80</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.029465</td>\n",
       "      <td>0.077615</td>\n",
       "      <td>6881</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.037402</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.392523</td>\n",
       "      <td>0.077615</td>\n",
       "      <td>5190</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 210 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      srcip     sport     dstip dsport       dur     sbyte    dbytes  \\\n",
       "0  0.000327  0.092393  0.077615  54145  0.001216  0.000295  0.004147   \n",
       "1  0.000327  0.119509  0.077615   5607  0.002416  0.000360  0.006213   \n",
       "2  0.000327  0.173907  0.077615     21  0.001935  0.000204  0.000255   \n",
       "3  0.000327  0.058045  0.077615     53  0.000016  0.000010  0.000012   \n",
       "4  0.000327  0.218799  0.077615  14724  0.000641  0.000622  0.000022   \n",
       "5  0.000327  0.596536  0.077615     53  0.000017  0.000009  0.000011   \n",
       "6  0.000327  0.165484  0.077615   5190  0.000094  0.000074  0.000154   \n",
       "7  0.000327  0.696452  0.077615     80  0.000334  0.000072  0.000056   \n",
       "8  0.000327  0.029465  0.077615   6881  0.054600  0.000959  0.037402   \n",
       "9  0.000327  0.392523  0.077615   5190  0.002555  0.000089  0.000175   \n",
       "\n",
       "       sttl      dttl     sloss  ...  service-radius  service-smtp  \\\n",
       "0  0.121569  0.114173  0.001316  ...               0             0   \n",
       "1  0.121569  0.114173  0.001316  ...               0             0   \n",
       "2  0.121569  0.114173  0.002068  ...               0             0   \n",
       "3  0.121569  0.114173  0.000000  ...               0             0   \n",
       "4  0.121569  0.114173  0.000752  ...               0             0   \n",
       "5  0.121569  0.114173  0.000000  ...               0             0   \n",
       "6  0.121569  0.114173  0.000752  ...               0             0   \n",
       "7  0.121569  0.114173  0.000376  ...               0             0   \n",
       "8  0.121569  0.114173  0.003948  ...               0             0   \n",
       "9  0.121569  0.114173  0.000752  ...               0             0   \n",
       "\n",
       "   service-snmp  service-ssh  service-ssl  ct_ftp_cmd-0  ct_ftp_cmd-1  \\\n",
       "0             0            0            0             0             0   \n",
       "1             0            0            0             0             0   \n",
       "2             0            0            0             0             0   \n",
       "3             0            0            0             0             0   \n",
       "4             0            0            0             0             0   \n",
       "5             0            0            0             0             0   \n",
       "6             0            0            0             0             0   \n",
       "7             0            0            0             0             0   \n",
       "8             0            0            0             0             0   \n",
       "9             0            0            0             0             0   \n",
       "\n",
       "   ct_ftp_cmd-2  ct_ftp_cmd-4  ct_ftp_cmd-   \n",
       "0             0             0             0  \n",
       "1             0             0             0  \n",
       "2             0             0             0  \n",
       "3             0             0             0  \n",
       "4             0             0             0  \n",
       "5             0             0             0  \n",
       "6             0             0             0  \n",
       "7             0             0             0  \n",
       "8             0             0             0  \n",
       "9             0             0             0  \n",
       "\n",
       "[10 rows x 210 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (1,3,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0      1              2     3    4    5         6    7    8   9   \\\n",
      "0  59.166.0.0   1390  149.171.126.6    53  udp  CON  0.001055  132  164  31   \n",
      "1  59.166.0.0  33661  149.171.126.9  1024  udp  CON  0.036133  528  304  31   \n",
      "2  59.166.0.6   1464  149.171.126.7    53  udp  CON  0.001119  146  178  31   \n",
      "\n",
      "   ...  39  40  41 42  43  44  45  46   47  48  \n",
      "0  ...   0   3   7  1   3   1   1   1  NaN   0  \n",
      "1  ...   0   2   4  2   3   1   1   2  NaN   0  \n",
      "2  ...   0  12   8  1   2   2   1   1  NaN   0  \n",
      "\n",
      "[3 rows x 49 columns]\n",
      "Read 700001 rows.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '0x000b'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-7e09e8ee5905>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dstip'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dstip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_ip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sport'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sport'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;31m#df['dsport'] = df['dsport'].astype('int64')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[1;32m   5689\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5690\u001b[0m             new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors,\n\u001b[0;32m-> 5691\u001b[0;31m                                          **kwargs)\n\u001b[0m\u001b[1;32m   5692\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'astype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                                             copy=align_copy)\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         return self._astype(dtype, copy=copy, errors=errors, values=values,\n\u001b[0;32m--> 534\u001b[0;31m                             **kwargs)\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     def _astype(self, dtype, copy=False, errors='raise', values=None,\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m_astype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                     \u001b[0;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m                     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0;31m# TODO(extension)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;31m# work around NumPy brokenness, #1987\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype_intsafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;31m# if we have a datetime/timedelta array of objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.astype_intsafe\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '0x000b'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import tensorflow.contrib.learn as skflow\n",
    "import string\n",
    "\n",
    "\n",
    "#from sklearn.utils.multiclass import unique_labels\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, average_precision_score, precision_recall_curve\n",
    "from inspect import signature\n",
    "#%matplotlib inline\n",
    "\n",
    "path = \"UNSW-NB15_1.csv\"\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "df = pd.read_csv(path, header=None)\n",
    "print(df[0:3])\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    " # For now, just drop NA's (rows with missing values)\n",
    "\n",
    "# The CSV file has no column heads, so add them\n",
    "df.columns = [\n",
    "    'srcip',\n",
    "    'sport',\n",
    "    'dstip',\n",
    "    'dsport',\n",
    "    'proto',\n",
    "    'state',\n",
    "    'dur',\n",
    "    'sbyte',\n",
    "    'dbytes',\n",
    "    'sttl',\n",
    "    'dttl',\n",
    "    'sloss',\n",
    "    'dloss',\n",
    "    'service',\n",
    "    'Sload',\n",
    "    'Dload',\n",
    "    'Spkts',\n",
    "    'Dpkts',\n",
    "    'swin',\n",
    "    'dwin',\n",
    "    'stcpb',\n",
    "    'dtcpb',\n",
    "    'smeansz',\n",
    "    'dmeansz',\n",
    "    'trans',\n",
    "    'res',\n",
    "    'Sjit',\n",
    "    'Djit',\n",
    "    'Stime', #QUITAR\n",
    "    'Ltime', #QUITAR\n",
    "    'Sintpkt',\n",
    "    'Dintpkt',\n",
    "    'tcprtt',\n",
    "    'synack',\n",
    "    'ackdat',\n",
    "    'is_sm_ips_ports',\n",
    "    'ct_state_ttl',\n",
    "    'ct_flw_http_mthd',\n",
    "    'is_ftp_login',\n",
    "    'ct_ftp_cmd',\n",
    "    'ct_srv_src',\n",
    "    'ct_srv_dst',\n",
    "    'ct_dst_ltm',\n",
    "    'ct_src_ltm', \n",
    "    'ct_src_dport_ltm',\n",
    "    'ct_dst_sport_lt', \n",
    "    'ct_dst_src_ltm',\n",
    "    'attack_cat',\n",
    "    'Label'\n",
    "]\n",
    "\n",
    "df[0:5]\n",
    "\n",
    "#df.drop('dsport', 1, inplace=True)#\n",
    "# df.drop('state', 1, inplace=True)#\n",
    "# df.drop('dur', 1, inplace=True)#\n",
    "# df.drop('Sload', 1, inplace=True)#\n",
    "# df.drop('Dload', 1, inplace=True)#\n",
    "df.drop('Stime', 1, inplace=True)#\n",
    "df.drop('Ltime', 1, inplace=True)#\n",
    "# df.drop('ct_src_ltm', 1, inplace=True)#\n",
    "\n",
    "ENCODING = 'utf-8'\n",
    "\n",
    "def expand_categories(values):\n",
    "    result = []\n",
    "    s = values.value_counts()\n",
    "    t = float(len(values))\n",
    "    for v in s.index:\n",
    "        result.append(\"{}:{}%\".format(v,round(100*(s[v]/t),2)))\n",
    "    return \"[{}]\".format(\",\".join(result))\n",
    "        \n",
    "def analyze(filename):\n",
    "    print()\n",
    "    print(\"Analyzing: {}\".format(filename))\n",
    "    df = pd.read_csv(filename,encoding=ENCODING)\n",
    "    cols = df.columns.values\n",
    "    total = float(len(df))\n",
    "\n",
    "    print(\"{} rows\".format(int(total)))\n",
    "    for col in cols:\n",
    "        uniques = df[col].unique()\n",
    "        unique_count = len(uniques)\n",
    "        if unique_count>100:\n",
    "            print(\"** {}:{} ({}%)\".format(col,unique_count,int(((unique_count)/total)*100)))\n",
    "        else:\n",
    "            print(\"** {}:{}\".format(col,expand_categories(df[col])))\n",
    "            expand_categories(df[col])\n",
    "\n",
    "#analyze(path)\n",
    "\n",
    "\n",
    "# display 5 rows\n",
    "# df[0:5]\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "#Clean 'date' column and convert to Int type\n",
    "def clean_date(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_removed = s.replace(\" \", \"\")\n",
    "    s_int = int(s_removed)\n",
    "    return s_int\n",
    "\n",
    "########## CLEAN IP #######################\n",
    "def clean_ip(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_int = int(s)\n",
    "    return s_int\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "#MINMAX -1 1\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def min_max_1(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "#MINMAX 0 1\n",
    "def min_max_0(df, name, normalized_low=0, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "    \n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(\n",
    "        target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    # Regression\n",
    "    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)\n",
    "\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['srcip'] = df['srcip'].apply(clean_ip)\n",
    "df['dstip'] = df['dstip'].apply(clean_ip)\n",
    "\n",
    "df['sport'] = df['sport'].astype('int64')\n",
    "#df['dsport'] = df['dsport'].astype('int64')\n",
    "\n",
    "# Now encode the feature vector\n",
    "\n",
    "min_max_0(df, 'srcip')#\n",
    "min_max_0(df, 'sport')\n",
    "\n",
    "min_max_0(df, 'dstip') #\n",
    "#min_max_0(df, 'dsport')\n",
    "\n",
    "encode_text_dummy(df, 'proto') #\n",
    "encode_text_dummy(df, 'state')\n",
    "\n",
    "min_max_0(df, 'dur')\n",
    "\n",
    "min_max_0(df, 'sbyte') #\n",
    "min_max_0(df, 'dbytes')#\n",
    "min_max_0(df, 'sttl')#\n",
    "min_max_0(df, 'dttl')#\n",
    "min_max_0(df, 'sloss')#\n",
    "min_max_0(df, 'dloss')#\n",
    "encode_text_dummy(df, 'service') #\n",
    "min_max_0(df, 'Sload')\n",
    "\n",
    "min_max_0(df, 'Dload')\n",
    "\n",
    "min_max_0(df, 'Spkts')#\n",
    "min_max_0(df, 'Dpkts')#\n",
    "min_max_0(df, 'swin')#\n",
    "min_max_0(df, 'dwin')#\n",
    "min_max_0(df, 'stcpb')#\n",
    "min_max_0(df, 'dtcpb')#\n",
    "min_max_0(df, 'smeansz')#\n",
    "min_max_0(df, 'dmeansz')#\n",
    "min_max_0(df, 'trans')#\n",
    "min_max_0(df, 'res')#\n",
    "min_max_0(df, 'Sjit')#\n",
    "min_max_0(df, 'Djit')#\n",
    "\n",
    "min_max_0(df, 'Sintpkt')#\n",
    "min_max_0(df, 'Dintpkt')#\n",
    "min_max_0(df, 'tcprtt')#\n",
    "min_max_0(df, 'synack')#\n",
    "min_max_0(df, 'ackdat')#\n",
    "min_max_0(df, 'is_sm_ips_ports')#ojo\n",
    "min_max_0(df, 'ct_state_ttl')#\n",
    "#min_max_0(df, 'ct_flw_http_mthd')#\n",
    "#min_max_0(df, 'is_ftp_login')#ojo\n",
    "#min_max_0(df, 'ct_ftp_cmd')#\n",
    "encode_text_dummy(df, 'ct_ftp_cmd')#\n",
    "min_max_0(df, 'ct_srv_src')#\n",
    "min_max_0(df, 'ct_srv_dst')#\n",
    "min_max_0(df, 'ct_dst_ltm')#\n",
    "min_max_0(df, 'ct_src_ltm')\n",
    "\n",
    "min_max_0(df, 'ct_src_dport_ltm')#\n",
    "min_max_0(df, 'ct_dst_sport_lt')#\n",
    "min_max_0(df, 'ct_dst_src_ltm')#\n",
    "\n",
    "#encode_text_dummy(df, 'attack_cat')\n",
    "\n",
    "outcomes = encode_text_index(df, 'Label')#\n",
    "num_classes = len(outcomes)\n",
    "\n",
    "# display 5 rows\n",
    "\n",
    "#df.dropna(inplace=True,axis=1)\n",
    "df[0:10]\n",
    "\n",
    "\n",
    "##################################################\n",
    "# Break into X (predictors) & y (prediction)\n",
    "x, y = to_xy(df,'Label')\n",
    "#################################################\n",
    "\n",
    "\n",
    "\n",
    "# Create a test/train split.  25% test\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Create neural net\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(50, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(10, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "model.add(Dense(y.shape[1],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, verbose=1, mode='auto')\n",
    "history = model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2,epochs=1000)\n",
    "\n",
    "\n",
    "# Measure accuracy\n",
    "pred = model.predict(x_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "y_eval = np.argmax(y_test,axis=1)\n",
    "score = metrics.accuracy_score(y_eval, pred)\n",
    "print(\"Validation score: {}\".format(score))\n",
    "\n",
    "print(outcomes)\n",
    "\n",
    "### PLOT ACCURACY ####\n",
    "\n",
    "plt.plot(np.arange(len(history.history['acc'])),\n",
    "history.history['acc'], label='training')\n",
    "plt.plot(np.arange(len(history.history['val_acc'])),\n",
    "history.history['val_acc'], label='validation')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy ')\n",
    "plt.legend(loc=0)\n",
    "plt.show()\n",
    "\n",
    "### PLOT CONFUSION MATRIX ###\n",
    "\n",
    "# Not normalized\n",
    "cm = confusion_matrix(y_eval, pred)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, outcomes)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_normalized, outcomes, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### PLOT ROC ###\n",
    "\n",
    "#Plot an ROC. pred - the predictions, y - the expected outpus.\n",
    "#En mi caso creo que es pred == pred y== y_eval\n",
    "def plot_roc(pred, y):\n",
    "    fpr, tpr, _ = roc_curve(y, pred)\n",
    "    roc_auc = auc(fpr,tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "plot_roc(pred, y_eval)\n",
    "\n",
    "\n",
    "### PRECISION-RECALL ###\n",
    "\n",
    "average_precision = average_precision_score(y_eval, pred)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_eval, pred)\n",
    "\n",
    "# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srcip</th>\n",
       "      <th>sport</th>\n",
       "      <th>dstip</th>\n",
       "      <th>dsport</th>\n",
       "      <th>dur</th>\n",
       "      <th>sbyte</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sloss</th>\n",
       "      <th>...</th>\n",
       "      <th>service-radius</th>\n",
       "      <th>service-smtp</th>\n",
       "      <th>service-snmp</th>\n",
       "      <th>service-ssh</th>\n",
       "      <th>service-ssl</th>\n",
       "      <th>ct_ftp_cmd-0</th>\n",
       "      <th>ct_ftp_cmd-1</th>\n",
       "      <th>ct_ftp_cmd-2</th>\n",
       "      <th>ct_ftp_cmd-4</th>\n",
       "      <th>ct_ftp_cmd-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.092393</td>\n",
       "      <td>0.077615</td>\n",
       "      <td>54145</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.119509</td>\n",
       "      <td>0.077615</td>\n",
       "      <td>5607</td>\n",
       "      <td>0.002416</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.006213</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.173907</td>\n",
       "      <td>0.077615</td>\n",
       "      <td>21</td>\n",
       "      <td>0.001935</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.058045</td>\n",
       "      <td>0.077615</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.218799</td>\n",
       "      <td>0.077615</td>\n",
       "      <td>14724</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.596536</td>\n",
       "      <td>0.077615</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.165484</td>\n",
       "      <td>0.077615</td>\n",
       "      <td>5190</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.696452</td>\n",
       "      <td>0.077615</td>\n",
       "      <td>80</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.029465</td>\n",
       "      <td>0.077615</td>\n",
       "      <td>6881</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.037402</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.392523</td>\n",
       "      <td>0.077615</td>\n",
       "      <td>5190</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>0.114173</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 210 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      srcip     sport     dstip dsport       dur     sbyte    dbytes  \\\n",
       "0  0.000327  0.092393  0.077615  54145  0.001216  0.000295  0.004147   \n",
       "1  0.000327  0.119509  0.077615   5607  0.002416  0.000360  0.006213   \n",
       "2  0.000327  0.173907  0.077615     21  0.001935  0.000204  0.000255   \n",
       "3  0.000327  0.058045  0.077615     53  0.000016  0.000010  0.000012   \n",
       "4  0.000327  0.218799  0.077615  14724  0.000641  0.000622  0.000022   \n",
       "5  0.000327  0.596536  0.077615     53  0.000017  0.000009  0.000011   \n",
       "6  0.000327  0.165484  0.077615   5190  0.000094  0.000074  0.000154   \n",
       "7  0.000327  0.696452  0.077615     80  0.000334  0.000072  0.000056   \n",
       "8  0.000327  0.029465  0.077615   6881  0.054600  0.000959  0.037402   \n",
       "9  0.000327  0.392523  0.077615   5190  0.002555  0.000089  0.000175   \n",
       "\n",
       "       sttl      dttl     sloss  ...  service-radius  service-smtp  \\\n",
       "0  0.121569  0.114173  0.001316  ...               0             0   \n",
       "1  0.121569  0.114173  0.001316  ...               0             0   \n",
       "2  0.121569  0.114173  0.002068  ...               0             0   \n",
       "3  0.121569  0.114173  0.000000  ...               0             0   \n",
       "4  0.121569  0.114173  0.000752  ...               0             0   \n",
       "5  0.121569  0.114173  0.000000  ...               0             0   \n",
       "6  0.121569  0.114173  0.000752  ...               0             0   \n",
       "7  0.121569  0.114173  0.000376  ...               0             0   \n",
       "8  0.121569  0.114173  0.003948  ...               0             0   \n",
       "9  0.121569  0.114173  0.000752  ...               0             0   \n",
       "\n",
       "   service-snmp  service-ssh  service-ssl  ct_ftp_cmd-0  ct_ftp_cmd-1  \\\n",
       "0             0            0            0             0             0   \n",
       "1             0            0            0             0             0   \n",
       "2             0            0            0             0             0   \n",
       "3             0            0            0             0             0   \n",
       "4             0            0            0             0             0   \n",
       "5             0            0            0             0             0   \n",
       "6             0            0            0             0             0   \n",
       "7             0            0            0             0             0   \n",
       "8             0            0            0             0             0   \n",
       "9             0            0            0             0             0   \n",
       "\n",
       "   ct_ftp_cmd-2  ct_ftp_cmd-4  ct_ftp_cmd-   \n",
       "0             0             0             0  \n",
       "1             0             0             0  \n",
       "2             0             0             0  \n",
       "3             0             0             0  \n",
       "4             0             0             0  \n",
       "5             0             0             0  \n",
       "6             0             0             0  \n",
       "7             0             0             0  \n",
       "8             0             0             0  \n",
       "9             0             0             0  \n",
       "\n",
       "[10 rows x 210 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "5         0\n",
       "6         0\n",
       "7         0\n",
       "8         0\n",
       "9         0\n",
       "10        0\n",
       "11        0\n",
       "12        0\n",
       "13        0\n",
       "14        0\n",
       "15        0\n",
       "16        0\n",
       "17        0\n",
       "18        0\n",
       "19        0\n",
       "20        0\n",
       "21        0\n",
       "22        0\n",
       "23        0\n",
       "24        0\n",
       "25        0\n",
       "26        0\n",
       "27        0\n",
       "28        0\n",
       "29        0\n",
       "         ..\n",
       "699971    0\n",
       "699972    0\n",
       "699973    0\n",
       "699974    0\n",
       "699975    0\n",
       "699976    0\n",
       "699977    0\n",
       "699978    0\n",
       "699979    0\n",
       "699980    0\n",
       "699981    0\n",
       "699982    0\n",
       "699983    0\n",
       "699984    0\n",
       "699985    1\n",
       "699986    1\n",
       "699987    0\n",
       "699988    0\n",
       "699989    0\n",
       "699990    0\n",
       "699991    0\n",
       "699992    0\n",
       "699993    0\n",
       "699994    0\n",
       "699995    0\n",
       "699996    0\n",
       "699997    0\n",
       "699998    0\n",
       "699999    0\n",
       "700000    0\n",
       "Name: Label, Length: 700001, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "srcip                 int64\n",
       "sport                object\n",
       "dstip                 int64\n",
       "dsport               object\n",
       "proto                object\n",
       "state                object\n",
       "dur                 float64\n",
       "sbyte                 int64\n",
       "dbytes                int64\n",
       "sttl                  int64\n",
       "dttl                  int64\n",
       "sloss                 int64\n",
       "dloss                 int64\n",
       "service              object\n",
       "Sload               float64\n",
       "Dload               float64\n",
       "Spkts                 int64\n",
       "Dpkts                 int64\n",
       "swin                  int64\n",
       "dwin                  int64\n",
       "stcpb                 int64\n",
       "dtcpb                 int64\n",
       "smeansz               int64\n",
       "dmeansz               int64\n",
       "trans                 int64\n",
       "res                   int64\n",
       "Sjit                float64\n",
       "Djit                float64\n",
       "Sintpkt             float64\n",
       "Dintpkt             float64\n",
       "tcprtt              float64\n",
       "synack              float64\n",
       "ackdat              float64\n",
       "is_sm_ips_ports       int64\n",
       "ct_state_ttl          int64\n",
       "ct_flw_http_mthd      int64\n",
       "is_ftp_login          int64\n",
       "ct_ftp_cmd            int64\n",
       "ct_srv_src            int64\n",
       "ct_srv_dst            int64\n",
       "ct_dst_ltm            int64\n",
       "ct_src_ltm            int64\n",
       "ct_src_dport_ltm      int64\n",
       "ct_dst_sport_lt       int64\n",
       "ct_dst_src_ltm        int64\n",
       "attack_cat           object\n",
       "Label                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0      1              2     3    4    5         6    7    8   9   \\\n",
      "0  59.166.0.0   1390  149.171.126.6    53  udp  CON  0.001055  132  164  31   \n",
      "1  59.166.0.0  33661  149.171.126.9  1024  udp  CON  0.036133  528  304  31   \n",
      "2  59.166.0.6   1464  149.171.126.7    53  udp  CON  0.001119  146  178  31   \n",
      "\n",
      "   ...  39  40  41 42  43  44  45  46   47  48  \n",
      "0  ...   0   3   7  1   3   1   1   1  NaN   0  \n",
      "1  ...   0   2   4  2   3   1   1   2  NaN   0  \n",
      "2  ...   0  12   8  1   2   2   1   1  NaN   0  \n",
      "\n",
      "[3 rows x 49 columns]\n",
      "Read 700001 rows.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '0x000b'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-230c48c9cdf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dstip'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dstip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_ip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sport'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sport'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;31m#df['dsport'] = df['dsport'].astype('int64')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[1;32m   5689\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5690\u001b[0m             new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors,\n\u001b[0;32m-> 5691\u001b[0;31m                                          **kwargs)\n\u001b[0m\u001b[1;32m   5692\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'astype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                                             copy=align_copy)\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         return self._astype(dtype, copy=copy, errors=errors, values=values,\n\u001b[0;32m--> 534\u001b[0;31m                             **kwargs)\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     def _astype(self, dtype, copy=False, errors='raise', values=None,\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m_astype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                     \u001b[0;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m                     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0;31m# TODO(extension)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/envs/tf_jupyter/lib/python3.6/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;31m# work around NumPy brokenness, #1987\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype_intsafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;31m# if we have a datetime/timedelta array of objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.astype_intsafe\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '0x000b'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import tensorflow.contrib.learn as skflow\n",
    "import string\n",
    "\n",
    "\n",
    "#from sklearn.utils.multiclass import unique_labels\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, average_precision_score, precision_recall_curve\n",
    "from inspect import signature\n",
    "#%matplotlib inline\n",
    "\n",
    "path = \"UNSW-NB15_1.csv\"\n",
    "# This file is a CSV, just no CSV extension or headers\n",
    "df = pd.read_csv(path, header=None, na_values = '0x')\n",
    "print(df[0:3])\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "# df = df.sample(frac=0.1, replace=False) # Uncomment this line to sample only 10% of the dataset\n",
    " # For now, just drop NA's (rows with missing values)\n",
    "\n",
    "# The CSV file has no column heads, so add them\n",
    "df.columns = [\n",
    "    'srcip',\n",
    "    'sport',\n",
    "    'dstip',\n",
    "    'dsport',\n",
    "    'proto',\n",
    "    'state',\n",
    "    'dur',\n",
    "    'sbyte',\n",
    "    'dbytes',\n",
    "    'sttl',\n",
    "    'dttl',\n",
    "    'sloss',\n",
    "    'dloss',\n",
    "    'service',\n",
    "    'Sload',\n",
    "    'Dload',\n",
    "    'Spkts',\n",
    "    'Dpkts',\n",
    "    'swin',\n",
    "    'dwin',\n",
    "    'stcpb',\n",
    "    'dtcpb',\n",
    "    'smeansz',\n",
    "    'dmeansz',\n",
    "    'trans',\n",
    "    'res',\n",
    "    'Sjit',\n",
    "    'Djit',\n",
    "    'Stime', #QUITAR\n",
    "    'Ltime', #QUITAR\n",
    "    'Sintpkt',\n",
    "    'Dintpkt',\n",
    "    'tcprtt',\n",
    "    'synack',\n",
    "    'ackdat',\n",
    "    'is_sm_ips_ports',\n",
    "    'ct_state_ttl',\n",
    "    'ct_flw_http_mthd',\n",
    "    'is_ftp_login',\n",
    "    'ct_ftp_cmd',\n",
    "    'ct_srv_src',\n",
    "    'ct_srv_dst',\n",
    "    'ct_dst_ltm',\n",
    "    'ct_src_ltm', \n",
    "    'ct_src_dport_ltm',\n",
    "    'ct_dst_sport_lt', \n",
    "    'ct_dst_src_ltm',\n",
    "    'attack_cat',\n",
    "    'Label'\n",
    "]\n",
    "\n",
    "df[0:5]\n",
    "\n",
    "#df.drop('dsport', 1, inplace=True)#\n",
    "# df.drop('state', 1, inplace=True)#\n",
    "# df.drop('dur', 1, inplace=True)#\n",
    "# df.drop('Sload', 1, inplace=True)#\n",
    "# df.drop('Dload', 1, inplace=True)#\n",
    "df.drop('Stime', 1, inplace=True)#\n",
    "df.drop('Ltime', 1, inplace=True)#\n",
    "# df.drop('ct_src_ltm', 1, inplace=True)#\n",
    "\n",
    "ENCODING = 'utf-8'\n",
    "\n",
    "def expand_categories(values):\n",
    "    result = []\n",
    "    s = values.value_counts()\n",
    "    t = float(len(values))\n",
    "    for v in s.index:\n",
    "        result.append(\"{}:{}%\".format(v,round(100*(s[v]/t),2)))\n",
    "    return \"[{}]\".format(\",\".join(result))\n",
    "        \n",
    "def analyze(filename):\n",
    "    print()\n",
    "    print(\"Analyzing: {}\".format(filename))\n",
    "    df = pd.read_csv(filename,encoding=ENCODING)\n",
    "    cols = df.columns.values\n",
    "    total = float(len(df))\n",
    "\n",
    "    print(\"{} rows\".format(int(total)))\n",
    "    for col in cols:\n",
    "        uniques = df[col].unique()\n",
    "        unique_count = len(uniques)\n",
    "        if unique_count>100:\n",
    "            print(\"** {}:{} ({}%)\".format(col,unique_count,int(((unique_count)/total)*100)))\n",
    "        else:\n",
    "            print(\"** {}:{}\".format(col,expand_categories(df[col])))\n",
    "            expand_categories(df[col])\n",
    "\n",
    "#analyze(path)\n",
    "\n",
    "\n",
    "# display 5 rows\n",
    "# df[0:5]\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "#Clean 'date' column and convert to Int type\n",
    "def clean_date(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_removed = s.replace(\" \", \"\")\n",
    "    s_int = int(s_removed)\n",
    "    return s_int\n",
    "\n",
    "########## CLEAN IP #######################\n",
    "def clean_ip(s):\n",
    "    s = ''.join([i for i in s if i not in frozenset(string.punctuation)])\n",
    "    s_int = int(s)\n",
    "    return s_int\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "#MINMAX -1 1\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def min_max_1(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "#MINMAX 0 1\n",
    "def min_max_0(df, name, normalized_low=0, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "        * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "    \n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(\n",
    "        target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    # Regression\n",
    "    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)\n",
    "\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['srcip'] = df['srcip'].apply(clean_ip)\n",
    "df['dstip'] = df['dstip'].apply(clean_ip)\n",
    "\n",
    "df['sport'] = df['sport'].astype('int64')\n",
    "#df['dsport'] = df['dsport'].astype('int64')\n",
    "\n",
    "# Now encode the feature vector\n",
    "\n",
    "min_max_0(df, 'srcip')#\n",
    "min_max_0(df, 'sport')\n",
    "\n",
    "min_max_0(df, 'dstip') #\n",
    "#min_max_0(df, 'dsport')\n",
    "\n",
    "encode_text_dummy(df, 'proto') #\n",
    "encode_text_dummy(df, 'state')\n",
    "\n",
    "min_max_0(df, 'dur')\n",
    "\n",
    "min_max_0(df, 'sbyte') #\n",
    "min_max_0(df, 'dbytes')#\n",
    "min_max_0(df, 'sttl')#\n",
    "min_max_0(df, 'dttl')#\n",
    "min_max_0(df, 'sloss')#\n",
    "min_max_0(df, 'dloss')#\n",
    "encode_text_dummy(df, 'service') #\n",
    "min_max_0(df, 'Sload')\n",
    "\n",
    "min_max_0(df, 'Dload')\n",
    "\n",
    "min_max_0(df, 'Spkts')#\n",
    "min_max_0(df, 'Dpkts')#\n",
    "min_max_0(df, 'swin')#\n",
    "min_max_0(df, 'dwin')#\n",
    "min_max_0(df, 'stcpb')#\n",
    "min_max_0(df, 'dtcpb')#\n",
    "min_max_0(df, 'smeansz')#\n",
    "min_max_0(df, 'dmeansz')#\n",
    "min_max_0(df, 'trans')#\n",
    "min_max_0(df, 'res')#\n",
    "min_max_0(df, 'Sjit')#\n",
    "min_max_0(df, 'Djit')#\n",
    "\n",
    "min_max_0(df, 'Sintpkt')#\n",
    "min_max_0(df, 'Dintpkt')#\n",
    "min_max_0(df, 'tcprtt')#\n",
    "min_max_0(df, 'synack')#\n",
    "min_max_0(df, 'ackdat')#\n",
    "min_max_0(df, 'is_sm_ips_ports')#ojo\n",
    "min_max_0(df, 'ct_state_ttl')#\n",
    "#min_max_0(df, 'ct_flw_http_mthd')#\n",
    "#min_max_0(df, 'is_ftp_login')#ojo\n",
    "#min_max_0(df, 'ct_ftp_cmd')#\n",
    "encode_text_dummy(df, 'ct_ftp_cmd')#\n",
    "min_max_0(df, 'ct_srv_src')#\n",
    "min_max_0(df, 'ct_srv_dst')#\n",
    "min_max_0(df, 'ct_dst_ltm')#\n",
    "min_max_0(df, 'ct_src_ltm')\n",
    "\n",
    "min_max_0(df, 'ct_src_dport_ltm')#\n",
    "min_max_0(df, 'ct_dst_sport_lt')#\n",
    "min_max_0(df, 'ct_dst_src_ltm')#\n",
    "\n",
    "#encode_text_dummy(df, 'attack_cat')\n",
    "\n",
    "outcomes = encode_text_index(df, 'Label')#\n",
    "num_classes = len(outcomes)\n",
    "\n",
    "# display 5 rows\n",
    "\n",
    "#df.dropna(inplace=True,axis=1)\n",
    "df[0:10]\n",
    "\n",
    "\n",
    "##################################################\n",
    "# Break into X (predictors) & y (prediction)\n",
    "x, y = to_xy(df,'Label')\n",
    "#################################################\n",
    "\n",
    "\n",
    "\n",
    "# Create a test/train split.  25% test\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Create neural net\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(50, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(10, input_dim=x.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "model.add(Dense(y.shape[1],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, verbose=1, mode='auto')\n",
    "history = model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2,epochs=1000)\n",
    "\n",
    "\n",
    "# Measure accuracy\n",
    "pred = model.predict(x_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "y_eval = np.argmax(y_test,axis=1)\n",
    "score = metrics.accuracy_score(y_eval, pred)\n",
    "print(\"Validation score: {}\".format(score))\n",
    "\n",
    "print(outcomes)\n",
    "\n",
    "### PLOT ACCURACY ####\n",
    "\n",
    "plt.plot(np.arange(len(history.history['acc'])),\n",
    "history.history['acc'], label='training')\n",
    "plt.plot(np.arange(len(history.history['val_acc'])),\n",
    "history.history['val_acc'], label='validation')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy ')\n",
    "plt.legend(loc=0)\n",
    "plt.show()\n",
    "\n",
    "### PLOT CONFUSION MATRIX ###\n",
    "\n",
    "# Not normalized\n",
    "cm = confusion_matrix(y_eval, pred)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, outcomes)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_normalized, outcomes, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### PLOT ROC ###\n",
    "\n",
    "#Plot an ROC. pred - the predictions, y - the expected outpus.\n",
    "#En mi caso creo que es pred == pred y== y_eval\n",
    "def plot_roc(pred, y):\n",
    "    fpr, tpr, _ = roc_curve(y, pred)\n",
    "    roc_auc = auc(fpr,tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "plot_roc(pred, y_eval)\n",
    "\n",
    "\n",
    "### PRECISION-RECALL ###\n",
    "\n",
    "average_precision = average_precision_score(y_eval, pred)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_eval, pred)\n",
    "\n",
    "# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2-Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tf_jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
